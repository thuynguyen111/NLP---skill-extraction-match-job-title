{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d127874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Visualization     \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# do not print warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4379caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"job_offers_original_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b8500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns and keeps only job_title and job_description\n",
    "df = df[['job_title','company_name', 'job_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84663490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(?<![A-Z\\W])  what precedes is a word character EXCEPT for capital letters\n",
    "#(?=[A-Z])     and what follows is a capital letter\n",
    "def sepa(text): \n",
    "    text = re.sub(r'(?<![A-Z\\W])(?=[A-Z])', ' ', text)\n",
    "    return(text)\n",
    "\n",
    "df['job_description']=df['job_description'].apply(sepa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8f5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_description'] = df['job_description'].str.replace('\\d+', '') # remove digits\n",
    "df[\"job_description\"] = df[\"job_description\"].str.lower() #lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cb6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_description'] = df['job_description'].str.replace('/', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035a3f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" do you want to work on the most pressing problem of our generation?we're building the infrastructure for the net zero transition, and we're looking for brilliant engineers, designers, and data scientists who want to help define a low carbon future.decarbonizing the economy requires a granular, real-time view of where emissions come from and how they might be reduced. we build software to automate the carbon footprinting of supply chains. banks, traders, and manufacturers use our product to tame the complexity of international supply networks, identify the most carbon-intensive parts, and find greener alternatives. we were part of the y combinator summer  batch and have secured backing from the uk government's innovation arm, innovate uk, the nat west accelerator and the london business school incubator.to join carbon chain, you'll be a keen technologist who loves to learn from others. our company is made up of  passionate people with expertise ranging from oil refining to deep learning. between us we've run amazon's european supply chain, built just eat's corporate meal delivery platform, and monitored industrial emissions with satellites for al gore. we've got mbas and ph ds but we know that there's a lot we don't know, and we're hoping you can help fill that gap.what will you be responsible for at carbon chain?as the world wakes up to the reality of climate change and the need to decarbonize, there's a pressing need to understand the carbon intensity of every activity in the economy. your job as data engineer is to work with our data scientists to organize, automate, and deploy the data pipelines we need to provide that understanding.we're a small team of versatile technologists and we don't believe in a siloed approach. our data engineers sit side by side with software engineers and designers, making sure that we have the data we need to provide the experience our customers want. you'll be deeply embedded in the product team, with your work being deployed to clients every week. you'll work closely with our domain experts, and have the chance to present to clients if that's something that excites you.you can expect to have:ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python. we deploy our work in a variety of ways depending upon the challenge, from lambdas to docker containers. our etl is run in dagster, which is a friendlier and more modern version of airflow. you'd be joining an experienced team but you'd be the first data engineer, so you'd have lots of scope to define best practices and choose your tools.we're interested in talking to people with dev ops and classical software engineering experience, as well as those coming from data science who have a passion for scaling etl systems.our only must-haves are possessing a hunger to solve business challenges using technology, the ability to build close relationships with your team, and the right to work in the uk.which tools, technologies, and processes will you work with?data processing with the standard scientific stack (pandas, numpy, scipy) and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will.object-oriented code forms the bulk of our codebase.postgre sql and dynamo db managed databases form the persistence layer - you'll learn to navigate document and relational databases and appreciate the values in both worlds.infrastructure automation is owned by the whole team, helping to spread the dev ops mentality across the whole technology department (and beyond).you don't need to be a pro at all of these skills to apply for the role, but we'd love to hear about any relevant knowledge and experiences that you have in these areas.what we require from applicants right to work in the uk and willingness to come to london office + days a week+ years of commercial data engeering, data science, or software engineering experience a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we're offering competitive salary + generous equity package flexible working hours - we encourage regular breaks and being afk (away from keyboard) to support your wellbeing flexible working location (we like to meet in the office couple of times every week)£ annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays, and frequent pub trips pakt coffee and snacks of your choice in the office days holiday + bank holidays we're striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology, be that in terms of gender, race, or professional background.if you think your skills and experience match what we're looking for and you'd like to join a carbon tech industry unicorn, please get in touch!\\n      \\n\\n        show more\\n\\n        \\n\\n\\n        show less\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1d83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some common words that lead to the skills are experience, you'll have, responsible, are looking for, ability to,\n",
    "#knowledge of, understanding of\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de2d8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c173767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the ads into a list\n",
    "desc=list(df.job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73801bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise Spacy model\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75c875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_terms(terms, texts):\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for sentence in set([tok.sent for tok in doc if tok.lower_ in terms]):\n",
    "            text = sentence.text.strip() # break docs into sentence\n",
    "            markup = re.sub(fr'(?i)\\b({\"|\".join(terms)})\\b', r'<strong>\\1</strong>', text)\n",
    "            display(HTML(markup))\n",
    "            print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b574235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "you'd be joining an experienced team but you'd be the first data engineer, so you'd have lots of scope to define best practices and choose your tools.we're interested in talking to people with dev ops and classical software engineering experience, as well as those coming from data science who have a passion for scaling etl systems.our only must-haves are possessing a hunger to solve business challenges using technology, the ability to build close relationships with your team, and the right to work in the uk.which tools, technologies, and processes will you work with?data processing with the standard scientific stack (pandas, numpy, scipy) and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will.object-oriented code forms the bulk of our codebase.postgre sql and dynamo db managed databases form the persistence layer - you'll learn to navigate document and relational databases and appreciate the values in both worlds.infrastructure automation is owned by the whole team, helping to spread the dev ops mentality across the whole technology department (and beyond).you don't need to be a pro at all of these skills to apply for the role, but we'd love to hear about any relevant <strong>knowledge</strong> and experiences that you have in these areas.what we require from applicants right to work in the uk and willingness to come to london office + days a week+ years of commercial data engeering, data science, or software engineering experience a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we're offering competitive salary + generous equity package flexible working hours - we encourage regular breaks and being afk (away from keyboard) to support your wellbeing flexible working location (we like to meet in the office couple of times every week)£ annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays, and frequent pub trips pakt coffee and snacks of your choice in the office days holiday + bank holidays we're striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology, be that in terms of gender, race, or professional background.if"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "if you need reasonable adjustments at any point in the application or interview process, please let us know.in your application, please feel free to note which pronouns you use (for example - she,her,hers, he,him,his, they,them,theirs, etc).bumble is looking for an experienced engineer to participate in the development of the data-collecting framework, services and tools for the cross-functional bi department.this role will be based in london, reporting to the data engineering team lead.key accountabilities work on one of the key data sources - bumble’s data definition and collection framework provide data to the company’s analysts and decision-makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources, reporting tools and databases support and evolve the underlying infrastructure of the company’s data platform experience we are looking for advanced level python for backend development advanced <strong>knowledge</strong> of the posix,unix,linux ecosystem sql-based and relational databases, especially data warehouse solutions understanding of popular code development approaches test-driven development continuous integration continuous deployment containerized service development desirable skills typescript,react for ui development hadoop ecosystem experience java,spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self-starter: you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a 'can-do' attitude and a flexible approach you know how to manage multiple priorities, breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team’s advantage you are deeply passionate about bumble’s brand vision and values\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "bumble is looking for an experienced engineer to participate in the development of the data-collecting framework, services and tools for the cross-functional bi department.this role will be based in london, reporting to the data engineering team lead.key accountabilities work on one of the key data sources - bumble’s data definition and collection framework provide data to the company’s analysts and decision-makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources, reporting tools and databases support and evolve the underlying infrastructure of the company’s data platform experience we are looking for advanced level python for backend development advanced <strong>knowledge</strong> of the posix,unix,linux ecosystem sql-based and relational databases, especially data warehouse solutions understanding of popular code development approaches test-driven development continuous integration continuous deployment containerized service development desirable skills typescript,react for ui development hadoop ecosystem experience java,spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self-starter: you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a 'can-do' attitude and a flexible approach you know how to manage multiple priorities, breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team’s advantage you are deeply passionate about bumble’s brand vision and values\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "building reliable data pipelines experience of exploratory data analysis experience of visualising data working with metrics, segments, aggregates, features requirements of the role maintain a broad <strong>knowledge</strong> of the technology landscape helping the data shed provide market-leading assist our clients in enterprise-scale projects utilising best-practice development methodologies, well tested spend as much time on tests and security as on writing code work with a team of like-minded, high-calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that’s broken, fix it."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "can write code and tests in at least one core language  working <strong>knowledge</strong> of sql and relational databases and,or no sql databases <strong>knowledge</strong> of at least one cloud provider such as aws, azure or gcp comfortable working with different data formats, e.g., csv, json and xml broader <strong>knowledge</strong> of it — e.g., security and networking working in an agile environment test-driven development and,or behaviour driven development continuous integration and continuous deployment (ci,cd)optional experience the following is optional, but highly desirable experience!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and <strong>knowledge</strong> to help you build a career in this fast evolving, and in demand, industry.some of the things we’d like you to do:assist the development of technical solutions, in line with specifications, that collect, store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures, helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies, ensuring your work incorporates industry best practice monitor automated jobs, troubleshooting data issues as-and-when they arise support other members of the team responsible for “last mile” transformation and visualization of data within google data studio reports and dashboards provide hands-on support to users of reporting solutions, helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings, presenting your solutions and providing updates on your work.support the development strong working relationships with third-party data providers that we rely on for access to necessary data a bit about yourself:required previous experience working with data and technology experience with programming and,or statistical languages (e.g. sql, python)analytically minded, enabling you to understand and overcome technically complex challenges, and to tell compelling stories with data strong organizational skills and attention to detail, including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills, ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem, and an understanding of the role that data plays within it delivers best results when working in a team environment, and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl, particularly useful if done using google cloud platform, airflow, dbt etc.experience with digital marketing platforms and the data they generate, in particular google marketing platform, facebook, twitter etc. <strong>knowledge</strong> of their api’s a plus.an understanding of how data is tracked and exchanged in the process of digital advertising (e.g. role of ad servers and other third-party tech vendors)experience using or building reports with business intelligence software, ideally google data studio work experience within a marketing organization, preferably at a media agency or related company (e.g. publisher, ad tech, client marketing org)what you can expect from essence:essence’s mission is to make advertising more valuable to the world."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "to always represent the team professionally – both internally and externally key stakeholders:senior director digital channels, director of analytics & insight, data protection officer <strong>knowledge</strong> & experience essential:programming experience in java ( preferable) and python experience with testing frameworks, junit, mockito, etc.comfortable familiarity working with large data sets good sql skills strong problem-solving skills experience writing batch etls on large datasets using various sources (e.g. sql servers, rest apis, json files)experience with build tools, such as gradle, maven, sbtfamiliarity with osx or linux environment (shell scripting, basic system administration etc).experience using source control,collaboration tools such as git hub, bitbucket or git lab.familiarity with collaboration and communication tools such as jira, confluence, slack etc.desirable:bsc or higher level degree in computer science, stem subject or a similar field of study experience with cloud-based engineering platforms, e.g. gcp, aws, azure experience with apache beam experience with streaming data experience with dag based workflow management systems, ideally air flow competencies, skills & attributes essential:ability to quickly learn and employ new technologies and methodologies."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "we'll make sure you're supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout .requirements must have: sql, python, data infrastructure, sql etl,elt <strong>knowledge</strong>, experience with dags to manage script dependencies with tools like airflow nice to have: snowflake, airflow, terraform, ruby, data visualisation tool (e.g. looker, tableau, power bi), amplitude, dev ops, redshift, awsplease note: we know that no candidate will be the perfect match for all we've listed in this posting, so we’d encourage you to apply if you feel you're close to the brief but not an exact match.benefits a competitive salary with equity in the company (share options)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "the ideal candidate combines strong business acumen, experience in data pipelines, databases and development best-practices along with a passion for tech.key accountabilities working with big data: tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team’s ecosystem: dozens of in-house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and <strong>knowledge</strong> a <strong>knowledge</strong> and understanding of sql language, ability to write complex queries data warehousing and database basic architecture principles posix,unix,linux ecosystem <strong>knowledge</strong> experience with php,python or desire to learn them we appreciate result-oriented work style, flexibility in choosing tools and technical approaches nice to have experience with exasol and,or snowflake databases good <strong>knowledge</strong> of sql (window functions, common table expressions, complex grouping etc.)google cloud platform familiarity basic hadoop familiarity (hdfs,hive)about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a 'can-do' attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team’s advantage\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    }
   ],
   "source": [
    "highlight_terms(['knowledge'], desc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f04e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'POS': {'IN': ('NOUN', 'PROPN','PUNCT')}, 'OP': '+'}, {'LOWER': 'knowledge'}]\n",
    "matcher.add('knowledge_noun', [pattern])\n",
    "\n",
    "pattern = [{'LOWER': 'knowledge'}, {'POS': 'ADP'}, {'POS': {'IN': ('DET', 'NOUN', 'PROPN','PUNCT','CONJ')}, 'OP': '+'}]\n",
    "matcher.add('knowledge_adp', [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd82367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extraction(examples, *extractors):\n",
    "    seen = set()\n",
    "    for doc in nlp.pipe(examples):\n",
    "        doc.ents = filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)])\n",
    "        for tok in doc:\n",
    "            if tok.lower_ == 'knowledge':\n",
    "                sentence = tok.sent\n",
    "                if sentence.text in seen:\n",
    "                    continue\n",
    "                seen.update([sentence.text])\n",
    "                if not sentence.ents:\n",
    "                    doc.ents = list(doc.ents) + [Span(doc, tok.i, tok.i+1, 'MISSING')]\n",
    "                displacy.render(sentence, style='ent', options = {'colors': {'MISSING': 'pink',\n",
    "                                                                            'KNOWLEDGE': 'lightgreen'}})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb77eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">you'd be joining an experienced team but you'd be the first data engineer, so you'd have lots of scope to define best practices and choose your tools.we're interested in talking to people with dev ops and classical software engineering experience, as well as those coming from data science who have a passion for scaling etl systems.our only must-haves are possessing a hunger to solve business challenges using technology, the ability to build close relationships with your team, and the right to work in the uk.which tools, technologies, and processes will you work with?data processing with the standard scientific stack (pandas, numpy, scipy) and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will.object-oriented code forms the bulk of our codebase.postgre sql and dynamo db managed databases form the persistence layer - you'll learn to navigate document and relational databases and appreciate the values in both worlds.infrastructure automation is owned by the whole team, helping to spread the dev ops mentality across the whole technology department (and beyond).you don't need to be a pro at all of these skills to apply for the role, but we'd love to hear about any relevant \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " and experiences that you have in these areas.what we require from applicants right to work in the uk and willingness to come to london office + days a week+ years of commercial data engeering, data science, or software engineering experience a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we're offering competitive salary + generous equity package flexible working hours - we encourage regular breaks and being afk (away from keyboard) to support your wellbeing flexible working location (we like to meet in the office couple of times every week)£ annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays, and frequent pub trips pakt coffee and snacks of your choice in the office days holiday + bank holidays we're striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology, be that in terms of gender, race, or professional background.if </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">if you need reasonable adjustments at any point in the application or interview process, please let us know.in your application, please feel free to note which pronouns you use (for example - she,her,hers, he,him,his, they,them,theirs, etc).bumble is looking for an experienced engineer to participate in the development of the data-collecting framework, services and tools for the cross-functional bi department.this role will be based in london, reporting to the data engineering team lead.key accountabilities work on one of the key data sources - bumble’s data definition and collection framework provide data to the company’s analysts and decision-makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources, reporting tools and databases support and evolve the underlying infrastructure of the company’s data platform experience we are looking for advanced level python for backend development advanced \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of the posix,unix,linux ecosystem sql-\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       "based and relational databases, especially data warehouse solutions understanding of popular code development approaches test-driven development continuous integration continuous deployment containerized service development desirable skills typescript,react for ui development hadoop ecosystem experience java,spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self-starter: you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a 'can-do' attitude and a flexible approach you know how to manage multiple priorities, breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team’s advantage you are deeply passionate about bumble’s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">bumble is looking for an experienced engineer to participate in the development of the data-collecting framework, services and tools for the cross-functional bi department.this role will be based in london, reporting to the data engineering team lead.key accountabilities work on one of the key data sources - bumble’s data definition and collection framework provide data to the company’s analysts and decision-makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources, reporting tools and databases support and evolve the underlying infrastructure of the company’s data platform experience we are looking for advanced level python for backend development advanced \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of the posix,unix,linux ecosystem sql-\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       "based and relational databases, especially data warehouse solutions understanding of popular code development approaches test-driven development continuous integration continuous deployment containerized service development desirable skills typescript,react for ui development hadoop ecosystem experience java,spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self-starter: you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a 'can-do' attitude and a flexible approach you know how to manage multiple priorities, breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team’s advantage you are deeply passionate about bumble’s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">can write code and tests in at least one core language  working \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of sql\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " and relational databases and,or no sql databases knowledge of at least one cloud provider such as aws, azure or gcp comfortable working with different data formats, e.g., csv, json and xml broader knowledge of it — e.g., security and networking working in an agile environment test-driven development and,or behaviour driven development continuous integration and continuous deployment (ci,cd)optional experience the following is optional, but highly desirable experience! </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">building reliable data pipelines experience of exploratory data analysis experience of visualising data working with metrics, segments, aggregates, features requirements of the role maintain a broad \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of the technology landscape\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " helping the data shed provide market-leading assist our clients in enterprise-scale projects utilising best-practice development methodologies, well tested spend as much time on tests and security as on writing code work with a team of like-minded, high-calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that’s broken, fix it. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " to help you build a career in this fast evolving, and in demand, industry.some of the things we’d like you to do:assist the development of technical solutions, in line with specifications, that collect, store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures, helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies, ensuring your work incorporates industry best practice monitor automated jobs, troubleshooting data issues as-and-when they arise support other members of the team responsible for “last mile” transformation and visualization of data within google data studio reports and dashboards provide hands-on support to users of reporting solutions, helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings, presenting your solutions and providing updates on your work.support the development strong working relationships with third-party data providers that we rely on for access to necessary data a bit about yourself:required previous experience working with data and technology experience with programming and,or statistical languages (e.g. sql, python)analytically minded, enabling you to understand and overcome technically complex challenges, and to tell compelling stories with data strong organizational skills and attention to detail, including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills, ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem, and an understanding of the role that data plays within it delivers best results when working in a team environment, and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl, particularly useful if done using google cloud platform, airflow, dbt etc.experience with digital marketing platforms and the data they generate, in particular google marketing platform, facebook, twitter etc. knowledge of their api’s a plus.an understanding of how data is tracked and exchanged in the process of digital advertising (e.g. role of ad servers and other third-party tech vendors)experience using or building reports with business intelligence software, ideally google data studio work experience within a marketing organization, preferably at a media agency or related company (e.g. publisher, ad tech, client marketing org)what you can expect from essence:essence’s mission is to make advertising more valuable to the world. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">to always represent the team professionally – both internally and externally key stakeholders:senior director digital channels, director of analytics &amp; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    insight, data protection officer knowledge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_noun</span>\n",
       "</mark>\n",
       " &amp; experience essential:programming experience in java ( preferable) and python experience with testing frameworks, junit, mockito, etc.comfortable familiarity working with large data sets good sql skills strong problem-solving skills experience writing batch etls on large datasets using various sources (e.g. sql servers, rest apis, json files)experience with build tools, such as gradle, maven, sbtfamiliarity with osx or linux environment (shell scripting, basic system administration etc).experience using source control,collaboration tools such as git hub, bitbucket or git lab.familiarity with collaboration and communication tools such as jira, confluence, slack etc.desirable:bsc or higher level degree in computer science, stem subject or a similar field of study experience with cloud-based engineering platforms, e.g. gcp, aws, azure experience with apache beam experience with streaming data experience with dag based workflow management systems, ideally air flow competencies, skills &amp; attributes essential:ability to quickly learn and employ new technologies and methodologies. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">we'll make sure you're supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout .requirements must have\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    : sql, python, data infrastructure, sql etl,elt knowledge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_noun</span>\n",
       "</mark>\n",
       ", experience with dags to manage script dependencies with tools like airflow nice to have: snowflake, airflow, terraform, ruby, data visualisation tool (e.g. looker, tableau, power bi), amplitude, dev ops, redshift, awsplease note: we know that no candidate will be the perfect match for all we've listed in this posting, so we’d encourage you to apply if you feel you're close to the brief but not an exact match.benefits a competitive salary with equity in the company (share options) </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">the ideal candidate combines strong business acumen, experience in data pipelines, databases and development best-practices along with a passion for tech.key accountabilities working with big data: tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team’s ecosystem: dozens of in-house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language, ability to write complex queries data warehousing and database basic \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    architecture principles posix,unix,linux ecosystem knowledge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_noun</span>\n",
       "</mark>\n",
       " experience with php,python or desire to learn them we appreciate result-oriented work style, flexibility in choosing tools and technical approaches nice to have experience with exasol and,or snowflake databases good \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of sql (window functions,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " common table expressions, complex grouping etc.)google cloud platform familiarity basic hadoop familiarity (hdfs,hive)about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a 'can-do' attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team’s advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">you will have relevant experience in: big data experience strong coding background in python or similar and strong sql skills;domain \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of all\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " azure architecture and experience using azure tooling;expertise in data modelling;experience in building data pipelines (etl and,or analytical pipelines);experience in cleansing, managing and transforming high volume data;senior stakeholder management skills including the ability to manage a diverse set of stakeholders and to prioritize needs;experience in fraud software deployment; and configuration of fraud detection tools and,or analytics platforms (desirable);experience in fraud, compliance or financial crime (desirable). </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">additional responsibilities will include managing data pipelines and problem solving, help automate manual data processing and manage the knowledge base. about the person above all, we’re looking for someone who lives and breathes our relaxed and agile culture, you’ll need to be able to demonstrate that you have…excellent numeracy and it skills, including advanced \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of office\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       "  and excel.strong experience in traditional microsoft bi stack: sql server, ssrs , ssas (tabular with dax &amp; olap with mdx) , ssisexperience with some of the following: data factory, data lake store (gen ), databricks, synapse analytics, cosmos db, azure sql, azure analysis services the ability to move out of comfort zone.the ability to understand complex situations and to present synthesis. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of data modelling tactics, techniques,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " and procedures and how to apply them. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">you will need to be competent in data assessment and profiling, source system analysis and be able to provide a clear vision on how the data can be processed and interpreted to support the end use of the data.the ideal person will come from a data analytics background (data engineer,data scientist,data analyst) with strong software engineering, etl,elt data pipeline experience and an interest in machine learning.key skills - mandatory:strong data modelling and sql,database design skills.skill and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of etl,elt processes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " good programming skills – specifically those used in the application of data science, e.g. sql, r, python, java script etc.experience of the .net programming stack of technologies.excellent numerical, analytical and statistics skills experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modelling, clustering, decision trees, neural networks, etc.experience of natural language processing.knowledge,experience using data science technologies including predictive and prescriptive modelling techniques experience in visualising,presenting data and insights to stakeholders. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> you’ll bring the ambition, we’ll provide the opportunities at tesco bank we have an excellent opportunity for a data engineer with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of sas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " or another programming language. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">· produce regular business performance bi for analysis, executive and governance purposes in a consistent, accurate and timely manner.· ensure data reporting and manipulation are compliant with internal policies, maintaining all documentation and data definition schedules where appropriate· liaising with internal stakeholders regularly to ensure assistance is given in understanding data &amp; bi for improving business performance or operations· understand and identify stakeholder data requests and develop or recommend solutions to meet requirements· responsible for supporting all aspects of data such as solution development, quality, security, management, architecture, availability and performance· identify and monitor associated data &amp; bi risks and report any business impact with recommended solutions to the data engineering manager· working with the data &amp; bi team to develop and maintain a comprehensive data warehouse using sas,sql to ensure all data clearly defined and consistently maintained throughout the organisation· develop and maintain data dictionaries covering factors and measures within data warehouses  experience and skills that are essential to be a data engineer· some \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of sql\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " is essential· ability to analyse and interpret data with good investigative and analytical skills and make recommendations· strong communication skills (both verbal and written) with non-technical internal colleagues· proven organisation skills with the ability to work with tight deadlines· able to demonstrate sound attention to detail, ensuring any output is accurate before being passed onto the wider business· experience developing and maintaining strong working relationships· demonstrate a ‘can do’ attitude with a desire to thrive in a dynamic and fast paced environment· in-depth \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of microsoft office (\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       "particularly excel) other experience and skills that would be beneficial· \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of sas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " or another programming language· experience of excel, or other analytical , visualisation tools· some experience of defining data requirements· previous experience within the general insurance or financial services industry at tesco our purpose is to help our customers, communities and the planet a little better every day. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">you will be working with multiple departments and juggling competing time-sensitive requests, so an ability to prioritise and remain ‘cool-headed’ under pressure is important.principal responsibilities &amp; accountabilities:analyse and organise raw data build data systems and pipelines identify, design, and implement internal process improvements: automating manual processes, optimising data delivery, re-designing infrastructure for greater scalability, etc.evaluate business needs and objectives conduct complex data analysis and report on results combine raw information from different sources explore ways to enhance data quality and reliability requirements,professional,technical skills:previous experience as a data engineer, or a similar role technical expertise with data models \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    knowledge of programming languages,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_adp</span>\n",
       "</mark>\n",
       " specifically python hands-on experience with ms sql server and mongodb great numerical and analytical skills experience working in finance is a considered a plus</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">our people have a creative, innovative, fun, and collaborative attitude, and are dedicated to creating new and valuable solutions for hp.the data engineer applies advanced subject \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    matter knowledge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">knowledge_noun</span>\n",
       "</mark>\n",
       " to solve complex business issues and is regarded as a subject matter expert. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:20], matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "949ad614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extractions(examples, *extractors):\n",
    "    # Could use context instead of enumerate\n",
    "    for idx, doc in enumerate(nlp.pipe(examples, batch_size=100, disable=['ner'])):\n",
    "        for ent in filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)]):\n",
    "            sent = ent.root.sent\n",
    "            yield ent.text, idx, ent.start, ent.end, ent.label_, sent.start, sent.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a7239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('knowledge of the posix,unix,linux ecosystem sql-',\n",
       "  1,\n",
       "  334,\n",
       "  345,\n",
       "  'knowledge_adp',\n",
       "  151,\n",
       "  492),\n",
       " ('knowledge of the posix,unix,linux ecosystem sql-',\n",
       "  2,\n",
       "  235,\n",
       "  246,\n",
       "  'knowledge_adp',\n",
       "  105,\n",
       "  393),\n",
       " ('knowledge of sql', 3, 285, 288, 'knowledge_adp', 272, 370),\n",
       " ('knowledge of the technology landscape',\n",
       "  3,\n",
       "  399,\n",
       "  404,\n",
       "  'knowledge_adp',\n",
       "  370,\n",
       "  508),\n",
       " ('insight, data protection officer knowledge',\n",
       "  6,\n",
       "  258,\n",
       "  264,\n",
       "  'knowledge_noun',\n",
       "  235,\n",
       "  442),\n",
       " (': sql, python, data infrastructure, sql etl,elt knowledge',\n",
       "  7,\n",
       "  292,\n",
       "  305,\n",
       "  'knowledge_noun',\n",
       "  259,\n",
       "  404),\n",
       " ('architecture principles posix,unix,linux ecosystem knowledge',\n",
       "  9,\n",
       "  452,\n",
       "  461,\n",
       "  'knowledge_noun',\n",
       "  314,\n",
       "  580),\n",
       " ('knowledge of sql (window functions,',\n",
       "  9,\n",
       "  498,\n",
       "  505,\n",
       "  'knowledge_adp',\n",
       "  314,\n",
       "  580)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_extractions(desc[:10], matcher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31b660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put it in a dataframe and join with the job metadata\n",
    "def extract_df(*extractors, n_max=None, **kwargs):\n",
    "    if n_max is None:\n",
    "        n_max = len(df)\n",
    "    ent_df = pd.DataFrame(list(get_extractions(df[:n_max].job_description, *extractors)),\n",
    "                          columns=['text', 'docidx', 'start', 'end', 'label', 'sent_start', 'sent_end'])\n",
    "    return ent_df.merge(df, how='left', left_on='docidx', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d4d9caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docidx</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_start</th>\n",
       "      <th>sent_end</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knowledge of the posix,unix,linux ecosystem sql-</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>345</td>\n",
       "      <td>knowledge_adp</td>\n",
       "      <td>151</td>\n",
       "      <td>492</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bumble</td>\n",
       "      <td>we strongly encourage people of colour, lesbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knowledge of the posix,unix,linux ecosystem sql-</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>246</td>\n",
       "      <td>knowledge_adp</td>\n",
       "      <td>105</td>\n",
       "      <td>393</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bumble</td>\n",
       "      <td>we strongly encourage people of colour, lesbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knowledge of sql</td>\n",
       "      <td>3</td>\n",
       "      <td>285</td>\n",
       "      <td>288</td>\n",
       "      <td>knowledge_adp</td>\n",
       "      <td>272</td>\n",
       "      <td>370</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>The Data Shed</td>\n",
       "      <td>description at the data shed, we've been work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knowledge of the technology landscape</td>\n",
       "      <td>3</td>\n",
       "      <td>399</td>\n",
       "      <td>404</td>\n",
       "      <td>knowledge_adp</td>\n",
       "      <td>370</td>\n",
       "      <td>508</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>The Data Shed</td>\n",
       "      <td>description at the data shed, we've been work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insight, data protection officer knowledge</td>\n",
       "      <td>6</td>\n",
       "      <td>258</td>\n",
       "      <td>264</td>\n",
       "      <td>knowledge_noun</td>\n",
       "      <td>235</td>\n",
       "      <td>442</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Square Enix</td>\n",
       "      <td>job summary:square enix has an internal cloud...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text  docidx  start  end  \\\n",
       "0  knowledge of the posix,unix,linux ecosystem sql-       1    334  345   \n",
       "1  knowledge of the posix,unix,linux ecosystem sql-       2    235  246   \n",
       "2                                  knowledge of sql       3    285  288   \n",
       "3             knowledge of the technology landscape       3    399  404   \n",
       "4        insight, data protection officer knowledge       6    258  264   \n",
       "\n",
       "            label  sent_start  sent_end      job_title   company_name  \\\n",
       "0   knowledge_adp         151       492  Data Engineer         Bumble   \n",
       "1   knowledge_adp         105       393  Data Engineer         Bumble   \n",
       "2   knowledge_adp         272       370  Data Engineer  The Data Shed   \n",
       "3   knowledge_adp         370       508  Data Engineer  The Data Shed   \n",
       "4  knowledge_noun         235       442  Data Engineer    Square Enix   \n",
       "\n",
       "                                     job_description  \n",
       "0   we strongly encourage people of colour, lesbi...  \n",
       "1   we strongly encourage people of colour, lesbi...  \n",
       "2   description at the data shed, we've been work...  \n",
       "3   description at the data shed, we've been work...  \n",
       "4   job summary:square enix has an internal cloud...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "ent_df = extract_df(matcher, n_max=1000)\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ac75523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the counts of different texts.\n",
    "\n",
    "#It's more significant if it happens accross multiple Advertisers/Sources.\n",
    "\n",
    "def aggregate_df(df, col=['text']):\n",
    "    return (df\n",
    "            .groupby(col)\n",
    "            .agg(n_company=('company_name', 'nunique'),\n",
    "                 n=('job_title', 'count'))\n",
    "            .reset_index()\n",
    "            .sort_values(['n_company','n'], ascending=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "028f002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dab5da92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>knowledge of sql</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>skills, knowledge</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>knowledge of the</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>knowledge of a</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>knowledge of data</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>analyses knowledge</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>knowledge of drug, device</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>knowledge of statistics</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>skills,knowledge</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>knowledge of ms</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text  n_company   n\n",
       "129           knowledge of sql          5  15\n",
       "175          skills, knowledge          4  19\n",
       "136           knowledge of the          3  14\n",
       "51              knowledge of a          3   9\n",
       "72           knowledge of data          3   7\n",
       "11          analyses knowledge          2  14\n",
       "94   knowledge of drug, device          2  10\n",
       "132    knowledge of statistics          2   9\n",
       "176           skills,knowledge          2   9\n",
       "116            knowledge of ms          2   8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb15560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showent(docidx, start, end, label, sent_start, sent_end, **kwargs):\n",
    "    # We don't need to parse it, so just make_doc\n",
    "    doc = nlp.make_doc(desc[docidx])\n",
    "    doc.ents = [Span(doc, start, end, label)]\n",
    "    sent = doc[sent_start:sent_end]\n",
    "    displacy.render(sent, style='ent')\n",
    "    \n",
    "def showent_df(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        showent(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad010bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df['text'] = ent_df['text'].str.replace('knowledge', '')\n",
    "ent_df['text'] = ent_df['text'].str.replace('of', '')\n",
    "ent_df['text'] = ent_df['text'].str.replace(',', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5e09a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>sql</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>skills;</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sql skills</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sql.·</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>staff.in depth</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>technologies•</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>threats.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                text  n_company   n\n",
       "78               sql          5  15\n",
       "176         skills;           4  19\n",
       "85               the          3  14\n",
       "0                  a          3   9\n",
       "21              data          3   7\n",
       "..               ...        ...  ..\n",
       "180      sql skills           1   1\n",
       "181           sql.·           1   1\n",
       "182  staff.in depth           1   1\n",
       "186   technologies•           1   1\n",
       "188        threats.           1   1\n",
       "\n",
       "[191 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88f5dfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ent_agg = aggregate_df(ent_df)\n",
    "len(df_ent_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1bde060",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=df_ent_agg['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a115c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skills_2.txt', 'w') as f:\n",
    "    for skill in skills:\n",
    "        print(skill, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56a349fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sql                              skills;                              the\n",
      "  a                                  data                             analyses \n",
      "  drug; device                       statistics                       skills;\n",
      "  ms                               requirements                         excel\n",
      "database                           product                              sas\n",
      "tensor flow                          the posix;unix;linux ecosystem sql-  data vendor landscape●\n",
      "  iso                              -data (hadoop) concepts            data visualisation experience \n",
      "  all the                            microst fice (                     sql (window functions;\n",
      "architecture principles posix;unix;linux ecosystem   data modelling; data cleansing;    excel;\n",
      "  r;python data                    insights bonus points:               core data modelling; manipulation\n",
      "  data technologies (sme)            excel;                             sql;no\n",
      "  the linux;posix ecosystem        business background.good           delivery \n",
      "power bi;                            all                              -depth \n",
      "architecture                       sound                                data modelling tactics; techniques;\n",
      "  dev ops constructs                 enterprise architecture; optimization techniques  enterprise data warehousing; data integration\n",
      "  fice                               programming languages;             systems integration\n",
      "  the linux environment             with bank colleagues              ; python ; matlab \n",
      "machine learning techniques          data analysis; data monitoring;    hpc storage (fc; sas) principles; file systems (nfs; lustre; beeg fs; zfs;\n",
      "  mlops concepts                     the enterprise architecture frameworks (togaf)ai concepts \n",
      "data                               degree                               indexes; triggers; functions;\n",
      "  the data management capability assessment model in data management                domain \n",
      "  apis; microservices; cloud; dev ops etc.an individual  courts                             database; data warehouse\n",
      "  snowflake                          the capital                       about encryption communication skills troubleshooting activities (\n",
      "insight; data protection ficer     judiciary pensions                 matter \n",
      "project management·                  api design -                       building processes\n",
      "  c                                  consumer; retail; enterprise channel  data capture; update; usage\n",
      "  data management concepts;          data mining                        data patterns\n",
      "  database design principles         enterprise data platforms          message queuing; stream processing;\n",
      "  ms fice applications;              process documentation (miro; slack; quip box; keynote  python (\n",
      "  system optimisation; system implementation; data management; data  the codebase                       web app development;\n",
      "  web app security practices mongo db  web frameworks                    for the end-\n",
      " with adobe experience cloud solutions experience-date market                       .)· \n",
      ": sql; python; data infrastructure; sql etl;elt :·                                 computer science concepts domain \n",
      "dev ops background;experience      isolation levels                   plan. \n",
      "practice;                          sql server                         standards exception management skills; \n",
      "streaming data;                    stware development methods         version control \n",
      "working sql                          a range                            aml typologies ;\n",
      "  any another programming language   any j ee application server writing  application security; authentication\n",
      "  automation processes team player; ability  business processes                 cnns; machine vision\n",
      "  computer science fundamentals      consulting;project management techniques;methods ability  containers (docker; kubernetes).\n",
      "  data governance practices; business  data science                       data vendor landscape\n",
      "  data visualization tools           database backup procedures; recovery systems;  database engineering\n",
      "  database systems (oracle; sql server; postgre sql;  databases                          delivery\n",
      "  etl;elt processes                  experimentation principles         google analytics architecture\n",
      "  ia c (infrastructure               java script libraries              json structures\n",
      "  kotlin;                            machine learning methods           microst windows (administration; installation; service management;\n",
      "  r studio; python                   sas; r                             scripting languages;\n",
      "  security systems administration    terraform *                        the relationship\n",
      "  the technology landscape           the uk                             these techniques\n",
      "  type script the ability            uk;                                unity\n",
      "  unix;linux                         vendor landscape;                 :graph qlmicro\n",
      " across the firms                   around finance; machine learning   in capital markets -\n",
      " in design principles; data structures in java script;                    in specialist areas;\n",
      " on ci;cd pipelines                 on cloud services                  through self-\n",
      " with peers                        -depth specialty                   -end campaign management experience \n",
      "-end experience                    apis.java script –                 applications \n",
      "bi tooling                         collection                         data science perspective expert \n",
      "data transformation pipelines      data visualisation platform.strong sql data;risk committees. \n",
      "development                        experience ;                       experience building \n",
      "feature engineering experience     hackathons;                        industry \n",
      "information;                       must!                              qualifications \n",
      "requirements programming skills –  risk                               snowflake snowpipes);good python \n",
      "sql skills                         sql.·                              staff.in depth \n"
     ]
    }
   ],
   "source": [
    "n_max=10000\n",
    "for a,b,c in zip(skills[:n_max:3],skills[1:n_max:3],skills[2:n_max:3]):\n",
    "     print('{:<35}{:<35}{:<}'.format(a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7e489f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = pd.read_csv (r'skills_2.txt')\n",
    "read_file.to_csv (r'skills_2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4b388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
