{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d127874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Visualization     \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# do not print warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4379caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"job_offers_original_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b8500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns and keeps only job_title and job_description\n",
    "df = df[['job_title','company_name', 'job_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d9a8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(?<![A-Z\\W])  what precedes is a word character EXCEPT for capital letters\n",
    "#(?=[A-Z])     and what follows is a capital letter\n",
    "def sepa(text): \n",
    "    text = re.sub(r'(?<![A-Z\\W])(?=[A-Z])', ' ', text)\n",
    "    return(text)\n",
    "\n",
    "df['job_description']=df['job_description'].apply(sepa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78b3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"job_description\"] = df[\"job_description\"].str.lower() #lowercase\n",
    "df['job_description'] = df['job_description'].str.replace('\\d+', '') # remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01e5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_description'] = df['job_description'].str.replace('/', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035a3f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" do you want to work on the most pressing problem of our generation?we're building the infrastructure for the net zero transition, and we're looking for brilliant engineers, designers, and data scientists who want to help define a low carbon future.decarbonizing the economy requires a granular, real-time view of where emissions come from and how they might be reduced. we build software to automate the carbon footprinting of supply chains. banks, traders, and manufacturers use our product to tame the complexity of international supply networks, identify the most carbon-intensive parts, and find greener alternatives. we were part of the y combinator summer  batch and have secured backing from the uk government's innovation arm, innovate uk, the nat west accelerator and the london business school incubator.to join carbon chain, you'll be a keen technologist who loves to learn from others. our company is made up of  passionate people with expertise ranging from oil refining to deep learning. between us we've run amazon's european supply chain, built just eat's corporate meal delivery platform, and monitored industrial emissions with satellites for al gore. we've got mbas and ph ds but we know that there's a lot we don't know, and we're hoping you can help fill that gap.what will you be responsible for at carbon chain?as the world wakes up to the reality of climate change and the need to decarbonize, there's a pressing need to understand the carbon intensity of every activity in the economy. your job as data engineer is to work with our data scientists to organize, automate, and deploy the data pipelines we need to provide that understanding.we're a small team of versatile technologists and we don't believe in a siloed approach. our data engineers sit side by side with software engineers and designers, making sure that we have the data we need to provide the experience our customers want. you'll be deeply embedded in the product team, with your work being deployed to clients every week. you'll work closely with our domain experts, and have the chance to present to clients if that's something that excites you.you can expect to have:ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python. we deploy our work in a variety of ways depending upon the challenge, from lambdas to docker containers. our etl is run in dagster, which is a friendlier and more modern version of airflow. you'd be joining an experienced team but you'd be the first data engineer, so you'd have lots of scope to define best practices and choose your tools.we're interested in talking to people with dev ops and classical software engineering experience, as well as those coming from data science who have a passion for scaling etl systems.our only must-haves are possessing a hunger to solve business challenges using technology, the ability to build close relationships with your team, and the right to work in the uk.which tools, technologies, and processes will you work with?data processing with the standard scientific stack (pandas, numpy, scipy) and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will.object-oriented code forms the bulk of our codebase.postgre sql and dynamo db managed databases form the persistence layer - you'll learn to navigate document and relational databases and appreciate the values in both worlds.infrastructure automation is owned by the whole team, helping to spread the dev ops mentality across the whole technology department (and beyond).you don't need to be a pro at all of these skills to apply for the role, but we'd love to hear about any relevant knowledge and experiences that you have in these areas.what we require from applicants right to work in the uk and willingness to come to london office + days a week+ years of commercial data engeering, data science, or software engineering experience a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we're offering competitive salary + generous equity package flexible working hours - we encourage regular breaks and being afk (away from keyboard) to support your wellbeing flexible working location (we like to meet in the office couple of times every week)Â£ annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays, and frequent pub trips pakt coffee and snacks of your choice in the office days holiday + bank holidays we're striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology, be that in terms of gender, race, or professional background.if you think your skills and experience match what we're looking for and you'd like to join a carbon tech industry unicorn, please get in touch!\\n      \\n\\n        show more\\n\\n        \\n\\n\\n        show less\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1d83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some common words that lead to the skills are experience, you'll have, responsible, are looking for, ability to,\n",
    "#knowledge of, understanding of\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2d8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c173767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the ads into a list\n",
    "desc=list(df.job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73801bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise Spacy model\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75c875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_terms(terms, texts):\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for sentence in set([tok.sent for tok in doc if tok.lower_ in terms]):\n",
    "            text = sentence.text.strip() # break docs into sentence\n",
    "            markup = re.sub(fr'(?i)\\b({\"|\".join(terms)})\\b', r'<strong>\\1</strong>', text)\n",
    "            display(HTML(markup))\n",
    "            print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b574235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "you'd be joining an experienced team but you'd be the first data engineer, so you'd have lots of scope to define best practices and choose your tools.we're interested in talking to people with dev ops and classical software engineering experience, as well as those coming from data science who have a passion for scaling etl systems.our only must-haves are possessing a hunger to solve business challenges using technology, the <strong>ability</strong> to build close relationships with your team, and the right to work in the uk.which tools, technologies, and processes will you work with?data processing with the standard scientific stack (pandas, numpy, scipy) and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will.object-oriented code forms the bulk of our codebase.postgre sql and dynamo db managed databases form the persistence layer - you'll learn to navigate document and relational databases and appreciate the values in both worlds.infrastructure automation is owned by the whole team, helping to spread the dev ops mentality across the whole technology department (and beyond).you don't need to be a pro at all of these skills to apply for the role, but we'd love to hear about any relevant knowledge and experiences that you have in these areas.what we require from applicants right to work in the uk and willingness to come to london office + days a week+ years of commercial data engeering, data science, or software engineering experience a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we're offering competitive salary + generous equity package flexible working hours - we encourage regular breaks and being afk (away from keyboard) to support your wellbeing flexible working location (we like to meet in the office couple of times every week)Â£ annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays, and frequent pub trips pakt coffee and snacks of your choice in the office days holiday + bank holidays we're striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology, be that in terms of gender, race, or professional background.if"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "you'll work closely with our domain experts, and have the chance to present to clients if that's something that excites you.you can expect to have:ownership of your projects an independent path to production the <strong>ability</strong> to make real changes with tangible business value our data science stack is predominantly python."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "while our teams have commonly used python, sql, java, go, ruby, java script and c#, we expect engineers to be agnostic to technologyâvaluing their <strong>ability</strong> to be adaptable and learn quickly.as part of our engineering team, you will be responsible for building large-scale data management and analytics platforms."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "has the data been offloaded from the producers?has the data stream been processed?is the data available for consumption?designing, developing, and maintaining software while ensuring that data integrity is preserved throughout the data stream.working closely with data infrastructure engineers to support implementation of tools that facilitate data-driven inference on vast volumes of data.supporting the development of autonomy components by clearly illustrating (via quantitative analysis) where we are as a company.contributing to processes that show,share metrics inferred from the data (e.g. performance in autonomy, number of revokes per km, etc.) and whether the metrics being computed are sufficient.investigating what extra information can be extracted from the current raw data stream.identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy.requirements what you need to succeed:proficiency in python software development skills (tools such as debugger, ide and profilers).proficiency with data science libraries such as pandas, numpy, scipy, bokeh, etc..familiarity with git.the <strong>ability</strong> to maintain high-quality code documentation.experience with performing mathematically robust statistical analysis, data modelling, and predictive analytics.the <strong>ability</strong> to interact with databases (e.g. sql).ui skills for interacting with dashboards constructed using grafana, apache superset, etc the <strong>ability</strong> to clearly translate numbers into meaningful and informative diagrams.extra kudos if you have:software development skills in c++.familiarity with robotics.an understanding of machine learning.an understanding of measuring operations and processes.an understanding of data streaming processes.our culture at oxbotica, our diverse and inclusive culture fuels our growth."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving, and in demand, industry.some of the things weâd like you to do:assist the development of technical solutions, in line with specifications, that collect, store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures, helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies, ensuring your work incorporates industry best practice monitor automated jobs, troubleshooting data issues as-and-when they arise support other members of the team responsible for âlast mileâ transformation and visualization of data within google data studio reports and dashboards provide hands-on support to users of reporting solutions, helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings, presenting your solutions and providing updates on your work.support the development strong working relationships with third-party data providers that we rely on for access to necessary data a bit about yourself:required previous experience working with data and technology experience with programming and,or statistical languages (e.g. sql, python)analytically minded, enabling you to understand and overcome technically complex challenges, and to tell compelling stories with data strong organizational skills and attention to detail, including the <strong>ability</strong> to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills, ensuring your thoughts and needs are heard and understood an <strong>ability</strong> to demonstrate a passion for the digital marketing ecosystem, and an understanding of the role that data plays within it delivers best results when working in a team environment, and an <strong>ability</strong> to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl, particularly useful if done using google cloud platform, airflow, dbt etc.experience with digital marketing platforms and the data they generate, in particular google marketing platform, facebook, twitter etc. knowledge of their apiâs a plus.an understanding of how data is tracked and exchanged in the process of digital advertising (e.g. role of ad servers and other third-party tech vendors)experience using or building reports with business intelligence software, ideally google data studio work experience within a marketing organization, preferably at a media agency or related company (e.g. publisher, ad tech, client marketing org)what you can expect from essence:essenceâs mission is to make advertising more valuable to the world."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "to always represent the team professionally â both internally and externally key stakeholders:senior director digital channels, director of analytics & insight, data protection officer knowledge & experience essential:programming experience in java ( preferable) and python experience with testing frameworks, junit, mockito, etc.comfortable familiarity working with large data sets good sql skills strong problem-solving skills experience writing batch etls on large datasets using various sources (e.g. sql servers, rest apis, json files)experience with build tools, such as gradle, maven, sbtfamiliarity with osx or linux environment (shell scripting, basic system administration etc).experience using source control,collaboration tools such as git hub, bitbucket or git lab.familiarity with collaboration and communication tools such as jira, confluence, slack etc.desirable:bsc or higher level degree in computer science, stem subject or a similar field of study experience with cloud-based engineering platforms, e.g. gcp, aws, azure experience with apache beam experience with streaming data experience with dag based workflow management systems, ideally air flow competencies, skills & attributes essential:<strong>ability</strong> to quickly learn and employ new technologies and methodologies."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "the ideal candidate combines strong business acumen, experience in data pipelines, databases and development best-practices along with a passion for tech.key accountabilities working with big data: tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of teamâs ecosystem: dozens of in-house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language, <strong>ability</strong> to write complex queries data warehousing and database basic architecture principles posix,unix,linux ecosystem knowledge experience with php,python or desire to learn them we appreciate result-oriented work style, flexibility in choosing tools and technical approaches nice to have experience with exasol and,or snowflake databases good knowledge of sql (window functions, common table expressions, complex grouping etc.)google cloud platform familiarity basic hadoop familiarity (hdfs,hive)about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a 'can-do' attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your teamâs advantage\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    }
   ],
   "source": [
    "highlight_terms(['ability'], desc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07dbb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'LOWER': 'ability'},{'LOWER':'to'},{\"POS\": {\"IN\": ['ADJ',\"AUX\", \"VERB\", \"NOUN\",'ADP','ADV']}, \"OP\": \"*\"},\n",
    "          ]\n",
    "matcher.add('ability_adp', [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dd82367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extraction(examples, *extractors):\n",
    "    seen = set()\n",
    "    for doc in nlp.pipe(examples):\n",
    "        doc.ents = filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)])\n",
    "        for tok in doc:\n",
    "            if tok.lower_ == 'ability':\n",
    "                sentence = tok.sent\n",
    "                if sentence.text in seen:\n",
    "                    continue\n",
    "                seen.update([sentence.text])\n",
    "                if not sentence.ents:\n",
    "                    doc.ents = list(doc.ents) + [Span(doc, tok.i, tok.i+1, 'MISSING')]\n",
    "                displacy.render(sentence, style='ent', options = {'colors': {'MISSING': 'pink',\n",
    "                                                                            'ABILITY': 'lightgreen'}})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cb77eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">you'll work closely with our domain experts, and have the chance to present to clients if that's something that excites you.you can expect to have:ownership of your projects an independent path to production the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to make real changes with tangible business value\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " our data science stack is predominantly python. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">you'd be joining an experienced team but you'd be the first data engineer, so you'd have lots of scope to define best practices and choose your tools.we're interested in talking to people with dev ops and classical software engineering experience, as well as those coming from data science who have a passion for scaling etl systems.our only must-haves are possessing a hunger to solve business challenges using technology, the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to build close relationships with\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " your team, and the right to work in the uk.which tools, technologies, and processes will you work with?data processing with the standard scientific stack (pandas, numpy, scipy) and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will.object-oriented code forms the bulk of our codebase.postgre sql and dynamo db managed databases form the persistence layer - you'll learn to navigate document and relational databases and appreciate the values in both worlds.infrastructure automation is owned by the whole team, helping to spread the dev ops mentality across the whole technology department (and beyond).you don't need to be a pro at all of these skills to apply for the role, but we'd love to hear about any relevant knowledge and experiences that you have in these areas.what we require from applicants right to work in the uk and willingness to come to london office + days a week+ years of commercial data engeering, data science, or software engineering experience a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we're offering competitive salary + generous equity package flexible working hours - we encourage regular breaks and being afk (away from keyboard) to support your wellbeing flexible working location (we like to meet in the office couple of times every week)Â£ annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays, and frequent pub trips pakt coffee and snacks of your choice in the office days holiday + bank holidays we're striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology, be that in terms of gender, race, or professional background.if </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">while our teams have commonly used python, sql, java, go, ruby, java script and c#, we expect engineers to be agnostic to technologyâvaluing their \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to be adaptable\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " and learn quickly.as part of our engineering team, you will be responsible for building large-scale data management and analytics platforms. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">has the data been offloaded from the producers?has the data stream been processed?is the data available for consumption?designing, developing, and maintaining software while ensuring that data integrity is preserved throughout the data stream.working closely with data infrastructure engineers to support implementation of tools that facilitate data-driven inference on vast volumes of data.supporting the development of autonomy components by clearly illustrating (via quantitative analysis) where we are as a company.contributing to processes that show,share metrics inferred from the data (e.g. performance in autonomy, number of revokes per km, etc.) and whether the metrics being computed are sufficient.investigating what extra information can be extracted from the current raw data stream.identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy.requirements what you need to succeed:proficiency in python software development skills (tools such as debugger, ide and profilers).proficiency with data science libraries such as pandas, numpy, scipy, bokeh, etc..familiarity with git.the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to maintain high\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       "-quality code documentation.experience with performing mathematically robust statistical analysis, data modelling, and predictive analytics.the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to interact with databases\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " (e.g. sql).ui skills for interacting with dashboards constructed using grafana, apache superset, etc the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to clearly translate numbers into meaningful\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " and informative diagrams.extra kudos if you have:software development skills in c++.familiarity with robotics.an understanding of machine learning.an understanding of measuring operations and processes.an understanding of data streaming processes.our culture at oxbotica, our diverse and inclusive culture fuels our growth. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving, and in demand, industry.some of the things weâd like you to do:assist the development of technical solutions, in line with specifications, that collect, store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures, helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies, ensuring your work incorporates industry best practice monitor automated jobs, troubleshooting data issues as-and-when they arise support other members of the team responsible for âlast mileâ transformation and visualization of data within google data studio reports and dashboards provide hands-on support to users of reporting solutions, helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings, presenting your solutions and providing updates on your work.support the development strong working relationships with third-party data providers that we rely on for access to necessary data a bit about yourself:required previous experience working with data and technology experience with programming and,or statistical languages (e.g. sql, python)analytically minded, enabling you to understand and overcome technically complex challenges, and to tell compelling stories with data strong organizational skills and attention to detail, including the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to manage multiple tasks in\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " a fairly autonomous way strong spoken and written communication skills, ensuring your thoughts and needs are heard and understood an \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to demonstrate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " a passion for the digital marketing ecosystem, and an understanding of the role that data plays within it delivers best results when working in a team environment, and an \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " and etl, particularly useful if done using google cloud platform, airflow, dbt etc.experience with digital marketing platforms and the data they generate, in particular google marketing platform, facebook, twitter etc. knowledge of their apiâs a plus.an understanding of how data is tracked and exchanged in the process of digital advertising (e.g. role of ad servers and other third-party tech vendors)experience using or building reports with business intelligence software, ideally google data studio work experience within a marketing organization, preferably at a media agency or related company (e.g. publisher, ad tech, client marketing org)what you can expect from essence:essenceâs mission is to make advertising more valuable to the world. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">to always represent the team professionally â both internally and externally key stakeholders:senior director digital channels, director of analytics &amp; insight, data protection officer knowledge &amp; experience essential:programming experience in java ( preferable) and python experience with testing frameworks, junit, mockito, etc.comfortable familiarity working with large data sets good sql skills strong problem-solving skills experience writing batch etls on large datasets using various sources (e.g. sql servers, rest apis, json files)experience with build tools, such as gradle, maven, sbtfamiliarity with osx or linux environment (shell scripting, basic system administration etc).experience using source control,collaboration tools such as git hub, bitbucket or git lab.familiarity with collaboration and communication tools such as jira, confluence, slack etc.desirable:bsc or higher level degree in computer science, stem subject or a similar field of study experience with cloud-based engineering platforms, e.g. gcp, aws, azure experience with apache beam experience with streaming data experience with dag based workflow management systems, ideally air flow competencies, skills &amp; attributes essential:\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to quickly learn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " and employ new technologies and methodologies. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">the ideal candidate combines strong business acumen, experience in data pipelines, databases and development best-practices along with a passion for tech.key accountabilities working with big data: tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of teamâs ecosystem: dozens of in-house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ability to write complex queries data warehousing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ability_adp</span>\n",
       "</mark>\n",
       " and database basic architecture principles posix,unix,linux ecosystem knowledge experience with php,python or desire to learn them we appreciate result-oriented work style, flexibility in choosing tools and technical approaches nice to have experience with exasol and,or snowflake databases good knowledge of sql (window functions, common table expressions, complex grouping etc.)google cloud platform familiarity basic hadoop familiarity (hdfs,hive)about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a 'can-do' attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your teamâs advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:10], matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "949ad614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extractions(examples, *extractors):\n",
    "    # Could use context instead of enumerate\n",
    "    for idx, doc in enumerate(nlp.pipe(examples, batch_size=100, disable=['ner'])):\n",
    "        for ent in filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)]):\n",
    "            sent = ent.root.sent\n",
    "            yield ent.text, idx, ent.start, ent.end, ent.label_, sent.start, sent.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3a7239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ability to make real changes with tangible business value',\n",
       "  0,\n",
       "  415,\n",
       "  424,\n",
       "  'ability_adp',\n",
       "  376,\n",
       "  432),\n",
       " ('ability to build close relationships with',\n",
       "  0,\n",
       "  547,\n",
       "  553,\n",
       "  'ability_adp',\n",
       "  470,\n",
       "  903),\n",
       " ('ability to be adaptable', 3, 145, 149, 'ability_adp', 112, 173),\n",
       " ('ability to maintain high', 4, 569, 573, 'ability_adp', 390, 662),\n",
       " ('ability to interact with databases', 4, 590, 595, 'ability_adp', 390, 662),\n",
       " ('ability to clearly translate numbers into meaningful',\n",
       "  4,\n",
       "  612,\n",
       "  619,\n",
       "  'ability_adp',\n",
       "  390,\n",
       "  662),\n",
       " ('ability to manage multiple tasks in', 5, 543, 549, 'ability_adp', 244, 750),\n",
       " ('ability to demonstrate', 5, 570, 573, 'ability_adp', 244, 750),\n",
       " ('ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines',\n",
       "  5,\n",
       "  604,\n",
       "  622,\n",
       "  'ability_adp',\n",
       "  244,\n",
       "  750),\n",
       " ('ability to quickly learn', 6, 431, 435, 'ability_adp', 235, 442),\n",
       " ('ability to write complex queries data warehousing',\n",
       "  9,\n",
       "  442,\n",
       "  449,\n",
       "  'ability_adp',\n",
       "  314,\n",
       "  580)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_extractions(desc[:10], matcher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a31b660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put it in a dataframe and join with the job metadata\n",
    "def extract_df(*extractors, n_max=None, **kwargs):\n",
    "    if n_max is None:\n",
    "        n_max = len(df)\n",
    "    ent_df = pd.DataFrame(list(get_extractions(df[:n_max].job_description, *extractors)),\n",
    "                          columns=['text', 'docidx', 'start', 'end', 'label', 'sent_start', 'sent_end'])\n",
    "    return ent_df.merge(df, how='left', left_on='docidx', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4d9caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 4 Âµs, total: 8 Âµs\n",
      "Wall time: 11 Âµs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docidx</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_start</th>\n",
       "      <th>sent_end</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ability to make real changes with tangible bus...</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>424</td>\n",
       "      <td>ability_adp</td>\n",
       "      <td>376</td>\n",
       "      <td>432</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>CarbonChain</td>\n",
       "      <td>do you want to work on the most pressing prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ability to build close relationships with</td>\n",
       "      <td>0</td>\n",
       "      <td>547</td>\n",
       "      <td>553</td>\n",
       "      <td>ability_adp</td>\n",
       "      <td>470</td>\n",
       "      <td>903</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>CarbonChain</td>\n",
       "      <td>do you want to work on the most pressing prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ability to be adaptable</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>ability_adp</td>\n",
       "      <td>112</td>\n",
       "      <td>173</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>The Data Shed</td>\n",
       "      <td>description at the data shed, we've been work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ability to maintain high</td>\n",
       "      <td>4</td>\n",
       "      <td>569</td>\n",
       "      <td>573</td>\n",
       "      <td>ability_adp</td>\n",
       "      <td>390</td>\n",
       "      <td>662</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Oxbotica</td>\n",
       "      <td>are you a data engineer interested in or curr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ability to interact with databases</td>\n",
       "      <td>4</td>\n",
       "      <td>590</td>\n",
       "      <td>595</td>\n",
       "      <td>ability_adp</td>\n",
       "      <td>390</td>\n",
       "      <td>662</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Oxbotica</td>\n",
       "      <td>are you a data engineer interested in or curr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  docidx  start  end  \\\n",
       "0  ability to make real changes with tangible bus...       0    415  424   \n",
       "1          ability to build close relationships with       0    547  553   \n",
       "2                            ability to be adaptable       3    145  149   \n",
       "3                           ability to maintain high       4    569  573   \n",
       "4                 ability to interact with databases       4    590  595   \n",
       "\n",
       "         label  sent_start  sent_end      job_title   company_name  \\\n",
       "0  ability_adp         376       432  Data Engineer    CarbonChain   \n",
       "1  ability_adp         470       903  Data Engineer    CarbonChain   \n",
       "2  ability_adp         112       173  Data Engineer  The Data Shed   \n",
       "3  ability_adp         390       662  Data Engineer       Oxbotica   \n",
       "4  ability_adp         390       662  Data Engineer       Oxbotica   \n",
       "\n",
       "                                     job_description  \n",
       "0   do you want to work on the most pressing prob...  \n",
       "1   do you want to work on the most pressing prob...  \n",
       "2   description at the data shed, we've been work...  \n",
       "3   are you a data engineer interested in or curr...  \n",
       "4   are you a data engineer interested in or curr...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "ent_df = extract_df(matcher, n_max=1000)\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac75523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the counts of different texts.\n",
    "\n",
    "#It's more significant if it happens accross multiple Advertisers/Sources.\n",
    "\n",
    "def aggregate_df(df, col=['text']):\n",
    "    return (df\n",
    "            .groupby(col)\n",
    "            .agg(n_company=('company_name', 'nunique'),\n",
    "                 n=('job_title', 'count'))\n",
    "            .reset_index()\n",
    "            .sort_values(['n_company','n'], ascending=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f24e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dab5da92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ability to understand</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>ability to work in</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>ability to identify</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>ability to manage</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ability to lead</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ability to drive</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ability to collect</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ability to process</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>ability to work</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ability to work under pressure</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  n_company   n\n",
       "209           ability to understand          5  26\n",
       "230              ability to work in          5  18\n",
       "109             ability to identify          4  17\n",
       "139               ability to manage          4  14\n",
       "126                 ability to lead          4   6\n",
       "79                 ability to drive          3  26\n",
       "35               ability to collect          3  16\n",
       "170              ability to process          3  13\n",
       "218                 ability to work          3   9\n",
       "240  ability to work under pressure          3   8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb15560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showent(docidx, start, end, label, sent_start, sent_end, **kwargs):\n",
    "    # We don't need to parse it, so just make_doc\n",
    "    doc = nlp.make_doc(desc[docidx])\n",
    "    doc.ents = [Span(doc, start, end, label)]\n",
    "    sent = doc[sent_start:sent_end]\n",
    "    displacy.render(sent, style='ent')\n",
    "    \n",
    "def showent_df(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        showent(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c1d33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df['text'] = ent_df['text'].str.replace('ability to', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b42b2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>understand</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>work in</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>identify</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>manage</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>lead</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>work on challenging issues</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>work productively</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>work remotely abroad for up to</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>work through</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>write content for crm campaigns hands on expe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  n_company   n\n",
       "209                                         understand          5  26\n",
       "230                                            work in          5  18\n",
       "109                                           identify          4  17\n",
       "139                                             manage          4  14\n",
       "126                                               lead          4   6\n",
       "..                                                 ...        ...  ..\n",
       "234                         work on challenging issues          1   1\n",
       "235                                  work productively          1   1\n",
       "236                     work remotely abroad for up to          1   1\n",
       "238                                       work through          1   1\n",
       "247   write content for crm campaigns hands on expe...          1   1\n",
       "\n",
       "[251 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88f5dfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ent_agg = aggregate_df(ent_df)\n",
    "len(df_ent_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8490cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=df_ent_agg['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a115c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skills_1.txt', 'w') as f:\n",
    "    for skill in skills:\n",
    "        print(skill, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a349fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " understand                         work in                            identify\n",
      " manage                             lead                               drive\n",
      " collect                            process                            work\n",
      " work under pressure                interpret unstructured data        think beyond raw data\n",
      " discuss                            establish                          operate within multidisciplinary diverse teams\n",
      " understand complex problems        work autonomously in               engage\n",
      " deal with                          engage with                        think in\n",
      " thrive in                          work independently                 work with\n",
      " influence                          operate with                       think strategically about business\n",
      " build well                         deploy machine learning models on cloud platforms such as aws write quality unit tests demonstrate\n",
      " deliver accurate                   design                             get involved nationally\n",
      " smoothly explain concepts          work collaboratively with senior stakeholders define\n",
      " deliver value                      focus on promptly addressing customer needs ability make\n",
      " analyse                            derive insights out of             innovate\n",
      " interpret fairly                   relate to customer business problems review\n",
      " try different approaches           weave                              work cross functionally\n",
      " work with data using               work with tight deadlines          write complex queries data warehousing\n",
      " write programs                     fault                              gather\n",
      " prioritise workload                see to                             soundly structure problems\n",
      " work with multidiscipline teams    adapt to different clients         be proactive\n",
      " build strong personal relationships create insightful visualisations   manage multiple priorities\n",
      " motivate                           work collaboratively               work effectively in\n",
      " analyse complex data               demonstrate understanding of       execute operations\n",
      " pitch                              analyse complex data sets          clearly explain complex concepts in simple language\n",
      " combine data from different sources communicate well on                communicate with\n",
      " document requirements              drive change using influence       explain sophisticated solutions to\n",
      " flex                               initiate                           integrate\n",
      " move out of comfort                prioritise                         solve complex technical problems at pace\n",
      " understand business problems       understand complex concepts        understand complex situations\n",
      " work across time                   work effectively on multiple projects write python code\n",
      " apply analytical thinking          deliver significant impact quickly;proven ability establish strong\n",
      " explain                            explain complex topics in simple terms frame business problems\n",
      " travel to client sites is          work to                            build close relationships with\n",
      " create results                     demonstrate                        make real changes with tangible business value\n",
      " manage multiple tasks in           partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines build\n",
      " clearly translate numbers into meaningful communicate effectively            drive product\n",
      " formulate                          interact with databases            launch\n",
      " lead change                        maintain high                      negotiate\n",
      " present specific work to stakeholders ability protect                            quickly learn\n",
      " translate business strategy into system understand complex processes       adapt to fast pace changing circumstances in order\n",
      " advocate cxos on                   anticipate problems                apply\n",
      " articulate complex ideas in        be consulted with data movements for data performance capture\n",
      " carry out analysis independently   communicate effectively verbally   communicate effectively with senior management\n",
      " dig into complex databases         extract actionable insights from data experience building efficient queries influence others\n",
      " interpret technical terms in layman terms in addition to manage time efficiently            provide platform roadmap along with short\n",
      " shape                              share in                           solve problems works effectively under pressure ability\n",
      " work effectively with employees at work flexible hours in             work independently excellent interpersonal skills\n",
      " work swiftly                       write                             \n",
      " actively keep up to date with security developments adjust style to                    articulate complex concepts\n",
      " assess                             assimilate information from        assist\n",
      " be                                 be adaptable                       be product driven\n",
      " become                             build data platforms using         build strong relationships with application teams\n",
      " challenge poor operational practices excellent written championing standardisation        communicate complex solutions to clients\n",
      " communicate in writing             communicate technical details to   communicate to\n",
      " communicate well with leadership teams communicate with diverse stakeholders confidently work on production systems\n",
      " connect                            control temperature                convey complex data in\n",
      " convey security complexities to audiences of various technical abilities convey technical information to    convince colleagues\n",
      " create                             create business reports ability    create informative presentations ability\n",
      " deliver change                     deliver outputs in                 design service oriented\n",
      " display                            distill                            draw insights from noisy data\n",
      " drive business results with        drive development forward          effectively interact\n",
      " enable performance through hands on leadership establish new approaches           explore\n",
      " express                            extrapolate                        follow\n",
      " grow                               guide                              identify red flags\n",
      " include various nfrs               interpret                          interpret data\n",
      " investigate                        keep                               lead by example on project strategies\n",
      " lead individuals                   learn by joining                   learn new information quickly\n",
      " leverage diverse industry experiences listen                             maintain\n",
      " make sense of                      manage budgets for                 manage clients expectations\n",
      " manage internal                    model business problems into data structures within sql server awareness of etl concepts motivate others pension\n",
      " multi-task                         multitask for various components of complex projects mastered knowledge offer employees\n",
      " operate in interdisciplinary teams comprised of product organise                           perform exploratory data analysis\n",
      " perform in                         present                            present complex analysis clearly\n",
      " prioritize demonstrated project management capabilities team player problem solve                      problem solve understanding of data visualisation tools\n",
      " propose bespoke                    reason mathematically              represent\n",
      " resolve conflict.able              right level conversations.demonstrated ability run\n",
      " see long term business outcomes.collaborative seek help                          self\n",
      " serve                              simplify complex data              solve complex technical problems\n",
      " solve problems quickly             take up                            team up with other architecture specialists\n",
      " tell stories                       think creatively                   think strategically about infrastructure good team player\n",
      " turn client requests into problems understand analysis                visualize algorithmic structures\n",
      " work autonomously                  work effectively across internal   work independently with little supervision.confident manner\n",
      " work on challenging issues         work productively                  work remotely abroad for up to\n"
     ]
    }
   ],
   "source": [
    "n_max=10000\n",
    "for a,b,c in zip(skills[:n_max:3],skills[1:n_max:3],skills[2:n_max:3]):\n",
    "     print('{:<35}{:<35}{:<}'.format(a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e489f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = pd.read_csv (r'skills_1.txt')\n",
    "read_file.to_csv (r'skills_1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63df7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
