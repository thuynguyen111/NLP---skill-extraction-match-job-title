{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4130f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Visualization     \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# do not print warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052add6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"job_offers_original_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352f2e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns and keeps only job_title and job_description\n",
    "df = df[['job_title','company_name', 'job_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a841ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(?<![A-Z\\W])  what precedes is a word character EXCEPT for capital letters\n",
    "#(?=[A-Z])     and what follows is a capital letter\n",
    "def sepa(text): \n",
    "    text = re.sub(r'(?<![A-Z\\W])(?=[A-Z])', ' ', text)\n",
    "    return(text)\n",
    "\n",
    "df['job_description']=df['job_description'].apply(sepa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36a0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate word and number\n",
    "def sepa2(text): \n",
    "    text = re.sub(r'(?<=\\d)(?=[^\\d\\s])|(?<=[^\\d\\s])(?=\\d)', ' ', text, 0)\n",
    "    return(text)\n",
    "\n",
    "df['job_description']=df['job_description'].apply(sepa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a2a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_description'] = df['job_description'].str.replace('[^\\w\\s]', ' ') # remove punctuation \n",
    "df[\"job_description\"] = df[\"job_description\"].str.lower() #lowercase \n",
    "df['job_description'] = df['job_description'].str.replace('\\d+', '') # remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b2192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Do you want to work on the most pressing problem of our generation?We're building the infrastructure for the net zero transition, and we're looking for brilliant engineers, designers, and data scientists who want to help define a low carbon future.Decarbonizing the economy requires a granular, real-time view of where emissions come from and how they might be reduced. We build software to automate the carbon footprinting of supply chains. Banks, traders, and manufacturers use our product to tame the complexity of international supply networks, identify the most carbon-intensive parts, and find greener alternatives. We were part of the Y Combinator Summer 2020 batch and have secured backing from the UK government's innovation arm, InnovateUK, the NatWest accelerator and the London Business School Incubator.To join Carbon Chain, you'll be a keen technologist who loves to learn from others. Our company is made up of 10 passionate people with expertise ranging from oil refining to deep learning. Between us we've run Amazon's European supply chain, built JustEat's corporate meal delivery platform, and monitored industrial emissions with satellites for Al Gore. We've got MBAs and PhDs but we know that there's a lot we don't know, and we're hoping you can help fill that gap.What will you be responsible for at Carbon Chain?As the world wakes up to the reality of climate change and the need to decarbonize, there's a pressing need to understand the carbon intensity of every activity in the economy. Your job as Data Engineer is to work with our Data Scientists to organize, automate, and deploy the data pipelines we need to provide that understanding.We're a small team of versatile technologists and we don't believe in a siloed approach. Our data engineers sit side by side with software engineers and designers, making sure that we have the data we need to provide the experience our customers want. You'll be deeply embedded in the product team, with your work being deployed to clients every week. You'll work closely with our domain experts, and have the chance to present to clients if that's something that excites you.You can expect to have:Ownership of your projectsAn independent path to productionThe ability to make real changes with tangible business valueOur data science stack is predominantly Python. We deploy our work in a variety of ways depending upon the challenge, from Lambdas to Docker containers. Our ETL is run in Dagster, which is a friendlier and more modern version of Airflow. You'd be joining an experienced team but you'd be the first data engineer, so you'd have lots of scope to define best practices and choose your tools.We're interested in talking to people with DevOps and classical software engineering experience, as well as those coming from Data Science who have a passion for scaling ETL systems.Our only must-haves are possessing a hunger to solve business challenges using technology, the ability to build close relationships with your team, and the right to work in the UK.Which tools, technologies, and processes will you work with?Data processing with the standard scientific stack (Pandas, Numpy, Scipy) and beyondAutomation with Dagster and Github ActionsDeployment via GCPContainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will.Object-oriented code forms the bulk of our codebase.PostgreSQL and DynamoDB managed databases form the persistence layer - you'll learn to navigate document and relational databases and appreciate the values in both worlds.Infrastructure automation is owned by the whole team, helping to spread the DevOps mentality across the whole technology department (and beyond).You don't need to be a pro at all of these skills to apply for the role, but we'd love to hear about any relevant knowledge and experiences that you have in these areas.What we require from applicantsRight to work in the UK and willingness to come to London office 2+ days a week1+ years of commercial Data Engeering, Data Science, or Software Engineering experienceA passion for environmental issuesA demonstrated interest in building products and collaborating tightly with scientists and engineersThe grit and energy to work in an early stage startupWhat we're offeringCompetitive salary + generous equity packageFlexible working hours - we encourage regular breaks and being AFK (away from keyboard) to support your wellbeingFlexible working location (we like to meet in the office couple of times every week)Â£1000 annual development allowance for you to spend on developing your current skills and learning new thingsTech equipment of your choiceTeam lunch on Wednesdays, and frequent pub tripsPakt coffee and snacks of your choice in the office28 days holiday + bank holidays We're striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology, be that in terms of gender, race, or professional background.If you think your skills and experience match what we're looking for and you'd like to join a Carbon Tech industry unicorn, please get in touch!\\n      \\n\\n        Show more\\n\\n        \\n\\n\\n        Show less\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebb6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stop words\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "# add more words to remove\n",
    "remove_key_w = ['show','le','please','feel','free','opportunity'\n",
    "               ,'company','paid','bonus','applicant','candidate','application','interview','day','annual','leave',\n",
    "               'plus','holiday']\n",
    "\n",
    "def clean_text(text):\n",
    "    le=WordNetLemmatizer()\n",
    "    word_tokens=word_tokenize(text)\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "    cleaned_text= [t for t in tokens if t not in remove_key_w]\n",
    "    cleaned_docs= \" \".join(cleaned_text)\n",
    "    return cleaned_docs\n",
    "\n",
    "df['desc_tokenized']=df['job_description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ddd5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Bi-grams \n",
    "\n",
    "def plot_top_ngrams_barchart(text, n=2):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = TfidfVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:20]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:20]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xlabel(\"Bi-gram Frequency\")\n",
    "    plt.ylabel(\"Top 20 bi-grams mentioned in Job Description\")\n",
    "    sns.barplot(x=y,y=x)\n",
    "\n",
    "\n",
    "plot_top_ngrams_barchart(df['job_description'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08e98fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tri-grams \n",
    "\n",
    "def plot_top_ngrams_barchart(text, n=3):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = TfidfVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:20]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:20]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xlabel(\"Tri-gram Frequency\")\n",
    "    plt.ylabel(\"Top 20 tri-grams mentioned in Job descriptions\")\n",
    "    sns.barplot(x=y,y=x)\n",
    "\n",
    "\n",
    "plot_top_ngrams_barchart(df['job_description'],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcdff42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Uni-grams \n",
    "\n",
    "def plot_top_ngrams_barchart(text, n=1):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = TfidfVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:20]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:20]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xlabel(\"Tri-gram Frequency\")\n",
    "    plt.ylabel(\"Top 20 tri-grams mentioned in Job descriptions\")\n",
    "    sns.barplot(x=y,y=x)\n",
    "\n",
    "\n",
    "plot_top_ngrams_barchart(df['desc_tokenized'],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06628fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some common words that lead to the skills are experience, you'll have, responsible, are looking for, ability to,\n",
    "#knowledge of, understanding of\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5a2ac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.4.1-cp38-cp38-macosx_10_9_x86_64.whl (6.5 MB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 6.5 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.3)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 42 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.4-cp38-cp38-macosx_10_9_x86_64.whl (457 kB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 457 kB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 181 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.7-cp38-cp38-macosx_10_9_x86_64.whl (107 kB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 107 kB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (60.9.3)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4\n",
      "  Downloading pydantic-1.9.2-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 2.9 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.8-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Downloading spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.23.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.27.1)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.1-cp38-cp38-macosx_10_9_x86_64.whl (752 kB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 752 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 58 kB 8.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.1-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.10.0,>=0.7.8\n",
      "  Downloading blis-0.9.1-cp38-cp38-macosx_10_9_x86_64.whl (5.3 MB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 5.3 MB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: catalogue, srsly, pydantic, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 6.1.0\n",
      "    Uninstalling smart-open-6.1.0:\n",
      "      Successfully uninstalled smart-open-6.1.0\n",
      "Successfully installed blis-0.9.1 catalogue-2.0.8 confection-0.0.1 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.8 pathy-0.6.2 preshed-3.0.7 pydantic-1.9.2 smart-open-5.2.1 spacy-3.4.1 spacy-legacy-3.0.10 spacy-loggers-1.0.3 srsly-2.4.4 thinc-8.1.1 typer-0.4.2 wasabi-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f967ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6227f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the ads into a list\n",
    "desc=list(df.job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25761ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |ââââââââââââââââââââââââââââââââ| 12.8 MB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.59.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.23.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (60.9.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.1)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in /opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.4.0\n",
      "\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f14d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise Spacy model\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f7ffd",
   "metadata": {},
   "source": [
    "# Extracting from job ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70163b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_terms(terms, texts):\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for sentence in set([tok.sent for tok in doc if tok.lower_ in terms]):\n",
    "            text = sentence.text.strip() # break docs into sentence\n",
    "            markup = re.sub(fr'(?i)\\b({\"|\".join(terms)})\\b', r'<strong>\\1</strong>', text)\n",
    "            display(HTML(markup))\n",
    "            print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf23841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "db managed databases form the persistence layer   you ll learn to navigate document and relational databases and appreciate the values in both worlds infrastructure automation is owned by the whole team  helping to spread the dev ops mentality across the whole technology department  and beyond  you don t need to be a pro at all of these skills to apply for the role  but we d love to hear about any relevant knowledge and experiences that you have in these areas what we require from applicants right to work in the uk and willingness to come to london office   days a week  years of commercial data engeering  data science  or software engineering <strong>experience</strong> a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we re offering competitive salary   generous equity package flexible working hours   we encourage regular breaks and being afk  away from keyboard  to support your wellbeing flexible working location  we like to meet in the office couple of times every week   annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays  and frequent pub trips pakt coffee and snacks of your choice in the office days holiday   bank holidays we re striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology  be that in terms of gender  race  or professional background if you think your skills and <strong>experience</strong> match what we re looking for and you d like to join a carbon tech industry unicorn  please get in touch \n",
       "      \n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "and we don t believe in a siloed approach  our data engineers sit side by side with software engineers and designers  making sure that we have the data we need to provide the <strong>experience</strong> our customers want  you ll be deeply embedded in the product team  with your work being deployed to clients every week  you ll work closely with our domain experts  and have the chance to present to clients if that s something that excites you you can expect to have ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python  we deploy our work in a variety of ways depending upon the challenge  from lambdas to docker containers  our etl is run in dagster  which is a friendlier and more modern version of airflow  you d be joining an experienced team but you d be the first data engineer  so you d have lots of scope to define best practices and choose your tools we re interested in talking to people with dev ops and classical software engineering <strong>experience</strong>  as well as those coming from data science who have a passion for scaling etl systems our only must haves are possessing a hunger to solve business challenges using technology  the ability to build close relationships with your team  and the right to work in the uk which tools  technologies  and processes will you work with data processing with the standard scientific stack  pandas  numpy  scipy  and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will object oriented code forms the bulk of our codebase postgre sql and dynamo"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of the company s data platform <strong>experience</strong> we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development hadoop ecosystem <strong>experience</strong> java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of the company s data platform <strong>experience</strong> we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development hadoop ecosystem <strong>experience</strong> java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   <strong>experience</strong> at the data shed we are looking for <strong>experience</strong> in the following things  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "csv  json and xml broader knowledge of it   e g   security and networking working in an agile environment test driven development and or behaviour driven development continuous integration and continuous deployment  ci cd optional <strong>experience</strong> the following is optional  but highly desirable <strong>experience</strong>  building reliable data pipelines <strong>experience</strong> of exploratory data analysis <strong>experience</strong> of visualising data working with metrics  segments  aggregates  features requirements of the role maintain a broad knowledge of the technology landscape helping the data shed provide market leading assist our clients in enterprise scale projects utilising best practice development methodologies  well tested spend as much time on tests and security as on writing code work with a team of like minded  high calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that s broken  fix it  that includes the coffee machine benefits we have a variety of benefits including free access to an eap program  an auto enrolment pension scheme  a life assurance scheme  regular socials and a company performance based bonus and for any additional needs you have  we have a friendly and knowledgeable hr team to support you location we have a leeds hq and a flexible hybrid working policy  travel to client sites may be required from time to time  subject to business need ready to be a shedder we also celebrate each other s differences and encourage each other to explore new ways of thinking  the result is a diverse set of individuals who come together to create a multi talented  cohesive organisation  if you think that your uniqueness could make us even stronger  then please get in touch \n",
       "      \n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "are you a data engineer interested in or currently working with autonomous vehicle technology  if so  we are looking to talk with you about your python software development skills  including exposure to working with vast volumes of data  in line with the opportunity to join oxbotica as a data engineer at oxbotica  we re fuelled by a bold purpose  to make the earth move from passenger shuttles to industrial vehicles  from congested city streets to mines  our industry leading autonomy software platform enables any vehicle to operate itself safely  securely and efficiently  we call it universal autonomy  it is changing how people and goods move we are a world class team guided by a shared vision to bring the benefits of autonomy to our customers and users  using our skills  <strong>experience</strong> and diversity  we are solving the most exciting and important technological challenges of our times  and creating a safer and more sustainable future for people and our planet our    and growing  team members in the uk and canada are building  scaling and commercialising our universal autonomy software to serve immediate market and deployment opportunities we re seeking bold  creative  hyper skilled people to join us  come create the future of autonomy with us at oxbotica  become an  oxbot  the systems metrics team is a cross functional team that is responsible for ensuring transparent evaluation of our technology and operations  clarity and transparency is enabled through concrete evaluation criteria  well defined evaluation processes  and visibility of results we develop and maintain metrics that are visible to all internally within the company  as well as metrics that are visible to the company s external partners during demonstrations  po c deployments  and product releases  we utilise metrics to perform inference to further the improvement of our technology and operations  while striving to maximise coverage of metrics across all aspects of the company as a data engineer your day will include  but will not be limited to  using our python based metrics extraction tools that operate on data produced by oxbotica vehicles working closely with the data that the oxbotica fleet and processes produce and consume where is the data  has the data been offloaded from the producers has the data stream been processed is the data available for consumption designing  developing  and maintaining software while ensuring that data integrity is preserved throughout the data stream working closely with data infrastructure engineers to support implementation of tools that facilitate data driven inference on vast volumes of data supporting the development of autonomy components by clearly illustrating  via quantitative analysis  where we are as a company contributing to processes that show share metrics inferred from the data  e g  performance in autonomy  number of revokes per km  etc   and whether the metrics being computed are sufficient investigating what extra information can be extracted from the current raw data stream identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy requirements what you need to succeed proficiency in python software development skills  tools such as debugger  ide and profilers  proficiency with data science libraries such as pandas  numpy  scipy  bokeh  etc  familiarity with git the ability to maintain high quality code documentation <strong>experience</strong> with performing mathematically robust statistical analysis  data modelling  and predictive analytics the ability to interact with databases  e g  sql  ui skills for interacting with dashboards constructed using grafana  apache superset  etc the ability to clearly translate numbers into meaningful and informative diagrams extra kudos if you have software development skills in c   familiarity with robotics an understanding of machine learning an understanding of measuring operations and processes an understanding of data streaming processes our culture at oxbotica  our diverse and inclusive culture fuels our growth  we celebrate individuality  foster an environment in which trust and respect flourish  and believe that innovation thrives when powered by different perspectives  experiences and ideas  our purpose  values and principles anchor us as we grow learn more about our culture here benefits competitive salary company share programme hybrid and or flexible work arrangements an outstanding    flexible benefits including private medical insurance  critical illness coverage  life assurance  eap  group income protection funded relocation support fully funded visa sponsorship if required a salary exchange pension plan days annual leave plus bank holidays a pet friendly office environment safe assigned spaces for team members with individual and diverse needs\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "not only does that mean running and maintaining the solution that already exists  but also continually improving it to incorporate new data sources  and to derive new insights  to support ever evolving business demands as data engineer your primary responsibility will be to support a senior data engineer to create and maintain underlying data infrastructure that provides the wider team with the data they need to provide timely  accurate and meaningful deliverables   reporting  in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving  and in demand  industry some of the things we d like you to do assist the development of technical solutions  in line with specifications  that collect  store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures  helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies  ensuring your work incorporates industry best practice monitor automated jobs  troubleshooting data issues as and when they arise support other members of the team responsible for  last mile  transformation and visualization of data within google data studio reports and dashboards provide hands on support to users of reporting solutions  helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings  presenting your solutions and providing updates on your work support the development strong working relationships with third party data providers that we rely on for access to necessary data a bit about yourself required previous <strong>experience</strong> working with data and technology <strong>experience</strong> with programming and or statistical languages  e g  sql  python analytically minded  enabling you to understand and overcome technically complex challenges  and to tell compelling stories with data strong organizational skills and attention to detail  including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills  ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem  and an understanding of the role that data plays within it delivers best results when working in a team environment  and an ability to partner effectively with people of varying degrees of technical capability desirable <strong>experience</strong> building underlying data pipelines and etl  particularly useful if done using google cloud platform  airflow  dbt etc <strong>experience</strong> with digital marketing platforms and the data they generate  in particular google marketing platform  facebook  twitter etc  knowledge of their api s a plus an understanding of how data is tracked and exchanged in the process of digital advertising  e g  role of ad servers and other third party tech vendors <strong>experience</strong> using or building reports with business intelligence software  ideally google data studio work <strong>experience</strong> within a marketing organization  preferably at a media agency or related company  e g  publisher  ad tech  client marketing org what you can expect from essence essence s mission is to make advertising more valuable to the world  we do this by employing the world s very best talent to solve some of the toughest challenges of today s digital marketing landscape  it s important that we hire people whose values reflect those of our own  genuine  results focused  daring and insightful  as an essence employee  we promise you a workplace that invests in your career  cares for you and is fun and engaging  we believe these factors create a workplace where you can be yourself and do amazing work \n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "job summary square enix has an internal cloud based platform  sgv   which provides our analytics   insight team and other groups across the business with a single data lake pooling game telemetry  sales information  marketing data  web analytics and other information duties include building  optimising and enhancing data acquisition pipelines working with client teams to ensure robust capture of high quality data supporting data analysts and other users of the data via with technical assistance this position requires a driven and talented person that can help the team progress requirements key deliverables build and test new functionality for existing pipelines alongside expanding the scope of data sources supported by the platform ensure the data engineering team deliver on requests from client teams to agreed specification and timelines ensure open and regular communication with other stakeholders as to the status of their projects work to ensure data engineering team is capable to deliver against responsibilities  ensure data is robust and of high quality provide data access and querying support to users both within the team and across the business have a good understanding of the scope  potential and limitations of the datasets maintained by the data engineering team  remaining alert to any opportunity to further employ our data to benefit the business evangelise the use of customer data to better understand our customers across the organisation  to always represent the team professionally   both internally and externally key stakeholders senior director digital channels  director of analytics   insight  data protection officer knowledge   <strong>experience</strong> essential programming <strong>experience</strong> in java   preferable  and python <strong>experience</strong> with testing frameworks  junit  mockito  etc comfortable familiarity working with large data sets good sql skills strong problem solving skills <strong>experience</strong> writing batch etls on large datasets using various sources  e g  sql servers  rest apis  json files <strong>experience</strong> with build tools  such as gradle  maven  sbtfamiliarity with osx or linux environment  shell scripting  basic system administration etc  <strong>experience</strong> using source control collaboration tools such as git hub  bitbucket or git lab familiarity with collaboration and communication tools such as jira  confluence  slack etc desirable bsc or higher level degree in computer science  stem subject or a similar field of study <strong>experience</strong> with cloud based engineering platforms  e g  gcp  aws  azure <strong>experience</strong> with apache beam <strong>experience</strong> with streaming data <strong>experience</strong> with dag based workflow management systems  ideally air flow competencies  skills   attributes essential ability to quickly learn and employ new technologies and methodologies  strong documentation skills ability to articulate and present ideas and information with ease and clarity ability to work on own initiative and as part of team other interest in technology  ambition to drive self development excellent attention to detail follower of industry trends and developments our goal at square enix is to hire  retain  develop and promote the best talent  regardless of age  gender  race  religious  belief  sexual orientation or physical ability our pledge to d iat square enix we believe in the importance of being a diverse and global company  and we stand firmly together against any forms of injustice  intolerance  harassment or discrimination  in our effort to create a truly diverse workforce  we pledge to continue to raise awareness in every step of the employee <strong>experience</strong>  from recruitment to promotions to ensure equal opportunities for all  one of our goals is to champion diversity in games and at work and work together to inspire real change learning and education around d"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "carwow is looking for a data engineer to join our platform engineering team on a full time basis in either a fully remote or hybrid capacity about carwow buying or selling a car shouldn t be difficult  that s why here at carwow we are on a mission to change the way people buy  sell or use a car by creating the world s best online car marketplace  we re not all petrolheads   just a highly driven  excuse the pun  scale up with over  carwowers in the uk  germany  spain and portugal  since starting our journey in   we ve grown to become one of the most trusted comparison sites with over  million users and a trustpilot rating of    we are also very proud to be backed by some of europe s most respected technology  marketplace and automotive investors about the role this year we re investing heavily in the continued growth of our analytics infrastructure and automotive pricing tribe and part of this growth has seen data engineering become its own entity  we are looking for someone to join the team and play a key role designing and building the data systems we use to make data driven decisions across the business and deliver great products   experiences to our customers you ll work closely with our data science and analytics teams in exploring and implementing ways to improve our current data systems whilst supporting with stand alone projects across each of our analytics verticals  we ll make sure you re supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout  requirements must have  sql  python  data infrastructure  sql etl elt knowledge  <strong>experience</strong> with dags to manage script dependencies with tools like airflow nice to have  snowflake  airflow  terraform  ruby  data visualisation tool  e g  looker  tableau  power bi   amplitude  dev ops  redshift  awsplease note  we know that no candidate will be the perfect match for all we ve listed in this posting"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "london  uk   full time a fantastic opportunity to be involved in end to end data management solutions for cutting edge advanced analytics and data science deployments who we are  at kearney analytics  we believe in the power of connected data  we are laser focused on helping organizations harness the interconnectedness of digital  data and decision making  we are problem solvers and builders focused on helping our clients win with data  our culture is cool and innovative  our environment is casual and conducive to collaboration and problem solving  we take our work seriously but not ourselves  it s the perfect balance of freedom and accountability  if you want to be part of something great   join us what can we offer competitive salary vitality private health care life insurance  accident insurance and long term disability insurance bupa annual wellness check  rrp      pension flu jab  eye test travelcard interest free loan annual performance bonus flexible working days annual leave   bank holidays about you you have <strong>experience</strong> with client projects and in handling vast amounts of data   working on database design and development  data integration and ingestion  designing etl architectures using a variety of etl tools and techniques  you are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled analytics team  play a key role on projects from a data engineering perspective  working with our architects and clients to model the data landscape  obtain data extracts and define secure data exchange approaches  this is a fantastic opportunity to be involved in end to end data management for cutting edge advanced analytics and data science job specifics plan and execute secure  best practice data integration strategies and approaches acquire  ingest  and process data from multiple sources and systems into big data platforms create and manage data environments in the cloud collaborate with our business analysts and data scientists to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models managing and monitoring the data integration process have a strong understanding of information security principles to ensure compliant handling and management of client data qualifications and required skills <strong>experience</strong> and desire to work with open source and branded open source frameworks <strong>experience</strong> working on projects within the cloud ideally aws  azure  gcp or snowflake <strong>experience</strong> working on agile delivery projects and a consulting setting  often working on different and multiple projects at the same time <strong>experience</strong> working with a variety of etl elt tools like matillion  talend  streamsets preferred strong development background with <strong>experience</strong> in at least one scripting  object oriented or functional programming language  etc   python  java  scala  c   r  bashexperience working with version control tools such as git hub  bitbucket data warehousing <strong>experience</strong>  building operational etl data pipelines across a number of sources  and constructing relational and dimensional data models excellent interpersonal skills when interacting with clients in a clear  timely  and professional manner desirable skills <strong>experience</strong> on client facing projects  including working in close knit teams <strong>experience</strong> working in a cloud architecture with data lake <strong>experience</strong> and interest in big data technologies  spark   no sql dbs <strong>experience</strong> or familiarity with real time ingestion and streaming frameworks is a plus a deep personal motivation to always produce outstanding work for your clients and colleagues excel in team collaboration and working with others from diverse skill sets and background <strong>experience</strong> leading a team and driving them go deliver results solution delivery\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "she her hers  he him his  they them theirs  etc  introbumble is looking for an etl data engineer to participate in the development of the data collecting and data processing framework  services and tools for the cross functional data platform department  concretely  this means implementing  deploying and maintaining large scale data pipelines as well as internal data tools that help bumble provide a safe and engaging <strong>experience</strong> for our users and improve the way bumble operates with millions of images and messages exchanged on our platform every day  there is a wealth of opportunity to make a real difference in this role and help people to find love all over the world  the ideal candidate combines strong business acumen  <strong>experience</strong> in data pipelines  databases and development best practices along with a passion for tech key accountabilities working with big data  tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team s ecosystem  dozens of in house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language  ability to write complex queries data warehousing and database basic architecture principles posix unix linux ecosystem knowledge <strong>experience</strong> with php python or desire to learn them we appreciate result oriented work style  flexibility in choosing tools and technical approaches nice to have <strong>experience</strong> with exasol and or snowflake databases good knowledge of sql  window functions  common table expressions  complex grouping etc  google cloud platform familiarity basic hadoop familiarity  hdfs hive about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a  can do  attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team s advantage\n",
       "\n",
       "\n",
       "        show more\n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "        show less"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    }
   ],
   "source": [
    "highlight_terms(['experience'], desc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018523d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'POS': 'NOUN', 'OP': '+'}, {'LOWER': 'experience'}]\n",
    "matcher.add('experience_noun', [pattern])\n",
    "\n",
    "pattern = [{'LOWER': 'experience'}, {'POS': 'ADP'}, {'POS': {'IN': ('DET', 'NOUN', 'PROPN')}, 'OP': '+'}]\n",
    "matcher.add('experience_adp', [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "660a0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extraction(examples, *extractors):\n",
    "    seen = set()\n",
    "    for doc in nlp.pipe(examples):\n",
    "        doc.ents = filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)])\n",
    "        for tok in doc:\n",
    "            if tok.lower_ == 'experience':\n",
    "                sentence = tok.sent\n",
    "                if sentence.text in seen:\n",
    "                    continue\n",
    "                seen.update([sentence.text])\n",
    "                if not sentence.ents:\n",
    "                    doc.ents = list(doc.ents) + [Span(doc, tok.i, tok.i+1, 'MISSING')]\n",
    "                displacy.render(sentence, style='ent', options = {'colors': {'MISSING': 'pink',\n",
    "                                                                            'EXPERIENCE': 'lightgreen'}})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb4d10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">and we don t believe in a siloed approach  our data engineers sit side by side with software engineers and designers  making sure that we have the data we need to provide the experience our customers want  you ll be deeply embedded in the product team  with your work being deployed to clients every week  you ll work closely with our domain experts  and have the chance to present to clients if that s something that excites you you can expect to have ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python  we deploy our work in a variety of ways depending upon the challenge  from lambdas to docker containers  our etl is run in dagster  which is a friendlier and more modern version of airflow  you d be joining an experienced team but you d be the first data engineer  so you d have lots of scope to define best practices and choose your tools we re interested in talking to people with dev ops and classical \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    software engineering experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       "  as well as those coming from data science who have a passion for scaling etl systems our only must haves are possessing a hunger to solve business challenges using technology  the ability to build close relationships with your team  and the right to work in the uk which tools  technologies  and processes will you work with data processing with the standard scientific stack  pandas  numpy  scipy  and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will object oriented code forms the bulk of our codebase postgre sql and dynamo </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">db managed databases form the persistence layer   you ll learn to navigate document and relational databases and appreciate the values in both worlds infrastructure automation is owned by the whole team  helping to spread the dev ops mentality across the whole technology department  and beyond  you don t need to be a pro at all of these skills to apply for the role  but we d love to hear about any relevant knowledge and experiences that you have in these areas what we require from applicants right to work in the uk and willingness to come to london office   days a week  years of commercial data engeering  data science  or \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    software engineering experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we re offering competitive salary   generous equity package flexible working hours   we encourage regular breaks and being afk  away from keyboard  to support your wellbeing flexible working location  we like to meet in the office couple of times every week   annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays  and frequent pub trips pakt coffee and snacks of your choice in the office days holiday   bank holidays we re striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology  be that in terms of gender  race  or professional background if you think your skills and experience match what we re looking for and you d like to join a carbon tech industry unicorn  please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of the company s \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data platform experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hadoop ecosystem experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience at the data shed\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " we are looking for \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in the\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " following things  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">csv  json and xml broader knowledge of it   e g   security and networking working in an agile environment test driven development and or behaviour driven development continuous integration and continuous deployment  ci cd optional experience the following is optional  but highly desirable experience  building reliable \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data pipelines experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " of exploratory \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data analysis experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " of visualising data working with metrics  segments  aggregates  features requirements of the role maintain a broad knowledge of the technology landscape helping the data shed provide market leading assist our clients in enterprise scale projects utilising best practice development methodologies  well tested spend as much time on tests and security as on writing code work with a team of like minded  high calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that s broken  fix it  that includes the coffee machine benefits we have a variety of benefits including free access to an eap program  an auto enrolment pension scheme  a life assurance scheme  regular socials and a company performance based bonus and for any additional needs you have  we have a friendly and knowledgeable hr team to support you location we have a leeds hq and a flexible hybrid working policy  travel to client sites may be required from time to time  subject to business need ready to be a shedder we also celebrate each other s differences and encourage each other to explore new ways of thinking  the result is a diverse set of individuals who come together to create a multi talented  cohesive organisation  if you think that your uniqueness could make us even stronger  then please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">are you a data engineer interested in or currently working with autonomous vehicle technology  if so  we are looking to talk with you about your python software development skills  including exposure to working with vast volumes of data  in line with the opportunity to join oxbotica as a data engineer at oxbotica  we re fuelled by a bold purpose  to make the earth move from passenger shuttles to industrial vehicles  from congested city streets to mines  our industry leading autonomy software platform enables any vehicle to operate itself safely  securely and efficiently  we call it universal autonomy  it is changing how people and goods move we are a world class team guided by a shared vision to bring the benefits of autonomy to our customers and users  using our skills  experience and diversity  we are solving the most exciting and important technological challenges of our times  and creating a safer and more sustainable future for people and our planet our    and growing  team members in the uk and canada are building  scaling and commercialising our universal autonomy software to serve immediate market and deployment opportunities we re seeking bold  creative  hyper skilled people to join us  come create the future of autonomy with us at oxbotica  become an  oxbot  the systems metrics team is a cross functional team that is responsible for ensuring transparent evaluation of our technology and operations  clarity and transparency is enabled through concrete evaluation criteria  well defined evaluation processes  and visibility of results we develop and maintain metrics that are visible to all internally within the company  as well as metrics that are visible to the company s external partners during demonstrations  po c deployments  and product releases  we utilise metrics to perform inference to further the improvement of our technology and operations  while striving to maximise coverage of metrics across all aspects of the company as a data engineer your day will include  but will not be limited to  using our python based metrics extraction tools that operate on data produced by oxbotica vehicles working closely with the data that the oxbotica fleet and processes produce and consume where is the data  has the data been offloaded from the producers has the data stream been processed is the data available for consumption designing  developing  and maintaining software while ensuring that data integrity is preserved throughout the data stream working closely with data infrastructure engineers to support implementation of tools that facilitate data driven inference on vast volumes of data supporting the development of autonomy components by clearly illustrating  via quantitative analysis  where we are as a company contributing to processes that show share metrics inferred from the data  e g  performance in autonomy  number of revokes per km  etc   and whether the metrics being computed are sufficient investigating what extra information can be extracted from the current raw data stream identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy requirements what you need to succeed proficiency in python software development skills  tools such as debugger  ide and profilers  proficiency with data science libraries such as pandas  numpy  scipy  bokeh  etc  familiarity with git the ability to maintain high \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    quality code documentation experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " with performing mathematically robust statistical analysis  data modelling  and predictive analytics the ability to interact with databases  e g  sql  ui skills for interacting with dashboards constructed using grafana  apache superset  etc the ability to clearly translate numbers into meaningful and informative diagrams extra kudos if you have software development skills in c   familiarity with robotics an understanding of machine learning an understanding of measuring operations and processes an understanding of data streaming processes our culture at oxbotica  our diverse and inclusive culture fuels our growth  we celebrate individuality  foster an environment in which trust and respect flourish  and believe that innovation thrives when powered by different perspectives  experiences and ideas  our purpose  values and principles anchor us as we grow learn more about our culture here benefits competitive salary company share programme hybrid and or flexible work arrangements an outstanding    flexible benefits including private medical insurance  critical illness coverage  life assurance  eap  group income protection funded relocation support fully funded visa sponsorship if required a salary exchange pension plan days annual leave plus bank holidays a pet friendly office environment safe assigned spaces for team members with individual and diverse needs</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">not only does that mean running and maintaining the solution that already exists  but also continually improving it to incorporate new data sources  and to derive new insights  to support ever evolving business demands as data engineer your primary responsibility will be to support a senior data engineer to create and maintain underlying data infrastructure that provides the wider team with the data they need to provide timely  accurate and meaningful deliverables   reporting  in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving  and in demand  industry some of the things we d like you to do assist the development of technical solutions  in line with specifications  that collect  store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures  helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies  ensuring your work incorporates industry best practice monitor automated jobs  troubleshooting data issues as and when they arise support other members of the team responsible for  last mile  transformation and visualization of data within google data studio reports and dashboards provide hands on support to users of reporting solutions  helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings  presenting your solutions and providing updates on your work support the development strong working relationships with third party data providers that we rely on for access to necessary data a bit about yourself required previous experience working with data and technology \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with programming\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " and or statistical languages  e g  sql  python analytically minded  enabling you to understand and overcome technically complex challenges  and to tell compelling stories with data strong organizational skills and attention to detail  including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills  ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem  and an understanding of the role that data plays within it delivers best results when working in a team environment  and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl  particularly useful if done using google cloud platform  airflow  dbt etc experience with digital marketing platforms and the data they generate  in particular google marketing platform  facebook  twitter etc  knowledge of their api s a plus an understanding of how data is tracked and exchanged in the process of digital advertising  e g  role of ad servers and other third \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    party tech vendors experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " using or building reports with business intelligence software  ideally google data studio work \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience within a marketing organization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       "  preferably at a media agency or related company  e g  publisher  ad tech  client marketing org what you can expect from essence essence s mission is to make advertising more valuable to the world  we do this by employing the world s very best talent to solve some of the toughest challenges of today s digital marketing landscape  it s important that we hire people whose values reflect those of our own  genuine  results focused  daring and insightful  as an essence employee  we promise you a workplace that invests in your career  cares for you and is fun and engaging  we believe these factors create a workplace where you can be yourself and do amazing work </br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job summary square enix has an internal cloud based platform  sgv   which provides our analytics   insight team and other groups across the business with a single data lake pooling game telemetry  sales information  marketing data  web analytics and other information duties include building  optimising and enhancing data acquisition pipelines working with client teams to ensure robust capture of high quality data supporting data analysts and other users of the data via with technical assistance this position requires a driven and talented person that can help the team progress requirements key deliverables build and test new functionality for existing pipelines alongside expanding the scope of data sources supported by the platform ensure the data engineering team deliver on requests from client teams to agreed specification and timelines ensure open and regular communication with other stakeholders as to the status of their projects work to ensure data engineering team is capable to deliver against responsibilities  ensure data is robust and of high quality provide data access and querying support to users both within the team and across the business have a good understanding of the scope  potential and limitations of the datasets maintained by the data engineering team  remaining alert to any opportunity to further employ our data to benefit the business evangelise the use of customer data to better understand our customers across the organisation  to always represent the team professionally   both internally and externally key stakeholders senior director digital channels  director of analytics   insight  data protection officer knowledge   experience essential programming \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in java\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       "   preferable  and python \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with testing frameworks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       "  junit  mockito  etc comfortable familiarity working with large data sets good sql skills strong problem solving \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    skills experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " writing batch etls on large datasets using various sources  e g  sql servers  rest apis  json files \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with build tools\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       "  such as gradle  maven  sbtfamiliarity with osx or linux environment  shell scripting  basic system administration etc  experience using source control collaboration tools such as git hub  bitbucket or git lab familiarity with collaboration and communication tools such as jira  confluence  slack etc desirable bsc or higher level degree in computer science  stem subject or a similar field of study \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with cloud\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " based engineering platforms  e g  gcp  aws  azure \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with apache beam experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    streaming data experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " with dag based workflow management systems  ideally air flow competencies  skills   attributes essential ability to quickly learn and employ new technologies and methodologies  strong documentation skills ability to articulate and present ideas and information with ease and clarity ability to work on own initiative and as part of team other interest in technology  ambition to drive self development excellent attention to detail follower of industry trends and developments our goal at square enix is to hire  retain  develop and promote the best talent  regardless of age  gender  race  religious  belief  sexual orientation or physical ability our pledge to d iat square enix we believe in the importance of being a diverse and global company  and we stand firmly together against any forms of injustice  intolerance  harassment or discrimination  in our effort to create a truly diverse workforce  we pledge to continue to raise awareness in every step of the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    employee experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       "  from recruitment to promotions to ensure equal opportunities for all  one of our goals is to champion diversity in games and at work and work together to inspire real change learning and education around d </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">carwow is looking for a data engineer to join our platform engineering team on a full time basis in either a fully remote or hybrid capacity about carwow buying or selling a car shouldn t be difficult  that s why here at carwow we are on a mission to change the way people buy  sell or use a car by creating the world s best online car marketplace  we re not all petrolheads   just a highly driven  excuse the pun  scale up with over  carwowers in the uk  germany  spain and portugal  since starting our journey in   we ve grown to become one of the most trusted comparison sites with over  million users and a trustpilot rating of    we are also very proud to be backed by some of europe s most respected technology  marketplace and automotive investors about the role this year we re investing heavily in the continued growth of our analytics infrastructure and automotive pricing tribe and part of this growth has seen data engineering become its own entity  we are looking for someone to join the team and play a key role designing and building the data systems we use to make data driven decisions across the business and deliver great products   experiences to our customers you ll work closely with our data science and analytics teams in exploring and implementing ways to improve our current data systems whilst supporting with stand alone projects across each of our analytics verticals  we ll make sure you re supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout  requirements must have  sql  python  data infrastructure  sql etl elt knowledge  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with dags\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " to manage script dependencies with tools like airflow nice to have  snowflake  airflow  terraform  ruby  data visualisation tool  e g  looker  tableau  power bi   amplitude  dev ops  redshift  awsplease note  we know that no candidate will be the perfect match for all we ve listed in this posting  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> london  uk   full time a fantastic opportunity to be involved in end to end data management solutions for cutting edge advanced analytics and data science deployments who we are  at kearney analytics  we believe in the power of connected data  we are laser focused on helping organizations harness the interconnectedness of digital  data and decision making  we are problem solvers and builders focused on helping our clients win with data  our culture is cool and innovative  our environment is casual and conducive to collaboration and problem solving  we take our work seriously but not ourselves  it s the perfect balance of freedom and accountability  if you want to be part of something great   join us what can we offer competitive salary vitality private health care life insurance  accident insurance and long term disability insurance bupa annual wellness check  rrp      pension flu jab  eye test travelcard interest free loan annual performance bonus flexible working days annual leave   bank holidays about you you have \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with client projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " and in handling vast amounts of data   working on database design and development  data integration and ingestion  designing etl architectures using a variety of etl tools and techniques  you are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled analytics team  play a key role on projects from a data engineering perspective  working with our architects and clients to model the data landscape  obtain data extracts and define secure data exchange approaches  this is a fantastic opportunity to be involved in end to end data management for cutting edge advanced analytics and data science job specifics plan and execute secure  best practice data integration strategies and approaches acquire  ingest  and process data from multiple sources and systems into big data platforms create and manage data environments in the cloud collaborate with our business analysts and data scientists to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models managing and monitoring the data integration process have a strong understanding of information security principles to ensure compliant handling and management of client data qualifications and required \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    skills experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " and desire to work with open source and branded open \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    source frameworks experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " working on projects within the cloud ideally aws  azure  gcp or \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    snowflake experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " working on agile delivery projects and a consulting setting  often working on different and multiple projects at the same \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    time experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " working with a variety of etl elt tools like matillion  talend  streamsets preferred strong development background with experience in at least one scripting  object oriented or functional programming language  etc   python  java  scala  c   r  bashexperience working with version control tools such as git hub  bitbucket data \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    warehousing experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       "  building operational etl data pipelines across a number of sources  and constructing relational and dimensional data models excellent interpersonal skills when interacting with clients in a clear  timely  and professional manner desirable skills \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience on client facing projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       "  including working in close knit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    teams experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " working in a cloud architecture with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data lake experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " and interest in big data technologies  spark   no sql dbs experience or familiarity with real time ingestion and streaming frameworks is a plus a deep personal motivation to always produce outstanding work for your clients and colleagues excel in team collaboration and working with others from diverse skill sets and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    background experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_noun</span>\n",
       "</mark>\n",
       " leading a team and driving them go deliver results solution delivery</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">she her hers  he him his  they them theirs  etc  introbumble is looking for an etl data engineer to participate in the development of the data collecting and data processing framework  services and tools for the cross functional data platform department  concretely  this means implementing  deploying and maintaining large scale data pipelines as well as internal data tools that help bumble provide a safe and engaging experience for our users and improve the way bumble operates with millions of images and messages exchanged on our platform every day  there is a wealth of opportunity to make a real difference in this role and help people to find love all over the world  the ideal candidate combines strong business acumen  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in data pipelines\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       "  databases and development best practices along with a passion for tech key accountabilities working with big data  tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team s ecosystem  dozens of in house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language  ability to write complex queries data warehousing and database basic architecture principles posix unix linux ecosystem knowledge \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with php python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " or desire to learn them we appreciate result oriented work style  flexibility in choosing tools and technical approaches nice to have \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience with exasol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " and or snowflake databases good knowledge of sql  window functions  common table expressions  complex grouping etc  google cloud platform familiarity basic hadoop familiarity  hdfs hive about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a  can do  attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team s advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:10], matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc1cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extractions(examples, *extractors):\n",
    "    # Could use context instead of enumerate\n",
    "    for idx, doc in enumerate(nlp.pipe(examples, batch_size=100, disable=['ner'])):\n",
    "        for ent in filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)]):\n",
    "            sent = ent.root.sent\n",
    "            yield ent.text, idx, ent.start, ent.end, ent.label_, sent.start, sent.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af63515d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('software engineering experience', 0, 519, 522, 'experience_noun', 322, 641),\n",
       " ('software engineering experience', 0, 760, 763, 'experience_noun', 641, 955),\n",
       " ('data platform experience', 1, 307, 310, 'experience_noun', 245, 471),\n",
       " ('hadoop ecosystem experience', 1, 361, 364, 'experience_noun', 245, 471),\n",
       " ('data platform experience', 2, 212, 215, 'experience_noun', 150, 376),\n",
       " ('hadoop ecosystem experience', 2, 266, 269, 'experience_noun', 150, 376),\n",
       " ('experience at the data shed', 3, 213, 218, 'experience_adp', 1, 258),\n",
       " ('experience in the', 3, 222, 225, 'experience_adp', 1, 258),\n",
       " ('data pipelines experience', 3, 365, 368, 'experience_noun', 314, 649),\n",
       " ('data analysis experience', 3, 370, 373, 'experience_noun', 314, 649),\n",
       " ('quality code documentation experience',\n",
       "  4,\n",
       "  586,\n",
       "  590,\n",
       "  'experience_noun',\n",
       "  1,\n",
       "  808),\n",
       " ('experience with programming', 5, 495, 498, 'experience_adp', 163, 848),\n",
       " ('party tech vendors experience', 5, 689, 693, 'experience_noun', 163, 848),\n",
       " ('experience within a marketing organization',\n",
       "  5,\n",
       "  707,\n",
       "  712,\n",
       "  'experience_adp',\n",
       "  163,\n",
       "  848),\n",
       " ('experience in java', 6, 268, 271, 'experience_adp', 0, 625),\n",
       " ('experience with testing frameworks', 6, 276, 280, 'experience_adp', 0, 625),\n",
       " ('skills experience', 6, 299, 301, 'experience_noun', 0, 625),\n",
       " ('experience with build tools', 6, 322, 326, 'experience_adp', 0, 625),\n",
       " ('experience with cloud', 6, 395, 398, 'experience_adp', 0, 625),\n",
       " ('experience with apache beam experience',\n",
       "  6,\n",
       "  410,\n",
       "  415,\n",
       "  'experience_adp',\n",
       "  0,\n",
       "  625),\n",
       " ('streaming data experience', 6, 416, 419, 'experience_noun', 0, 625),\n",
       " ('employee experience', 6, 586, 588, 'experience_noun', 0, 625),\n",
       " ('experience with dags', 7, 308, 311, 'experience_adp', 0, 374),\n",
       " ('experience with client projects', 8, 181, 185, 'experience_adp', 0, 633),\n",
       " ('skills experience', 8, 391, 393, 'experience_noun', 0, 633),\n",
       " ('source frameworks experience', 8, 403, 406, 'experience_noun', 0, 633),\n",
       " ('snowflake experience', 8, 419, 421, 'experience_noun', 0, 633),\n",
       " ('time experience', 8, 441, 443, 'experience_noun', 0, 633),\n",
       " ('warehousing experience', 8, 501, 503, 'experience_noun', 0, 633),\n",
       " ('experience on client facing projects',\n",
       "  8,\n",
       "  540,\n",
       "  545,\n",
       "  'experience_adp',\n",
       "  0,\n",
       "  633),\n",
       " ('teams experience', 8, 551, 553, 'experience_noun', 0, 633),\n",
       " ('data lake experience', 8, 559, 562, 'experience_noun', 0, 633),\n",
       " ('background experience', 8, 614, 616, 'experience_noun', 0, 633),\n",
       " ('experience in data pipelines', 9, 308, 312, 'experience_adp', 178, 561),\n",
       " ('experience with php python', 9, 444, 448, 'experience_adp', 178, 561),\n",
       " ('experience with exasol', 9, 470, 473, 'experience_adp', 178, 561)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_extractions(desc[:10], matcher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e6e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put it in a dataframe and join with the job metadata\n",
    "def extract_df(*extractors, n_max=None, **kwargs):\n",
    "    if n_max is None:\n",
    "        n_max = len(df)\n",
    "    ent_df = pd.DataFrame(list(get_extractions(df[:n_max].job_description, *extractors)),\n",
    "                          columns=['text', 'docidx', 'start', 'end', 'label', 'sent_start', 'sent_end'])\n",
    "    return ent_df.merge(df, how='left', left_on='docidx', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca99c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 1 Âµs, total: 5 Âµs\n",
      "Wall time: 20.3 Âµs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docidx</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_start</th>\n",
       "      <th>sent_end</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_description</th>\n",
       "      <th>desc_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>software engineering experience</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>522</td>\n",
       "      <td>experience_noun</td>\n",
       "      <td>322</td>\n",
       "      <td>641</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>CarbonChain</td>\n",
       "      <td>do you want to work on the most pressing prob...</td>\n",
       "      <td>want work pressing problem generation building...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>software engineering experience</td>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>763</td>\n",
       "      <td>experience_noun</td>\n",
       "      <td>641</td>\n",
       "      <td>955</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>CarbonChain</td>\n",
       "      <td>do you want to work on the most pressing prob...</td>\n",
       "      <td>want work pressing problem generation building...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data platform experience</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>310</td>\n",
       "      <td>experience_noun</td>\n",
       "      <td>245</td>\n",
       "      <td>471</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bumble</td>\n",
       "      <td>we strongly encourage people of colour  lesbi...</td>\n",
       "      <td>strongly encourage people colour lesbian bisex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hadoop ecosystem experience</td>\n",
       "      <td>1</td>\n",
       "      <td>361</td>\n",
       "      <td>364</td>\n",
       "      <td>experience_noun</td>\n",
       "      <td>245</td>\n",
       "      <td>471</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bumble</td>\n",
       "      <td>we strongly encourage people of colour  lesbi...</td>\n",
       "      <td>strongly encourage people colour lesbian bisex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data platform experience</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>215</td>\n",
       "      <td>experience_noun</td>\n",
       "      <td>150</td>\n",
       "      <td>376</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bumble</td>\n",
       "      <td>we strongly encourage people of colour  lesbi...</td>\n",
       "      <td>strongly encourage people colour lesbian bisex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text  docidx  start  end            label  \\\n",
       "0  software engineering experience       0    519  522  experience_noun   \n",
       "1  software engineering experience       0    760  763  experience_noun   \n",
       "2         data platform experience       1    307  310  experience_noun   \n",
       "3      hadoop ecosystem experience       1    361  364  experience_noun   \n",
       "4         data platform experience       2    212  215  experience_noun   \n",
       "\n",
       "   sent_start  sent_end      job_title company_name  \\\n",
       "0         322       641  Data Engineer  CarbonChain   \n",
       "1         641       955  Data Engineer  CarbonChain   \n",
       "2         245       471  Data Engineer       Bumble   \n",
       "3         245       471  Data Engineer       Bumble   \n",
       "4         150       376  Data Engineer       Bumble   \n",
       "\n",
       "                                     job_description  \\\n",
       "0   do you want to work on the most pressing prob...   \n",
       "1   do you want to work on the most pressing prob...   \n",
       "2   we strongly encourage people of colour  lesbi...   \n",
       "3   we strongly encourage people of colour  lesbi...   \n",
       "4   we strongly encourage people of colour  lesbi...   \n",
       "\n",
       "                                      desc_tokenized  \n",
       "0  want work pressing problem generation building...  \n",
       "1  want work pressing problem generation building...  \n",
       "2  strongly encourage people colour lesbian bisex...  \n",
       "3  strongly encourage people colour lesbian bisex...  \n",
       "4  strongly encourage people colour lesbian bisex...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "ent_df = extract_df(matcher, n_max=1000)\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51000ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the counts of different texts.\n",
    "\n",
    "#It's more significant if it happens accross multiple Advertisers/Sources.\n",
    "\n",
    "def aggregate_df(df, col=['text']):\n",
    "    return (df\n",
    "            .groupby(col)\n",
    "            .agg(n_company=('company_name', 'nunique'),\n",
    "                 n=('job_title', 'count'))\n",
    "            .reset_index()\n",
    "            .sort_values(['n_company','n'], ascending=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ad8cc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>experience in a</td>\n",
       "      <td>14</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>customer experience</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>skills experience</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>data experience</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>work experience</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>user experience</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>experience experience</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>industry experience</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>experience in data architecture</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>experience with python</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  n_company   n\n",
       "149                  experience in a         14  71\n",
       "58               customer experience         11  32\n",
       "506                skills experience         11  32\n",
       "66                   data experience         10  33\n",
       "559                  work experience          9  22\n",
       "551                  user experience          8  17\n",
       "142            experience experience          6  27\n",
       "422              industry experience          6   8\n",
       "189  experience in data architecture          4  25\n",
       "381           experience with python          4  19"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2461d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showent(docidx, start, end, label, sent_start, sent_end, **kwargs):\n",
    "    # We don't need to parse it, so just make_doc\n",
    "    doc = nlp.make_doc(desc[docidx])\n",
    "    doc.ents = [Span(doc, start, end, label)]\n",
    "    sent = doc[sent_start:sent_end]\n",
    "    displacy.render(sent, style='ent')\n",
    "    \n",
    "def showent_df(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        showent(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d8e40b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> sql data engineer     remote working from home role ideally residing within yorkshire  cumbria  lancashire  greater manchester  merseyside  derbyshire or midlands s area  full working from home role starting salary  c k    k  depending on experience    company benefits main skills  ms sql  t sql  programming languages  c   python  vb   ms access with advanced vba  ssrs report design  etl  ssis prefect azure  we have an exciting opportunity for a business focussed sql data engineer with a strong desire to build a career in data analysis  database design and application solutions  to join this long standing client of ours originally starting out in the rural parts of yorkshire  my client has established itself as a highly successful international financial retail consultancy that now services some of the world s largest organisations as a result of this huge business demand for their leading solutions  we are looking to help expand their sql data engineering team further the role the key element of this role is to ideally find an sql data engineer who loves big data  with also a good understanding of how retailing businesses work  in order to interpret the importance and value to the information being developed and processed towards the users  the candidate in order to be considered you will ideally have experience of the following     years of previous \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " similar sql data engineering role data analysis and conversion skills using microsoft sql server is essential an understanding of relational database design and build schema design  normalising data  indexing  query performance analysis ability to analyse complex data to identify patterns and detect anomalies assisting with etl design and implementation projects key skills sought microsoft sql server  sql server management studio  stored procedure writing etc t sqlprogramming languages  c   vb  python etc use of python to manipulate and import data front end application design in microsoft access with advanced vbassrs report design experience of etl automation advantageous but not essential  ssis prefect azure a self starter who can drive projects with minimal guidance meeting stakeholders to agree system requirements someone who is enthusiastic and eager to learn excellent verbal and written communication skills essential this is a fully home based role  working alongside their in house it  data engineering team located in the uk and off shore although this is a purely home based   remote working from home role  it would be highly beneficial to find a successful candidate who resides in either yorkshire  cumbria  lancashire  greater manchester  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> sql data engineer     remote working from home role ideally residing within yorkshire  cumbria  lancashire  greater manchester  merseyside  derbyshire or midlands s area  full working from home role starting salary  c k    k  depending on experience    company benefits main skills  ms sql  t sql  programming languages  c   python  vb   ms access with advanced vba  ssrs report design  etl  ssis prefect azure  we have an exciting opportunity for a business focussed sql data engineer with a strong desire to build a career in data analysis  database design and application solutions  to join this long standing client of ours originally starting out in the rural parts of yorkshire  my client has established itself as a highly successful international financial retail consultancy that now services some of the world s largest organisations as a result of this huge business demand for their leading solutions  we are looking to help expand their sql data engineering team further the role the key element of this role is to ideally find an sql data engineer who loves big data  with also a good understanding of how retailing businesses work  in order to interpret the importance and value to the information being developed and processed towards the users  the candidate in order to be considered you will ideally have experience of the following     years of previous \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " similar sql data engineering role data analysis and conversion skills using microsoft sql server is essential an understanding of relational database design and build schema design  normalising data  indexing  query performance analysis ability to analyse complex data to identify patterns and detect anomalies assisting with etl design and implementation projects key skills sought microsoft sql server  sql server management studio  stored procedure writing etc t sqlprogramming languages  c   vb  python etc use of python to manipulate and import data front end application design in microsoft access with advanced vbassrs report design experience of etl automation advantageous but not essential  ssis prefect azure a self starter who can drive projects with minimal guidance meeting stakeholders to agree system requirements someone who is enthusiastic and eager to learn excellent verbal and written communication skills essential this is a fully home based role  working alongside their in house it  data engineering team located in the uk and off shore although this is a purely home based   remote working from home role  it would be highly beneficial to find a successful candidate who resides in either yorkshire  cumbria  lancashire  greater manchester  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job reference   brjob type full time your role are you an analytic thinker  do you enjoy creating valuable insights with data  do you want to play a key role in transforming our firm into a data driven organization we re looking for a data engineer to  engineer reliable data pipelines for sourcing  processing  transforming  enriching and storing data in different ways  using data platform infrastructure effectively work with etl tools to ingest and transform data sets from a variety of data sources establish relationships with stakeholders to understand the specific operational and analytical needs of the organization  provide advice on advanced analytical approaches for addressing these needs  and identify and capture the required data sources leverage statistical tools  programming languages  and visualization tools   experience in pyspark  python  scala work closely in a cross functional team to improve  digital  products and journeys iteratively and continuously to drive business outcome liaise and coordinate with other data experts to build up shared services and capabilities coach and develop more junior team members your team you ll be working in the financing stream focusing on delivering cloud based data pipelines to pass data from golden source position keeping systems to our risk calculators  utilising the latest tooling available  you ll be supporting the global head of counterparty risk and the front office risk team in developing the data and visualisations required to manage counterparty risk your expertise \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " similar data engineering or developer role strong competence in sql and database design with a solid understanding of data architectures  e g  databases  data lakes  hands on experience with a cloud platform is essential  ideally within the azure data ecosystem  with azure databricks  data factory  data lake  and synapse  strong competence in python or scala  with good knowledge of the linux environment and ideally py spark experience experience with an off the shelf ui is a plus </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> sql data engineer     remote working from home role ideally residing within yorkshire  cumbria  lancashire  greater manchester  merseyside  derbyshire or midlands s area  full working from home role starting salary  c k    k  depending on experience    company benefits main skills  ms sql  t sql  programming languages  c   python  vb   ms access with advanced vba  ssrs report design  etl  ssis prefect azure  we have an exciting opportunity for a business focussed sql data engineer with a strong desire to build a career in data analysis  database design and application solutions  to join this long standing client of ours originally starting out in the rural parts of yorkshire  my client has established itself as a highly successful international financial retail consultancy that now services some of the world s largest organisations as a result of this huge business demand for their leading solutions  we are looking to help expand their sql data engineering team further the role the key element of this role is to ideally find an sql data engineer who loves big data  with also a good understanding of how retailing businesses work  in order to interpret the importance and value to the information being developed and processed towards the users  the candidate in order to be considered you will ideally have experience of the following     years of previous \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " similar sql data engineering role data analysis and conversion skills using microsoft sql server is essential an understanding of relational database design and build schema design  normalising data  indexing  query performance analysis ability to analyse complex data to identify patterns and detect anomalies assisting with etl design and implementation projects key skills sought microsoft sql server  sql server management studio  stored procedure writing etc t sqlprogramming languages  c   vb  python etc use of python to manipulate and import data front end application design in microsoft access with advanced vbassrs report design experience of etl automation advantageous but not essential  ssis prefect azure a self starter who can drive projects with minimal guidance meeting stakeholders to agree system requirements someone who is enthusiastic and eager to learn excellent verbal and written communication skills essential this is a fully home based role  working alongside their in house it  data engineering team located in the uk and off shore although this is a purely home based   remote working from home role  it would be highly beneficial to find a successful candidate who resides in either yorkshire  cumbria  lancashire  greater manchester  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job reference   brjob type full time your role are you an analytic thinker  do you enjoy creating valuable insights with data  do you want to play a key role in transforming our firm into a data driven organization we re looking for a data engineer to  engineer reliable data pipelines for sourcing  processing  transforming  enriching and storing data in different ways  using data platform infrastructure effectively work with etl tools to ingest and transform data sets from a variety of data sources establish relationships with stakeholders to understand the specific operational and analytical needs of the organization  provide advice on advanced analytical approaches for addressing these needs  and identify and capture the required data sources leverage statistical tools  programming languages  and visualization tools   experience in pyspark  python  scala work closely in a cross functional team to improve  digital  products and journeys iteratively and continuously to drive business outcome liaise and coordinate with other data experts to build up shared services and capabilities coach and develop more junior team members your team you ll be working in the financing stream focusing on delivering cloud based data pipelines to pass data from golden source position keeping systems to our risk calculators  utilising the latest tooling available  you ll be supporting the global head of counterparty risk and the front office risk team in developing the data and visualisations required to manage counterparty risk your expertise \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience in a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">experience_adp</span>\n",
       "</mark>\n",
       " similar data engineering or developer role strong competence in sql and database design with a solid understanding of data architectures  e g  databases  data lakes  hands on experience with a cloud platform is essential  ideally within the azure data ecosystem  with azure databricks  data factory  data lake  and synapse  strong competence in python or scala  with good knowledge of the linux environment and ideally py spark experience experience with an off the shelf ui is a plus </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showent_df(ent_df.query('text == \"experience in a\"').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737018d",
   "metadata": {},
   "source": [
    "**Extracting types of experience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d93fffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_phrase_experience(doc):\n",
    "    for np in doc.noun_chunks:\n",
    "        if np[-1].lower_ == 'experience':\n",
    "            if len(np) > 1:\n",
    "                yield 'EXPERIENCE', np[0].i, np[-1].i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc67c7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">and we don t believe in a siloed approach  our data engineers sit side by side with software engineers and designers  making sure that we have the data we need to provide \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience our customers want  you ll be deeply embedded in the product team  with your work being deployed to clients every week  you ll work closely with our domain experts  and have the chance to present to clients if that s something that excites you you can expect to have ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python  we deploy our work in a variety of ways depending upon the challenge  from lambdas to docker containers  our etl is run in dagster  which is a friendlier and more modern version of airflow  you d be joining an experienced team but you d be the first data engineer  so you d have lots of scope to define best practices and choose your tools we re interested in talking to people with dev ops and \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    classical software engineering\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience  as well as those coming from data science who have a passion for scaling etl systems our only must haves are possessing a hunger to solve business challenges using technology  the ability to build close relationships with your team  and the right to work in the uk which tools  technologies  and processes will you work with data processing with the standard scientific stack  pandas  numpy  scipy  and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will object oriented code forms the bulk of our codebase postgre sql and dynamo </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">db managed databases form the persistence layer   you ll learn to navigate document and relational databases and appreciate the values in both worlds infrastructure automation is owned by the whole team  helping to spread the dev ops mentality across the whole technology department  and beyond  you don t need to be a pro at all of these skills to apply for the role  but we d love to hear about any relevant knowledge and experiences that you have in these areas what we require from applicants right to work in the uk and willingness to come to london office   days a week  years of commercial data engeering  data science  or \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    software engineering\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we re offering competitive salary   generous equity package flexible working hours   we encourage regular breaks and being afk  away from keyboard  to support your wellbeing flexible working location  we like to meet in the office couple of times every week   annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays  and frequent pub trips pakt coffee and snacks of your choice in the office days holiday   bank holidays we re striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology  be that in terms of gender  race  or professional background if you think your skills and experience match what we re looking for and you d like to join a carbon tech industry unicorn  please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the company s data platform\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development hadoop ecosystem experience java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    product development skills   \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "experience at the data shed we are looking for experience in the following things  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">csv  json and xml broader knowledge of it   e g   security and networking working in an agile environment test driven development and or behaviour driven development continuous integration and \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    continuous deployment  ci cd optional\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience the following is optional  but \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    highly desirable\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience  building \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    reliable data pipelines\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience of \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exploratory data analysis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience of visualising data working with metrics  segments  aggregates  features requirements of the role maintain a broad knowledge of the technology landscape helping the data shed provide market leading assist our clients in enterprise scale projects utilising best practice development methodologies  well tested spend as much time on tests and security as on writing code work with a team of like minded  high calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that s broken  fix it  that includes the coffee machine benefits we have a variety of benefits including free access to an eap program  an auto enrolment pension scheme  a life assurance scheme  regular socials and a company performance based bonus and for any additional needs you have  we have a friendly and knowledgeable hr team to support you location we have a leeds hq and a flexible hybrid working policy  travel to client sites may be required from time to time  subject to business need ready to be a shedder we also celebrate each other s differences and encourage each other to explore new ways of thinking  the result is a diverse set of individuals who come together to create a multi talented  cohesive organisation  if you think that your uniqueness could make us even stronger  then please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">are you a data engineer interested in or currently working with autonomous vehicle technology  if so  we are looking to talk with you about your python software development skills  including exposure to working with vast volumes of data  in line with the opportunity to join oxbotica as a data engineer at oxbotica  we re fuelled by a bold purpose  to make the earth move from passenger shuttles to industrial vehicles  from congested city streets to mines  our industry leading autonomy software platform enables any vehicle to operate itself safely  securely and efficiently  we call it universal autonomy  it is changing how people and goods move we are a world class team guided by a shared vision to bring the benefits of autonomy to our customers and users  using \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    our skills  \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "experience and diversity  we are solving the most exciting and important technological challenges of our times  and creating a safer and more sustainable future for people and our planet our    and growing  team members in the uk and canada are building  scaling and commercialising our universal autonomy software to serve immediate market and deployment opportunities we re seeking bold  creative  hyper skilled people to join us  come create the future of autonomy with us at oxbotica  become an  oxbot  the systems metrics team is a cross functional team that is responsible for ensuring transparent evaluation of our technology and operations  clarity and transparency is enabled through concrete evaluation criteria  well defined evaluation processes  and visibility of results we develop and maintain metrics that are visible to all internally within the company  as well as metrics that are visible to the company s external partners during demonstrations  po c deployments  and product releases  we utilise metrics to perform inference to further the improvement of our technology and operations  while striving to maximise coverage of metrics across all aspects of the company as a data engineer your day will include  but will not be limited to  using our python based metrics extraction tools that operate on data produced by oxbotica vehicles working closely with the data that the oxbotica fleet and processes produce and consume where is the data  has the data been offloaded from the producers has the data stream been processed is the data available for consumption designing  developing  and maintaining software while ensuring that data integrity is preserved throughout the data stream working closely with data infrastructure engineers to support implementation of tools that facilitate data driven inference on vast volumes of data supporting the development of autonomy components by clearly illustrating  via quantitative analysis  where we are as a company contributing to processes that show share metrics inferred from the data  e g  performance in autonomy  number of revokes per km  etc   and whether the metrics being computed are sufficient investigating what extra information can be extracted from the current raw data stream identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy requirements what you need to succeed proficiency in python software development skills  tools such as debugger  ide and profilers  proficiency with data science libraries such as pandas  numpy  scipy  bokeh  etc  familiarity with git the ability to maintain \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    high quality code documentation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with performing mathematically robust statistical analysis  data modelling  and predictive analytics the ability to interact with databases  e g  sql  ui skills for interacting with dashboards constructed using grafana  apache superset  etc the ability to clearly translate numbers into meaningful and informative diagrams extra kudos if you have software development skills in c   familiarity with robotics an understanding of machine learning an understanding of measuring operations and processes an understanding of data streaming processes our culture at oxbotica  our diverse and inclusive culture fuels our growth  we celebrate individuality  foster an environment in which trust and respect flourish  and believe that innovation thrives when powered by different perspectives  experiences and ideas  our purpose  values and principles anchor us as we grow learn more about our culture here benefits competitive salary company share programme hybrid and or flexible work arrangements an outstanding    flexible benefits including private medical insurance  critical illness coverage  life assurance  eap  group income protection funded relocation support fully funded visa sponsorship if required a salary exchange pension plan days annual leave plus bank holidays a pet friendly office environment safe assigned spaces for team members with individual and diverse needs</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">not only does that mean running and maintaining the solution that already exists  but also continually improving it to incorporate new data sources  and to derive new insights  to support ever evolving business demands as data engineer your primary responsibility will be to support a senior data engineer to create and maintain underlying data infrastructure that provides the wider team with the data they need to provide timely  accurate and meaningful deliverables   reporting  in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving  and in demand  industry some of the things we d like you to do assist the development of technical solutions  in line with specifications  that collect  store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures  helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies  ensuring your work incorporates industry best practice monitor automated jobs  troubleshooting data issues as and when they arise support other members of the team responsible for  last mile  transformation and visualization of data within google data studio reports and dashboards provide hands on support to users of reporting solutions  helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings  presenting your solutions and providing updates on your work support the development strong working relationships with third party data providers that we rely on for access to necessary data a bit about yourself required \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    previous\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience working with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data and technology\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with programming and or statistical languages  e g  sql  python analytically minded  enabling you to understand and overcome technically complex challenges  and to tell compelling stories with data strong organizational skills and attention to detail  including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills  ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem  and an understanding of the role that data plays within it delivers best results when working in a team environment  and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl  particularly useful if done using google cloud platform  airflow  \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dbt etc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with digital marketing platforms and the data they generate  in particular google marketing platform  facebook  twitter etc  knowledge of their api s a plus an understanding of how data is tracked and exchanged in the process of digital advertising  e g  role of ad servers and other third party tech vendors experience using or building reports with business intelligence software  \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ideally google data studio work\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience within a marketing organization  preferably at a media agency or related company  e g  publisher  ad tech  client marketing org what you can expect from essence essence s mission is to make advertising more valuable to the world  we do this by employing the world s very best talent to solve some of the toughest challenges of today s digital marketing landscape  it s important that we hire people whose values reflect those of our own  genuine  results focused  daring and insightful  as an essence employee  we promise you a workplace that invests in your career  cares for you and is fun and engaging  we believe these factors create a workplace where you can be yourself and do amazing work </br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job summary square enix has an internal cloud based platform  sgv   which provides our analytics   insight team and other groups across the business with a single data lake pooling game telemetry  sales information  marketing data  web analytics and other information duties include building  optimising and enhancing data acquisition pipelines working with client teams to ensure robust capture of high quality data supporting data analysts and other users of the data via with technical assistance this position requires a driven and talented person that can help the team progress requirements key deliverables build and test new functionality for existing pipelines alongside expanding the scope of data sources supported by the platform ensure the data engineering team deliver on requests from client teams to agreed specification and timelines ensure open and regular communication with other stakeholders as to the status of their projects work to ensure data engineering team is capable to deliver against responsibilities  ensure data is robust and of high quality provide data access and querying support to users both within the team and across the business have a good understanding of the scope  potential and limitations of the datasets maintained by the data engineering team  remaining alert to any opportunity to further employ our data to benefit the business evangelise the use of customer data to better understand our customers across the organisation  to always represent the team professionally   both internally and externally key stakeholders senior director digital channels  director of analytics   insight  data protection officer knowledge   experience \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    essential programming\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    java   preferable  and python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with testing frameworks  junit  mockito  etc comfortable familiarity working with large data sets good sql skills strong problem solving \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    skills\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience writing batch etls on large datasets using various sources  e g  sql servers  \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rest apis  json files\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with build tools  such as gradle  maven  sbtfamiliarity with osx or linux environment  shell scripting  basic system administration etc  experience using source control collaboration tools such as git hub  bitbucket or git lab familiarity with collaboration and communication tools such as jira  confluence  slack etc desirable bsc or higher level degree in computer science  stem subject or a similar field of \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with cloud based engineering platforms  e g  gcp  aws  azure experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    apache beam\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    streaming data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with dag based workflow management systems  ideally air flow competencies  skills   attributes essential ability to quickly learn and employ new technologies and methodologies  strong documentation skills ability to articulate and present ideas and information with ease and clarity ability to work on own initiative and as part of team other interest in technology  ambition to drive self development excellent attention to detail follower of industry trends and developments our goal at square enix is to hire  retain  develop and promote the best talent  regardless of age  gender  race  religious  belief  sexual orientation or physical ability our pledge to d iat square enix we believe in the importance of being a diverse and global company  and we stand firmly together against any forms of injustice  intolerance  harassment or discrimination  in our effort to create a truly diverse workforce  we pledge to continue to raise awareness in every step of \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the employee\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience  from recruitment to promotions to ensure equal opportunities for all  one of our goals is to champion diversity in games and at work and work together to inspire real change learning and education around d </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">carwow is looking for a data engineer to join our platform engineering team on a full time basis in either a fully remote or hybrid capacity about carwow buying or selling a car shouldn t be difficult  that s why here at carwow we are on a mission to change the way people buy  sell or use a car by creating the world s best online car marketplace  we re not all petrolheads   just a highly driven  excuse the pun  scale up with over  carwowers in the uk  germany  spain and portugal  since starting our journey in   we ve grown to become one of the most trusted comparison sites with over  million users and a trustpilot rating of    we are also very proud to be backed by some of europe s most respected technology  marketplace and automotive investors about the role this year we re investing heavily in the continued growth of our analytics infrastructure and automotive pricing tribe and part of this growth has seen data engineering become its own entity  we are looking for someone to join the team and play a key role designing and building the data systems we use to make data driven decisions across the business and deliver great products   experiences to our customers you ll work closely with our data science and analytics teams in exploring and implementing ways to improve our current data systems whilst supporting with stand alone projects across each of our analytics verticals  we ll make sure you re supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout  requirements must have  sql  \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    python  data infrastructure  sql etl elt knowledge  \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "experience with dags to manage script dependencies with tools like airflow nice to have  snowflake  airflow  terraform  ruby  data visualisation tool  e g  looker  tableau  power bi   amplitude  dev ops  redshift  awsplease note  we know that no candidate will be the perfect match for all we ve listed in this posting  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> london  uk   full time a fantastic opportunity to be involved in end to end data management solutions for cutting edge advanced analytics and data science deployments who we are  at kearney analytics  we believe in the power of connected data  we are laser focused on helping organizations harness the interconnectedness of digital  data and decision making  we are problem solvers and builders focused on helping our clients win with data  our culture is cool and innovative  our environment is casual and conducive to collaboration and problem solving  we take our work seriously but not ourselves  it s the perfect balance of freedom and accountability  if you want to be part of something great   join us what can we offer competitive salary vitality private health care life insurance  accident insurance and long term disability insurance bupa annual wellness check  rrp      pension flu jab  eye test travelcard interest free loan annual performance bonus flexible working days annual leave   bank holidays about you you have experience with client projects and in handling vast amounts of data   working on database design and development  data integration and ingestion  designing etl architectures using a variety of etl tools and techniques  you are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled analytics team  play a key role on projects from a data engineering perspective  working with our architects and clients to model the data landscape  obtain data extracts and define secure data exchange approaches  this is a fantastic opportunity to be involved in end to end data management for cutting edge advanced analytics and data science job specifics plan and execute secure  best practice data integration strategies and approaches acquire  ingest  and process data from multiple sources and systems into big data platforms create and manage data environments in the cloud collaborate with our business analysts and data scientists to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models managing and monitoring the data integration process have a strong understanding of information security principles to ensure compliant handling and management of client data qualifications and \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    required skills\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience and desire to work with open source and branded open source frameworks experience working on projects within the cloud ideally aws  \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    azure  gcp or snowflake\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience working on agile delivery projects and a consulting setting  often working on different and multiple projects at \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the same time\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience working with a variety of etl elt tools like matillion  talend  streamsets preferred strong development background with experience in at least one scripting  object oriented or functional programming language  etc   python  java  scala  c   r  bashexperience working with version control tools such as \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    git hub  bitbucket data warehousing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience  building operational etl data pipelines across a number of sources  and constructing relational and dimensional data models excellent interpersonal skills when interacting with clients in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a clear  timely  and professional manner desirable skills\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience on client facing projects  including working in close knit teams experience working in a cloud architecture with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data lake\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience and interest in big data technologies  spark   \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    no sql dbs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience or familiarity with real time ingestion and streaming frameworks is a plus a deep personal motivation to always produce outstanding work for your clients and colleagues excel in team collaboration and working with others from diverse skill sets and \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    background\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience leading a team and driving them go deliver results solution delivery</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">she her hers  he him his  they them theirs  etc  introbumble is looking for an etl data engineer to participate in the development of the data collecting and data processing framework  services and tools for the cross functional data platform department  concretely  this means implementing  deploying and maintaining large scale data pipelines as well as internal data tools that help bumble provide \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a safe and engaging\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience for our users and improve the way bumble operates with millions of images and messages exchanged on our platform every day  there is a wealth of opportunity to make a real difference in this role and help people to find love all over the world  the ideal candidate combines \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    strong business acumen  \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "experience in data pipelines  databases and development best practices along with a passion for tech key accountabilities working with big data  tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team s ecosystem  dozens of in house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language  ability to write complex queries \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data warehousing and database basic architecture principles posix unix linux ecosystem knowledge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with php python or desire to learn them we appreciate result oriented work style  flexibility in choosing tools and technical approaches nice to have experience with exasol and or snowflake databases good knowledge of sql  window functions  common table expressions  complex grouping etc  google cloud platform familiarity basic hadoop familiarity  hdfs hive about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a  can do  attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team s advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:10], extract_noun_phrase_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b086f1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 1 Âµs, total: 5 Âµs\n",
      "Wall time: 13.1 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "ent_df = extract_df(extract_noun_phrase_experience, n_max=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d47dd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>previous</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>strong</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>your</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>relevant</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>proven</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>years</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>demonstrable</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>equivalent</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>extensive</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>user</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>the following</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>the</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>years</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>prior</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>practical</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>desirable</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>some</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>customer</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>working</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>a plus</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>data</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>work</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>etc</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>python</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>experience</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>significant</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>any</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>software engineering</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>required</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>excel</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>the user</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>both written and oral</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>solid</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>detail</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>professional</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>industry</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>airflow</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>techniques</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>elt tooling</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>findings</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>some sql</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>consolidating and normalizing data</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>microsoft azure</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>similar</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>sql  elasticsearch</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>not essential</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>advanced</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>research</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text  n_company    n\n",
       "570                            previous         30  149\n",
       "718                              strong         17   58\n",
       "860                                your         15   60\n",
       "622                            relevant         12   34\n",
       "593                              proven          9   49\n",
       "855                             years            8   34\n",
       "273                        demonstrable          7   45\n",
       "319                          equivalent          7   25\n",
       "361                           extensive          7   10\n",
       "832                                user          7    9\n",
       "781                       the following          6   33\n",
       "761                                 the          6   31\n",
       "854                               years          6   27\n",
       "575                               prior          6   26\n",
       "560                           practical          6   11\n",
       "282                           desirable          5   30\n",
       "674                                some          5   19\n",
       "219                            customer          5    8\n",
       "849                             working          4   30\n",
       "47                               a plus          4   23\n",
       "224                                data          4   19\n",
       "848                                work          4   15\n",
       "336                               etc            4   12\n",
       "597                              python          4   12\n",
       "355                          experience          4   11\n",
       "650                         significant          4   11\n",
       "112                                 any          4    8\n",
       "668                software engineering          3   39\n",
       "442                           knowledge          3   23\n",
       "630                            required          3   18\n",
       "343                               excel          3   16\n",
       "811                            the user          3   16\n",
       "165               both written and oral          3   12\n",
       "669                               solid          3   11\n",
       "290                              detail          3    8\n",
       "583                        professional          3    7\n",
       "420                            industry          3    5\n",
       "87                              airflow          3    4\n",
       "529                               other          2   28\n",
       "755                          techniques          2   18\n",
       "316                         elt tooling          2   14\n",
       "371                            findings          2   14\n",
       "682                            some sql          2   14\n",
       "210  consolidating and normalizing data          2   13\n",
       "472                     microsoft azure          2   13\n",
       "654                             similar          2   13\n",
       "688                  sql  elasticsearch          2   13\n",
       "511                       not essential          2   12\n",
       "79                             advanced          2   11\n",
       "634                            research          2   11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_df).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64725c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> we are a team of highly experienced software engineers and hands on coaches who move fast to solve our clients needs providing bespoke consultancy  training and pairing to upskill teams and deliver effective change  our aim is to identify the gaps in the client s engineering capability and then work to transfer our skills  knowledge and experience to their organisation providing repeatable patterns and behaviours to create sustainable change and build a culture of continuous improvement  armakuni is a test first and agile environment  with a keen focus on the quality of the software that we develop  and how we can support our engineers to continue their learning and career journey  we focus on helping organisations get their great ideas into the hands of their end users as quickly and effectively as possible  to do this we focus on the following areas  modern software delivery practices  ways of working  your role will empower you to make a real difference as you deliver hands on  strategic and technical consulting solutions to our clients  your role will vary depending on client needs  it could be designing  building and delivering a bespoke  immersive training programme on modern software development practices  for another client you could be embedded in a team  delivering value with them while helping them improve their practices using your coaching skills  you could be leading an armakuni team on an outcome based software delivery project  using \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience to architect and iteratively implement a simple solution to complex business needs   about you   the most important things we look for are attitude and learning agility  you are bright  flexible  intellectually curious  self aware  passionate about learning and sharing  and have an appetite for continuous improvement  you will have an aptitude for programming and developing software but we are language and technology agnostic  we expect you to be self sufficient  to fully understand and immerse yourself in the client s aims and have a high level of empathy  you will offer professional insight ensuring client satisfaction whilst representing the commercial interests of armakuni   requirements   the tech stack you ll be working with will vary by client of course  but typically  our engineers have experience working with some of the following  just as important  is the way you approach your work  and typically  candidates that will thrive at armakuni are likely to be able to demonstrate some of the following    java  aws  gcp  azure  docker java  aws  gcp  azure  docker  agile  stakeholder management tdd bdd ci cdpairing everything as code microservices  serverless software craft emergent design agile  specifically xp building high trust  high autonomy teams fast feedback loops focusing on business value delivery team health and topologies about the role  knowledge of one or more programming languages   java  ruby and c   are often good areas to have focussed on  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">data engineer are you a mid level data engineer looking for a new migration challenge within a large and reputable company  or perhaps a junior data engineer with at least two years experience looking to make that move to mid level data idols are supporting one of the best known retail brands in the uk with their search for two new data engineers to join their digital   data team  where you will be supporting the delivery of data transformation during an exciting time within the company  the opportunity as a data engineer  you will develop solutions to deliver capabilities and support migration onto our client s new cloud based data platform  azure   the key objective of the role is to develop high quality  automated pipelines which will ingest  transform  and create structured and performant data sets   it s key you have etl end to end experience  you will also build strong working relationships with technical leads  data modellers and engineers to collaborate on cross data team priorities and support the development of a passionate engineering community skills and experience minimum of two years experience  and solid expertise in sql and end to end etl pipelines any cloud experience is a bonus  but full training will be offered in the azure cloud stack  what s in it for you          salary  depending on experience   bonus great pension and leave allowances discounts and a wider benefits package please apply if this role interests you  and we will reach out if \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience is relevant  please note that our client currently cannot provide sponsorship from the first day of employment data engineer desired skills and experience sql  etl  python  azure  cloud  gcp  aws</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">data engineer are you a mid level data engineer looking for a new migration challenge within a large and reputable company  or perhaps a junior data engineer with at least two years experience looking to make that move to mid level data idols are supporting one of the best known retail brands in the uk with their search for two new data engineers to join their digital   data team  where you will be supporting the delivery of data transformation during an exciting time within the company  the opportunity as a data engineer  you will develop solutions to deliver capabilities and support migration onto our client s new cloud based data platform  azure   the key objective of the role is to develop high quality  automated pipelines which will ingest  transform  and create structured and performant data sets   it s key you have etl end to end experience  you will also build strong working relationships with technical leads  data modellers and engineers to collaborate on cross data team priorities and support the development of a passionate engineering community skills and experience minimum of two years experience  and solid expertise in sql and end to end etl pipelines any cloud experience is a bonus  but full training will be offered in the azure cloud stack  what s in it for you          salary  depending on experience   bonus great pension and leave allowances discounts and a wider benefits package please apply if this role interests you  and we will reach out if \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience is relevant  please note that our client currently cannot provide sponsorship from the first day of employment data engineer desired skills and experience sql  etl  python  azure  cloud  gcp  aws</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">data engineer are you a mid level data engineer looking for a new migration challenge within a large and reputable company  or perhaps a junior data engineer with at least two years experience looking to make that move to mid level data idols are supporting one of the best known retail brands in the uk with their search for two new data engineers to join their digital   data team  where you will be supporting the delivery of data transformation during an exciting time within the company  the opportunity as a data engineer  you will develop solutions to deliver capabilities and support migration onto our client s new cloud based data platform  azure   the key objective of the role is to develop high quality  automated pipelines which will ingest  transform  and create structured and performant data sets   it s key you have etl end to end experience  you will also build strong working relationships with technical leads  data modellers and engineers to collaborate on cross data team priorities and support the development of a passionate engineering community skills and experience minimum of two years experience  and solid expertise in sql and end to end etl pipelines any cloud experience is a bonus  but full training will be offered in the azure cloud stack  what s in it for you          salary  depending on experience   bonus great pension and leave allowances discounts and a wider benefits package please apply if this role interests you  and we will reach out if \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience is relevant  please note that our client currently cannot provide sponsorship from the first day of employment data engineer desired skills and experience sql  etl  python  azure  cloud  gcp  aws</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> we are a team of highly experienced software engineers and hands on coaches who move fast to solve our clients needs providing bespoke consultancy  training and pairing to upskill teams and deliver effective change  our aim is to identify the gaps in the client s engineering capability and then work to transfer our skills  knowledge and experience to their organisation providing repeatable patterns and behaviours to create sustainable change and build a culture of continuous improvement  armakuni is a test first and agile environment  with a keen focus on the quality of the software that we develop  and how we can support our engineers to continue their learning and career journey  we focus on helping organisations get their great ideas into the hands of their end users as quickly and effectively as possible  to do this we focus on the following areas  modern software delivery practices  ways of working  your role will empower you to make a real difference as you deliver hands on  strategic and technical consulting solutions to our clients  your role will vary depending on client needs  it could be designing  building and delivering a bespoke  immersive training programme on modern software development practices  for another client you could be embedded in a team  delivering value with them while helping them improve their practices using your coaching skills  you could be leading an armakuni team on an outcome based software delivery project  using \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience to architect and iteratively implement a simple solution to complex business needs   about you   the most important things we look for are attitude and learning agility  you are bright  flexible  intellectually curious  self aware  passionate about learning and sharing  and have an appetite for continuous improvement  you will have an aptitude for programming and developing software but we are language and technology agnostic  we expect you to be self sufficient  to fully understand and immerse yourself in the client s aims and have a high level of empathy  you will offer professional insight ensuring client satisfaction whilst representing the commercial interests of armakuni   requirements   the tech stack you ll be working with will vary by client of course  but typically  our engineers have experience working with some of the following  just as important  is the way you approach your work  and typically  candidates that will thrive at armakuni are likely to be able to demonstrate some of the following    java  aws  gcp  azure  docker java  aws  gcp  azure  docker  agile  stakeholder management tdd bdd ci cdpairing everything as code microservices  serverless software craft emergent design agile  specifically xp building high trust  high autonomy teams fast feedback loops focusing on business value delivery team health and topologies about the role  knowledge of one or more programming languages   java  ruby and c   are often good areas to have focussed on  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">excellent opportunity to work for a growing company work in a data team who are developing and evolving expand \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with sql and power bi a great opportunity to join an agency in bristol who are going through a digital and data transformation  in a time of huge changes  exciting growth and modernisation across the business  it could not be a better time to start your career here what you ll be doing as a marketing analyst  you  ll be focusing on how they can engage customers and making their marketing more efficient across the business  you ll be utilising sql and providing analytics to assist in developing segmentation for marketing campaigns and analysing the results from these while the company are going through all these changes  your team will become more and more important  this is a new for you to make what you want from it  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">so it s a great opportunity to make your mark this pivotal role would be stepping into data to know more about what they need to look at  initially you ll be understanding customer conversion rates  automating data sources and helping to create a single customer view you ll be working alongside the insight and marketing team to provide a customer level understanding what experience you ll need to apply you re a few years into your career you ve been working as a marketing insight campaign analyst experience with sql experience with power bi and or tableau or similar tool strong experience working with large data sets or complex customer data sets bonus for experience with python or r bonus for crm experience bonus for snowflake or data mining experience  as this will come later  what you ll get in return for \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience a base salary reaching up to    per annum for the right person this role requires two days a week in their bristol office what next please get in touch with tegan with an updated cv today  don t hesitate to call email with any questions </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> at m g our vision is   to become the best loved and most successful savings and investment business and we re looking for people who are excited about joining us on our journey  we re digitally transforming and investing heavily in technology and innovation to develop new and improved customer propositions that really raise the bar for our customers  to help us achieve our vision we re looking for exceptional people who live our values and behaviours and who can inspire others  embrace change  deliver results and keep it simple we know that an inclusive environment makes us more accessible and ensures we attract  engage  promote and retain exceptional people  we welcome applications from all individuals regardless of age  gender gender identity  sexual orientation  ethnicity nationality  disability  or military service and welcome those who have taken career breaks  we will consider flexible working arrangements or home working arrangements for any of our roles and also offer work place accommodations to ensure you have what you need to effectively deliver in your role what you can expect from us we are committed to creating an environment where you can be exceptional at all you do  to help us deliver this  we promise to  challenge your limits by creating a stimulating working environment and providing opportunities for you to be involved in meaningful and challenging work  support your aspirations with a commitment to learning and development that helps you achieve and build \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with people who want you to succeed  value your input whereby leaders and managers will involve you in key decisions  listen to your thoughts and recognise the important contribution you make  balance your life through a work life partnership that focuses on making this an inclusive  diverse and friendly place to work and offers the flexibility and support that enables everyone to be at their best how do we support our employees </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> the mission having just closed our series a  percent is on a mission to power purpose in every organisation worldwide  we ve been called the stripe for giving which aligns to our ambition to become a huge global organisation driving the world towards a better future  read more about our mission in our tech crunch feature about our seed raise last year our team is the secret to our success  together  we have built an api first platform that allows our partners to quickly and easily build giving   purpose into their products  we house the world s largest vetted database of nonprofits  and by working together with the world s biggest customer facing platforms  from streaming giants to your favourite social media sites   we have accelerated charitable giving to these nonprofits the demand for our platform has sky rocketed  and now that we have closed our series a funding round  we are looking for passionate  talented   purpose driven minds to come onboard  join us and work at a fast paced  passionate organisation that will become the stripe for giving the role this position will work within our vetting and validation team  this team implements the apis and user experience to keep our nonprofits and partners happy and engaged in our product  you will be part of an autonomous  cross functional product team able to make its own decisions based on the objectives set by the business senior engineers at percent are involved on a highly technical level  helping establish and build best practices in terms of technologies used  day to day you will be expected to write code and be involved in planning and delivery  you will report directly to our technical lead you have at least   years experience working with frontend projects strong technical understanding of react in depth knowledge of type script the ability to be product driven  contributing towards product thinking  and engineering best practices with knowledge of how these integrate seamlessly experience working on a large or complex production codebase experience in frontend optimization experience developing secure  scalable  resilient systems a fundamental understanding of databases  we currently use postgre sql experience of monitoring systems  continuous integration and automated testing an ability to keep your team happy and productive comfortable managing business expectations  resolving conflicts  and keep stakeholders aligned the ability to establish new approaches to improve productivity and even better  although not a necessity  you might also have knowledge of graph qlmicro front end experience knowledge of other frontend frameworks understanding of backend api s as a prize for getting to the end of our job posting  feel free to read our super secret plan to get a sense for why we do what we do ready to build a huge organisation and change the world for good  let s do this about us at percent  we aim to build a culture of purpose  innovation  and empathy  we encourage you to apply  even if \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience is not a precise match  we believe in potential  we tackle everything with a growth mindset  if you believe that you have what it takes to help build a path of purpose  we would love to hear from you percent is an equal opportunity employer  all applicants will be considered for employment without attention to ethnicity  appearance  religion  gender identity  sexual orientation  national origin  veteran  or disability status </br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">excellent opportunity to work for a growing company work in a data team who are developing and evolving expand \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " experience with sql and power bi a great opportunity to join an agency in bristol who are going through a digital and data transformation  in a time of huge changes  exciting growth and modernisation across the business  it could not be a better time to start your career here what you ll be doing as a marketing analyst  you  ll be focusing on how they can engage customers and making their marketing more efficient across the business  you ll be utilising sql and providing analytics to assist in developing segmentation for marketing campaigns and analysing the results from these while the company are going through all these changes  your team will become more and more important  this is a new for you to make what you want from it  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showent_df(ent_df.query(\"text=='your'\").head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bad3f202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\b(?:previous|strong|your|relevant|proven|years|demonstrable|equivalent|extensive|following|the|prior|practical|desirable|the|some|working|significant|other|advanced|solid|professional|any|similar|required|a plus|work|essential|etc|experience|knowledge|good)\\\\b'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_qualifiers = ['previous', 'strong', 'your','relevant','proven','years','demonstrable','equivalent','extensive'\n",
    "                         ,'following', 'the','prior','practical','desirable','the','some','working','significant',\n",
    "                         'other','advanced', 'solid', 'professional', 'any', 'similar','required','a plus','work','essential','etc'\n",
    "                         ,'experience', 'knowledge','good'\n",
    "                        ]\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "experience_qualifier_pattern = rf'\\b(?:{\"|\".join(experience_qualifiers)})\\b'\n",
    "\n",
    "experience_qualifier_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85c4a93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>user</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>customer</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>data</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>python</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>software engineering</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>excel</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>both written and oral</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>detail</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>industry</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>airflow</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>techniques</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>elt tooling</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>findings</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>consolidating and normalizing data</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>microsoft azure</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>sql  elasticsearch</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>research</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a clinical  scientific or healthcare discipline</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>clinical database management system development</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>sql</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>this role</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>an agile environment</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>data modelling</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>big data</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>commercial</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>related technologies</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>troubleshooting tools</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>financial data</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>key skills</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>tableau</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>application</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>customer expectations</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>programming</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>rdata warehousing</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>services</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>a personalised customer</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>optimization</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>an excellent</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>adaptive learning</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>agency or consultancy</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>a safe and engaging</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>ocr text processing</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>e g  c   java</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>our consumer</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>computer science fundamentals</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>data warehouses</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>depth</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>media industry</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>music</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  n_company   n\n",
       "515                                             user          7   9\n",
       "166                                         customer          5   8\n",
       "170                                             data          4  19\n",
       "407                                           python          4  12\n",
       "449                             software engineering          3  39\n",
       "248                                            excel          3  16\n",
       "116                            both written and oral          3  12\n",
       "216                                           detail          3   8\n",
       "294                                         industry          3   5\n",
       "61                                           airflow          3   4\n",
       "497                                       techniques          2  18\n",
       "240                                      elt tooling          2  14\n",
       "263                                         findings          2  14\n",
       "158               consolidating and normalizing data          2  13\n",
       "337                                  microsoft azure          2  13\n",
       "455                               sql  elasticsearch          2  13\n",
       "429                                         research          2  11\n",
       "5    a clinical  scientific or healthcare discipline          2  10\n",
       "135  clinical database management system development          2  10\n",
       "454                                              sql          2  10\n",
       "505                                        this role          2   9\n",
       "65                              an agile environment          2   8\n",
       "185                                   data modelling          2   8\n",
       "108                                         big data          2   6\n",
       "145                                       commercial          2   6\n",
       "424                             related technologies          2   5\n",
       "507                            troubleshooting tools          2   5\n",
       "261                                   financial data          2   3\n",
       "312                                       key skills          2   3\n",
       "489                                          tableau          2   3\n",
       "86                                       application          2   2\n",
       "167                            customer expectations          2   2\n",
       "403                                      programming          2   2\n",
       "418                                rdata warehousing          2   2\n",
       "439                                         services          2   2\n",
       "36                           a personalised customer          1  37\n",
       "374                                     optimization          1  32\n",
       "68                                      an excellent          1  24\n",
       "53                                 adaptive learning          1  19\n",
       "56                             agency or consultancy          1  19\n",
       "487                                              t            1  19\n",
       "38                               a safe and engaging          1  18\n",
       "367                              ocr text processing          1  16\n",
       "235                                    e g  c   java          1  15\n",
       "377                                     our consumer          1  15\n",
       "154                    computer science fundamentals          1  14\n",
       "193                                data warehouses            1  14\n",
       "212                                            depth          1  14\n",
       "334                                   media industry          1  14\n",
       "353                                          music            1  14"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_df[(~ent_df.text.str.lower().str.contains(experience_qualifier_pattern)) & # Not a qualifier\n",
    "                     ~ent_df.text.isin(stopwords)]).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc216b",
   "metadata": {},
   "source": [
    "# Extracting experience in a field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77f1314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adp_experience(doc, label='EXPERIENCE'):\n",
    "    for tok in doc:\n",
    "        if tok.lower_ == 'experience':\n",
    "            for child in tok.rights:\n",
    "                if child.dep_ == 'prep':\n",
    "                    for obj in child.children:\n",
    "                        if obj.dep_ == 'pobj':\n",
    "                            yield label, obj.left_edge.i, obj.i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5e7a65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">and we don t believe in a siloed approach  our data engineers sit side by side with software engineers and designers  making sure that we have the data we need to provide the \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " our customers want  you ll be deeply embedded in the product team  with your work being deployed to clients every week  you ll work closely with our domain experts  and have the chance to present to clients if that s something that excites you you can expect to have ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python  we deploy our work in a variety of ways depending upon the challenge  from lambdas to docker containers  our etl is run in dagster  which is a friendlier and more modern version of airflow  you d be joining an experienced team but you d be the first data engineer  so you d have lots of scope to define best practices and choose your tools we re interested in talking to people with dev ops and classical software engineering experience  as well as those coming from data science who have a passion for scaling etl systems our only must haves are possessing a hunger to solve business challenges using technology  the ability to build close relationships with your team  and the right to work in the uk which tools  technologies  and processes will you work with data processing with the standard scientific stack  pandas  numpy  scipy  and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will object oriented code forms the bulk of our codebase postgre sql and dynamo </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">db managed databases form the persistence layer   you ll learn to navigate document and relational databases and appreciate the values in both worlds infrastructure automation is owned by the whole team  helping to spread the dev ops mentality across the whole technology department  and beyond  you don t need to be a pro at all of these skills to apply for the role  but we d love to hear about any relevant knowledge and experiences that you have in these areas what we require from applicants right to work in the uk and willingness to come to london office   days a week  years of commercial data engeering  data science  or software engineering \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we re offering competitive salary   generous equity package flexible working hours   we encourage regular breaks and being afk  away from keyboard  to support your wellbeing flexible working location  we like to meet in the office couple of times every week   annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays  and frequent pub trips pakt coffee and snacks of your choice in the office days holiday   bank holidays we re striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology  be that in terms of gender  race  or professional background if you think your skills and experience match what we re looking for and you d like to join a carbon tech industry unicorn  please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of the company s data platform \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development hadoop ecosystem experience java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   experience at \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " shed we are looking for experience in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the following things\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">csv  json and xml broader knowledge of it   e g   security and networking working in an agile environment test driven development and or behaviour driven development continuous integration and continuous deployment  ci cd optional experience the following is optional  but highly desirable experience  building reliable data pipelines experience of \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exploratory data analysis experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " of visualising data working with metrics  segments  aggregates  features requirements of the role maintain a broad knowledge of the technology landscape helping the data shed provide market leading assist our clients in enterprise scale projects utilising best practice development methodologies  well tested spend as much time on tests and security as on writing code work with a team of like minded  high calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that s broken  fix it  that includes the coffee machine benefits we have a variety of benefits including free access to an eap program  an auto enrolment pension scheme  a life assurance scheme  regular socials and a company performance based bonus and for any additional needs you have  we have a friendly and knowledgeable hr team to support you location we have a leeds hq and a flexible hybrid working policy  travel to client sites may be required from time to time  subject to business need ready to be a shedder we also celebrate each other s differences and encourage each other to explore new ways of thinking  the result is a diverse set of individuals who come together to create a multi talented  cohesive organisation  if you think that your uniqueness could make us even stronger  then please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">are you a data engineer interested in or currently working with autonomous vehicle technology  if so  we are looking to talk with you about your python software development skills  including exposure to working with vast volumes of data  in line with the opportunity to join oxbotica as a data engineer at oxbotica  we re fuelled by a bold purpose  to make the earth move from passenger shuttles to industrial vehicles  from congested city streets to mines  our industry leading autonomy software platform enables any vehicle to operate itself safely  securely and efficiently  we call it universal autonomy  it is changing how people and goods move we are a world class team guided by a shared vision to bring the benefits of autonomy to our customers and users  using our skills  \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " and diversity  we are solving the most exciting and important technological challenges of our times  and creating a safer and more sustainable future for people and our planet our    and growing  team members in the uk and canada are building  scaling and commercialising our universal autonomy software to serve immediate market and deployment opportunities we re seeking bold  creative  hyper skilled people to join us  come create the future of autonomy with us at oxbotica  become an  oxbot  the systems metrics team is a cross functional team that is responsible for ensuring transparent evaluation of our technology and operations  clarity and transparency is enabled through concrete evaluation criteria  well defined evaluation processes  and visibility of results we develop and maintain metrics that are visible to all internally within the company  as well as metrics that are visible to the company s external partners during demonstrations  po c deployments  and product releases  we utilise metrics to perform inference to further the improvement of our technology and operations  while striving to maximise coverage of metrics across all aspects of the company as a data engineer your day will include  but will not be limited to  using our python based metrics extraction tools that operate on data produced by oxbotica vehicles working closely with the data that the oxbotica fleet and processes produce and consume where is the data  has the data been offloaded from the producers has the data stream been processed is the data available for consumption designing  developing  and maintaining software while ensuring that data integrity is preserved throughout the data stream working closely with data infrastructure engineers to support implementation of tools that facilitate data driven inference on vast volumes of data supporting the development of autonomy components by clearly illustrating  via quantitative analysis  where we are as a company contributing to processes that show share metrics inferred from the data  e g  performance in autonomy  number of revokes per km  etc   and whether the metrics being computed are sufficient investigating what extra information can be extracted from the current raw data stream identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy requirements what you need to succeed proficiency in python software development skills  tools such as debugger  ide and profilers  proficiency with data science libraries such as pandas  numpy  scipy  bokeh  etc  familiarity with git the ability to maintain high quality code documentation experience with performing mathematically robust statistical analysis  data modelling  and predictive analytics the ability to interact with databases  e g  sql  ui skills for interacting with dashboards constructed using grafana  apache superset  etc the ability to clearly translate numbers into meaningful and informative diagrams extra kudos if you have software development skills in c   familiarity with robotics an understanding of machine learning an understanding of measuring operations and processes an understanding of data streaming processes our culture at oxbotica  our diverse and inclusive culture fuels our growth  we celebrate individuality  foster an environment in which trust and respect flourish  and believe that innovation thrives when powered by different perspectives  experiences and ideas  our purpose  values and principles anchor us as we grow learn more about our culture here benefits competitive salary company share programme hybrid and or flexible work arrangements an outstanding    flexible benefits including private medical insurance  critical illness coverage  life assurance  eap  group income protection funded relocation support fully funded visa sponsorship if required a salary exchange pension plan days annual leave plus bank holidays a pet friendly office environment safe assigned spaces for team members with individual and diverse needs</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">not only does that mean running and maintaining the solution that already exists  but also continually improving it to incorporate new data sources  and to derive new insights  to support ever evolving business demands as data engineer your primary responsibility will be to support a senior data engineer to create and maintain underlying data infrastructure that provides the wider team with the data they need to provide timely  accurate and meaningful deliverables   reporting  in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving  and in demand  industry some of the things we d like you to do assist the development of technical solutions  in line with specifications  that collect  store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures  helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies  ensuring your work incorporates industry best practice monitor automated jobs  troubleshooting data issues as and when they arise support other members of the team responsible for  last mile  transformation and visualization of data within google data studio reports and dashboards provide hands on support to users of reporting solutions  helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings  presenting your solutions and providing updates on your work support the development strong working relationships with third party data providers that we rely on for access to necessary data a bit about yourself required previous experience working with data and technology experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    programming\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and or statistical languages  e g  sql  python analytically minded  enabling you to understand and overcome technically complex challenges  and to tell compelling stories with data strong organizational skills and attention to detail  including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills  ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem  and an understanding of the role that data plays within it delivers best results when working in a team environment  and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl  particularly useful if done using google cloud platform  airflow  dbt etc experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    digital marketing platforms\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and the data they generate  in particular google marketing platform  facebook  twitter etc  knowledge of their api s a plus an understanding of how data is tracked and exchanged in the process of digital advertising  e g  role of ad servers and other third party tech vendors experience using or building reports with business intelligence software  ideally google data studio work experience within \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a marketing organization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  preferably at a media agency or related company  e g  publisher  ad tech  client marketing org what you can expect from essence essence s mission is to make advertising more valuable to the world  we do this by employing the world s very best talent to solve some of the toughest challenges of today s digital marketing landscape  it s important that we hire people whose values reflect those of our own  genuine  results focused  daring and insightful  as an essence employee  we promise you a workplace that invests in your career  cares for you and is fun and engaging  we believe these factors create a workplace where you can be yourself and do amazing work </br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job summary square enix has an internal cloud based platform  sgv   which provides our analytics   insight team and other groups across the business with a single data lake pooling game telemetry  sales information  marketing data  web analytics and other information duties include building  optimising and enhancing data acquisition pipelines working with client teams to ensure robust capture of high quality data supporting data analysts and other users of the data via with technical assistance this position requires a driven and talented person that can help the team progress requirements key deliverables build and test new functionality for existing pipelines alongside expanding the scope of data sources supported by the platform ensure the data engineering team deliver on requests from client teams to agreed specification and timelines ensure open and regular communication with other stakeholders as to the status of their projects work to ensure data engineering team is capable to deliver against responsibilities  ensure data is robust and of high quality provide data access and querying support to users both within the team and across the business have a good understanding of the scope  potential and limitations of the datasets maintained by the data engineering team  remaining alert to any opportunity to further employ our data to benefit the business evangelise the use of customer data to better understand our customers across the organisation  to always represent the team professionally   both internally and externally key stakeholders senior director digital channels  director of analytics   insight  data protection officer knowledge   experience essential programming experience in java   preferable  and python experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    testing frameworks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  junit  mockito  etc comfortable familiarity working with large data sets good sql skills strong problem solving skills experience writing batch etls on large datasets using various sources  e g  sql servers  rest apis  json files experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    build tools\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  such as gradle  maven  sbtfamiliarity with osx or linux environment  shell scripting  basic system administration etc  experience using source control collaboration tools such as git hub  bitbucket or git lab familiarity with collaboration and communication tools such as jira  confluence  slack etc desirable bsc or higher level degree in computer science  stem subject or a similar field of study experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cloud based engineering platforms\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  e g  gcp  aws  azure experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    apache beam experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    streaming data experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dag\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " based workflow management systems  ideally air flow competencies  skills   attributes essential ability to quickly learn and employ new technologies and methodologies  strong documentation skills ability to articulate and present ideas and information with ease and clarity ability to work on own initiative and as part of team other interest in technology  ambition to drive self development excellent attention to detail follower of industry trends and developments our goal at square enix is to hire  retain  develop and promote the best talent  regardless of age  gender  race  religious  belief  sexual orientation or physical ability our pledge to d iat square enix we believe in the importance of being a diverse and global company  and we stand firmly together against any forms of injustice  intolerance  harassment or discrimination  in our effort to create a truly diverse workforce  we pledge to continue to raise awareness in every step of the employee experience  from \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    recruitment\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " to promotions to ensure equal opportunities for all  one of our goals is to champion diversity in games and at work and work together to inspire real change learning and education around d </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">carwow is looking for a data engineer to join our platform engineering team on a full time basis in either a fully remote or hybrid capacity about carwow buying or selling a car shouldn t be difficult  that s why here at carwow we are on a mission to change the way people buy  sell or use a car by creating the world s best online car marketplace  we re not all petrolheads   just a highly driven  excuse the pun  scale up with over  carwowers in the uk  germany  spain and portugal  since starting our journey in   we ve grown to become one of the most trusted comparison sites with over  million users and a trustpilot rating of    we are also very proud to be backed by some of europe s most respected technology  marketplace and automotive investors about the role this year we re investing heavily in the continued growth of our analytics infrastructure and automotive pricing tribe and part of this growth has seen data engineering become its own entity  we are looking for someone to join the team and play a key role designing and building the data systems we use to make data driven decisions across the business and deliver great products   experiences to our customers you ll work closely with our data science and analytics teams in exploring and implementing ways to improve our current data systems whilst supporting with stand alone projects across each of our analytics verticals  we ll make sure you re supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout  requirements must have  sql  python  data infrastructure  sql etl elt knowledge  experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dags\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " to manage script dependencies with tools like airflow nice to have  snowflake  airflow  terraform  ruby  data visualisation tool  e g  looker  tableau  power bi   amplitude  dev ops  redshift  awsplease note  we know that no candidate will be the perfect match for all we ve listed in this posting  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> london  uk   full time a fantastic opportunity to be involved in end to end data management solutions for cutting edge advanced analytics and data science deployments who we are  at kearney analytics  we believe in the power of connected data  we are laser focused on helping organizations harness the interconnectedness of digital  data and decision making  we are problem solvers and builders focused on helping our clients win with data  our culture is cool and innovative  our environment is casual and conducive to collaboration and problem solving  we take our work seriously but not ourselves  it s the perfect balance of freedom and accountability  if you want to be part of something great   join us what can we offer competitive salary vitality private health care life insurance  accident insurance and long term disability insurance bupa annual wellness check  rrp      pension flu jab  eye test travelcard interest free loan annual performance bonus flexible working days annual leave   bank holidays about you you have experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    client projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and in handling vast amounts of data   working on database design and development  data integration and ingestion  designing etl architectures using a variety of etl tools and techniques  you are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled analytics team  play a key role on projects from a data engineering perspective  working with our architects and clients to model the data landscape  obtain data extracts and define secure data exchange approaches  this is a fantastic opportunity to be involved in end to end data management for cutting edge advanced analytics and data science job specifics plan and execute secure  best practice data integration strategies and approaches acquire  ingest  and process data from multiple sources and systems into big data platforms create and manage data environments in the cloud collaborate with our business analysts and data scientists to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models managing and monitoring the data integration process have a strong understanding of information security principles to ensure compliant handling and management of client data qualifications and required skills experience and desire to work with open source and branded open source frameworks experience working on projects within the cloud ideally aws  azure  gcp or snowflake experience working on agile delivery projects and a consulting setting  often working on different and multiple projects at the same time experience working with a variety of etl elt tools like matillion  talend  streamsets preferred strong development background with experience in at least one scripting  object oriented or functional programming language  etc   python  java  scala  c   r  bashexperience working with version control tools such as git hub  bitbucket data warehousing experience  building operational etl data pipelines across a number of sources  and constructing relational and dimensional data models excellent interpersonal skills when interacting with clients in a clear  timely  and professional manner desirable skills experience on \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    client facing projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  including working in close knit teams experience working in a cloud architecture with data lake experience and interest in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    big data technologies  spark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "   no sql dbs experience or familiarity with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    real time ingestion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and streaming frameworks is a plus a deep personal motivation to always produce outstanding work for your clients and colleagues excel in team collaboration and working with others from diverse skill sets and background experience leading a team and driving them go deliver results solution delivery</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">she her hers  he him his  they them theirs  etc  introbumble is looking for an etl data engineer to participate in the development of the data collecting and data processing framework  services and tools for the cross functional data platform department  concretely  this means implementing  deploying and maintaining large scale data pipelines as well as internal data tools that help bumble provide a safe and engaging experience for \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    our users\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and improve the way bumble operates with millions of images and messages exchanged on our platform every day  there is a wealth of opportunity to make a real difference in this role and help people to find love all over the world  the ideal candidate combines strong business acumen  experience in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data pipelines  databases\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and development best practices along with a passion for tech key accountabilities working with big data  tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team s ecosystem  dozens of in house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language  ability to write complex queries data warehousing and database basic architecture principles posix unix linux ecosystem knowledge experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    php python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " or desire to learn them we appreciate result oriented work style  flexibility in choosing tools and technical approaches nice to have experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exasol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and or snowflake databases good knowledge of sql  window functions  common table expressions  complex grouping etc  google cloud platform familiarity basic hadoop familiarity  hdfs hive about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a  can do  attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team s advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:10], extract_adp_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32a86e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adp_experience_2(doc):\n",
    "    for np in doc.noun_chunks:\n",
    "        start_tok = np[0].i\n",
    "        if start_tok >= 2 and doc[start_tok - 2].lower_ == 'experience' and doc[start_tok - 1].pos_ == 'ADP':\n",
    "            yield 'EXPERIENCE', start_tok, start_tok + len(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9991e262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">and we don t believe in a siloed approach  our data engineers sit side by side with software engineers and designers  making sure that we have the data we need to provide the \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " our customers want  you ll be deeply embedded in the product team  with your work being deployed to clients every week  you ll work closely with our domain experts  and have the chance to present to clients if that s something that excites you you can expect to have ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python  we deploy our work in a variety of ways depending upon the challenge  from lambdas to docker containers  our etl is run in dagster  which is a friendlier and more modern version of airflow  you d be joining an experienced team but you d be the first data engineer  so you d have lots of scope to define best practices and choose your tools we re interested in talking to people with dev ops and classical software engineering experience  as well as those coming from data science who have a passion for scaling etl systems our only must haves are possessing a hunger to solve business challenges using technology  the ability to build close relationships with your team  and the right to work in the uk which tools  technologies  and processes will you work with data processing with the standard scientific stack  pandas  numpy  scipy  and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will object oriented code forms the bulk of our codebase postgre sql and dynamo </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">db managed databases form the persistence layer   you ll learn to navigate document and relational databases and appreciate the values in both worlds infrastructure automation is owned by the whole team  helping to spread the dev ops mentality across the whole technology department  and beyond  you don t need to be a pro at all of these skills to apply for the role  but we d love to hear about any relevant knowledge and experiences that you have in these areas what we require from applicants right to work in the uk and willingness to come to london office   days a week  years of commercial data engeering  data science  or software engineering \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we re offering competitive salary   generous equity package flexible working hours   we encourage regular breaks and being afk  away from keyboard  to support your wellbeing flexible working location  we like to meet in the office couple of times every week   annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays  and frequent pub trips pakt coffee and snacks of your choice in the office days holiday   bank holidays we re striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology  be that in terms of gender  race  or professional background if you think your skills and experience match what we re looking for and you d like to join a carbon tech industry unicorn  please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of the company s data platform \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development hadoop ecosystem experience java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   experience at \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " shed we are looking for experience in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the following things\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">csv  json and xml broader knowledge of it   e g   security and networking working in an agile environment test driven development and or behaviour driven development continuous integration and continuous deployment  ci cd optional experience the following is optional  but highly desirable experience  building reliable data pipelines experience of \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exploratory data analysis experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " of visualising data working with metrics  segments  aggregates  features requirements of the role maintain a broad knowledge of the technology landscape helping the data shed provide market leading assist our clients in enterprise scale projects utilising best practice development methodologies  well tested spend as much time on tests and security as on writing code work with a team of like minded  high calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that s broken  fix it  that includes the coffee machine benefits we have a variety of benefits including free access to an eap program  an auto enrolment pension scheme  a life assurance scheme  regular socials and a company performance based bonus and for any additional needs you have  we have a friendly and knowledgeable hr team to support you location we have a leeds hq and a flexible hybrid working policy  travel to client sites may be required from time to time  subject to business need ready to be a shedder we also celebrate each other s differences and encourage each other to explore new ways of thinking  the result is a diverse set of individuals who come together to create a multi talented  cohesive organisation  if you think that your uniqueness could make us even stronger  then please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">are you a data engineer interested in or currently working with autonomous vehicle technology  if so  we are looking to talk with you about your python software development skills  including exposure to working with vast volumes of data  in line with the opportunity to join oxbotica as a data engineer at oxbotica  we re fuelled by a bold purpose  to make the earth move from passenger shuttles to industrial vehicles  from congested city streets to mines  our industry leading autonomy software platform enables any vehicle to operate itself safely  securely and efficiently  we call it universal autonomy  it is changing how people and goods move we are a world class team guided by a shared vision to bring the benefits of autonomy to our customers and users  using our skills  \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " and diversity  we are solving the most exciting and important technological challenges of our times  and creating a safer and more sustainable future for people and our planet our    and growing  team members in the uk and canada are building  scaling and commercialising our universal autonomy software to serve immediate market and deployment opportunities we re seeking bold  creative  hyper skilled people to join us  come create the future of autonomy with us at oxbotica  become an  oxbot  the systems metrics team is a cross functional team that is responsible for ensuring transparent evaluation of our technology and operations  clarity and transparency is enabled through concrete evaluation criteria  well defined evaluation processes  and visibility of results we develop and maintain metrics that are visible to all internally within the company  as well as metrics that are visible to the company s external partners during demonstrations  po c deployments  and product releases  we utilise metrics to perform inference to further the improvement of our technology and operations  while striving to maximise coverage of metrics across all aspects of the company as a data engineer your day will include  but will not be limited to  using our python based metrics extraction tools that operate on data produced by oxbotica vehicles working closely with the data that the oxbotica fleet and processes produce and consume where is the data  has the data been offloaded from the producers has the data stream been processed is the data available for consumption designing  developing  and maintaining software while ensuring that data integrity is preserved throughout the data stream working closely with data infrastructure engineers to support implementation of tools that facilitate data driven inference on vast volumes of data supporting the development of autonomy components by clearly illustrating  via quantitative analysis  where we are as a company contributing to processes that show share metrics inferred from the data  e g  performance in autonomy  number of revokes per km  etc   and whether the metrics being computed are sufficient investigating what extra information can be extracted from the current raw data stream identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy requirements what you need to succeed proficiency in python software development skills  tools such as debugger  ide and profilers  proficiency with data science libraries such as pandas  numpy  scipy  bokeh  etc  familiarity with git the ability to maintain high quality code documentation experience with performing mathematically robust statistical analysis  data modelling  and predictive analytics the ability to interact with databases  e g  sql  ui skills for interacting with dashboards constructed using grafana  apache superset  etc the ability to clearly translate numbers into meaningful and informative diagrams extra kudos if you have software development skills in c   familiarity with robotics an understanding of machine learning an understanding of measuring operations and processes an understanding of data streaming processes our culture at oxbotica  our diverse and inclusive culture fuels our growth  we celebrate individuality  foster an environment in which trust and respect flourish  and believe that innovation thrives when powered by different perspectives  experiences and ideas  our purpose  values and principles anchor us as we grow learn more about our culture here benefits competitive salary company share programme hybrid and or flexible work arrangements an outstanding    flexible benefits including private medical insurance  critical illness coverage  life assurance  eap  group income protection funded relocation support fully funded visa sponsorship if required a salary exchange pension plan days annual leave plus bank holidays a pet friendly office environment safe assigned spaces for team members with individual and diverse needs</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">not only does that mean running and maintaining the solution that already exists  but also continually improving it to incorporate new data sources  and to derive new insights  to support ever evolving business demands as data engineer your primary responsibility will be to support a senior data engineer to create and maintain underlying data infrastructure that provides the wider team with the data they need to provide timely  accurate and meaningful deliverables   reporting  in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving  and in demand  industry some of the things we d like you to do assist the development of technical solutions  in line with specifications  that collect  store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures  helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies  ensuring your work incorporates industry best practice monitor automated jobs  troubleshooting data issues as and when they arise support other members of the team responsible for  last mile  transformation and visualization of data within google data studio reports and dashboards provide hands on support to users of reporting solutions  helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings  presenting your solutions and providing updates on your work support the development strong working relationships with third party data providers that we rely on for access to necessary data a bit about yourself required previous experience working with data and technology experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    programming\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and or statistical languages  e g  sql  python analytically minded  enabling you to understand and overcome technically complex challenges  and to tell compelling stories with data strong organizational skills and attention to detail  including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills  ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem  and an understanding of the role that data plays within it delivers best results when working in a team environment  and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl  particularly useful if done using google cloud platform  airflow  dbt etc experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    digital marketing platforms\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and the data they generate  in particular google marketing platform  facebook  twitter etc  knowledge of their api s a plus an understanding of how data is tracked and exchanged in the process of digital advertising  e g  role of ad servers and other third party tech vendors experience using or building reports with business intelligence software  ideally google data studio work experience within \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a marketing organization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  preferably at a media agency or related company  e g  publisher  ad tech  client marketing org what you can expect from essence essence s mission is to make advertising more valuable to the world  we do this by employing the world s very best talent to solve some of the toughest challenges of today s digital marketing landscape  it s important that we hire people whose values reflect those of our own  genuine  results focused  daring and insightful  as an essence employee  we promise you a workplace that invests in your career  cares for you and is fun and engaging  we believe these factors create a workplace where you can be yourself and do amazing work </br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job summary square enix has an internal cloud based platform  sgv   which provides our analytics   insight team and other groups across the business with a single data lake pooling game telemetry  sales information  marketing data  web analytics and other information duties include building  optimising and enhancing data acquisition pipelines working with client teams to ensure robust capture of high quality data supporting data analysts and other users of the data via with technical assistance this position requires a driven and talented person that can help the team progress requirements key deliverables build and test new functionality for existing pipelines alongside expanding the scope of data sources supported by the platform ensure the data engineering team deliver on requests from client teams to agreed specification and timelines ensure open and regular communication with other stakeholders as to the status of their projects work to ensure data engineering team is capable to deliver against responsibilities  ensure data is robust and of high quality provide data access and querying support to users both within the team and across the business have a good understanding of the scope  potential and limitations of the datasets maintained by the data engineering team  remaining alert to any opportunity to further employ our data to benefit the business evangelise the use of customer data to better understand our customers across the organisation  to always represent the team professionally   both internally and externally key stakeholders senior director digital channels  director of analytics   insight  data protection officer knowledge   experience essential programming experience in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    java   preferable  and python experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    testing frameworks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  junit  mockito  etc comfortable familiarity working with large data sets good sql skills strong problem solving skills experience writing batch etls on large datasets using various sources  e g  sql servers  rest apis  json files experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    build tools\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  such as gradle  maven  sbtfamiliarity with osx or linux environment  shell scripting  basic system administration etc  experience using source control collaboration tools such as git hub  bitbucket or git lab familiarity with collaboration and communication tools such as jira  confluence  slack etc desirable bsc or higher level degree in computer science  stem subject or a similar field of study experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cloud based engineering platforms\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  e g  gcp  aws  azure experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    apache beam experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    streaming data experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dag\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " based workflow management systems  ideally air flow competencies  skills   attributes essential ability to quickly learn and employ new technologies and methodologies  strong documentation skills ability to articulate and present ideas and information with ease and clarity ability to work on own initiative and as part of team other interest in technology  ambition to drive self development excellent attention to detail follower of industry trends and developments our goal at square enix is to hire  retain  develop and promote the best talent  regardless of age  gender  race  religious  belief  sexual orientation or physical ability our pledge to d iat square enix we believe in the importance of being a diverse and global company  and we stand firmly together against any forms of injustice  intolerance  harassment or discrimination  in our effort to create a truly diverse workforce  we pledge to continue to raise awareness in every step of the employee experience  from recruitment to promotions to ensure equal opportunities for all  one of our goals is to champion diversity in games and at work and work together to inspire real change learning and education around d </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">carwow is looking for a data engineer to join our platform engineering team on a full time basis in either a fully remote or hybrid capacity about carwow buying or selling a car shouldn t be difficult  that s why here at carwow we are on a mission to change the way people buy  sell or use a car by creating the world s best online car marketplace  we re not all petrolheads   just a highly driven  excuse the pun  scale up with over  carwowers in the uk  germany  spain and portugal  since starting our journey in   we ve grown to become one of the most trusted comparison sites with over  million users and a trustpilot rating of    we are also very proud to be backed by some of europe s most respected technology  marketplace and automotive investors about the role this year we re investing heavily in the continued growth of our analytics infrastructure and automotive pricing tribe and part of this growth has seen data engineering become its own entity  we are looking for someone to join the team and play a key role designing and building the data systems we use to make data driven decisions across the business and deliver great products   experiences to our customers you ll work closely with our data science and analytics teams in exploring and implementing ways to improve our current data systems whilst supporting with stand alone projects across each of our analytics verticals  we ll make sure you re supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout  requirements must have  sql  python  data infrastructure  sql etl elt knowledge  experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dags\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " to manage script dependencies with tools like airflow nice to have  snowflake  airflow  terraform  ruby  data visualisation tool  e g  looker  tableau  power bi   amplitude  dev ops  redshift  awsplease note  we know that no candidate will be the perfect match for all we ve listed in this posting  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> london  uk   full time a fantastic opportunity to be involved in end to end data management solutions for cutting edge advanced analytics and data science deployments who we are  at kearney analytics  we believe in the power of connected data  we are laser focused on helping organizations harness the interconnectedness of digital  data and decision making  we are problem solvers and builders focused on helping our clients win with data  our culture is cool and innovative  our environment is casual and conducive to collaboration and problem solving  we take our work seriously but not ourselves  it s the perfect balance of freedom and accountability  if you want to be part of something great   join us what can we offer competitive salary vitality private health care life insurance  accident insurance and long term disability insurance bupa annual wellness check  rrp      pension flu jab  eye test travelcard interest free loan annual performance bonus flexible working days annual leave   bank holidays about you you have experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    client projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and in handling vast amounts of data   working on database design and development  data integration and ingestion  designing etl architectures using a variety of etl tools and techniques  you are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled analytics team  play a key role on projects from a data engineering perspective  working with our architects and clients to model the data landscape  obtain data extracts and define secure data exchange approaches  this is a fantastic opportunity to be involved in end to end data management for cutting edge advanced analytics and data science job specifics plan and execute secure  best practice data integration strategies and approaches acquire  ingest  and process data from multiple sources and systems into big data platforms create and manage data environments in the cloud collaborate with our business analysts and data scientists to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models managing and monitoring the data integration process have a strong understanding of information security principles to ensure compliant handling and management of client data qualifications and required skills experience and desire to work with open source and branded open source frameworks experience working on projects within the cloud ideally aws  azure  gcp or snowflake experience working on agile delivery projects and a consulting setting  often working on different and multiple projects at the same time experience working with a variety of etl elt tools like matillion  talend  streamsets preferred strong development background with experience in at least one scripting  object oriented or functional programming language  etc   python  java  scala  c   r  bashexperience working with version control tools such as git hub  bitbucket data warehousing experience  building operational etl data pipelines across a number of sources  and constructing relational and dimensional data models excellent interpersonal skills when interacting with clients in a clear  timely  and professional manner desirable skills experience on \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    client facing projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  including working in close knit teams experience working in a cloud architecture with data lake experience and interest in big data technologies  spark   no sql dbs experience or familiarity with real time ingestion and streaming frameworks is a plus a deep personal motivation to always produce outstanding work for your clients and colleagues excel in team collaboration and working with others from diverse skill sets and background experience leading a team and driving them go deliver results solution delivery</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">she her hers  he him his  they them theirs  etc  introbumble is looking for an etl data engineer to participate in the development of the data collecting and data processing framework  services and tools for the cross functional data platform department  concretely  this means implementing  deploying and maintaining large scale data pipelines as well as internal data tools that help bumble provide a safe and engaging experience for \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    our users\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and improve the way bumble operates with millions of images and messages exchanged on our platform every day  there is a wealth of opportunity to make a real difference in this role and help people to find love all over the world  the ideal candidate combines strong business acumen  experience in \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data pipelines  databases\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and development best practices along with a passion for tech key accountabilities working with big data  tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team s ecosystem  dozens of in house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language  ability to write complex queries data warehousing and database basic architecture principles posix unix linux ecosystem knowledge experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    php python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " or desire to learn them we appreciate result oriented work style  flexibility in choosing tools and technical approaches nice to have experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exasol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and or snowflake databases good knowledge of sql  window functions  common table expressions  complex grouping etc  google cloud platform familiarity basic hadoop familiarity  hdfs hive about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a  can do  attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team s advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:10], extract_adp_experience_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d994f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 s, sys: 221 ms, total: 2.18 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%time ent_adp_df = extract_df(extract_adp_experience, n_max=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "350c1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 181 ms, total: 2.08 s\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%time ent_adp_df = extract_df(extract_adp_experience_2, n_max=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "019864a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.7 s, sys: 3.56 s, total: 1min 1s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%time ent_adp_df = extract_df(extract_adp_experience, n_max=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f6178b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>sql</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>python</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>performance tuning</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>building</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>any</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>design</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>backups  restores</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>data architecture</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>experience</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a range</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>data</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>the following</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>data visualisation tools</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>this role</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>aws</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>a similar data scientist role</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>excel</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>creation</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>dbt</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>python strong analytical skills</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>relational   non relational databases</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>data warehouse design</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>different data visualization</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>statistical packages</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a cloud platform</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>key data regulation</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>no sql</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a clinical  scientific or healthcare disciplin...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>clinical database management system developmen...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>database management</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>object oriented programming</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>strong medidata</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>big data</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>unstructured data</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>a variety</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>high availability</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>sql server</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>client facing projects</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>aws data technologies</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>the field</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>part</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>projects</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>solidatus</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>the financial services sector</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a statistical and or data science role</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>software engineering experience</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  n_company   n\n",
       "521                                                sql          7  17\n",
       "467                                             python          5  56\n",
       "442                                 performance tuning          4  13\n",
       "140                                           building          4  11\n",
       "90                                                 any          4   5\n",
       "275                                             design          3  31\n",
       "123                                  backups  restores          3  20\n",
       "204                                  data architecture          3  18\n",
       "321                                         experience          3  18\n",
       "29                                             a range          3  15\n",
       "193                                               data          3  14\n",
       "568                                      the following          3  14\n",
       "194                                      data analysis          3  13\n",
       "249                           data visualisation tools          3  10\n",
       "589                                          this role          3   7\n",
       "107                                                aws          3   4\n",
       "438                                             pandas          2  28\n",
       "36                       a similar data scientist role          2  25\n",
       "320                                              excel          2  15\n",
       "184                                           creation          2  14\n",
       "267                                                dbt          2  14\n",
       "473                    python strong analytical skills          2  14\n",
       "490              relational   non relational databases          2  14\n",
       "252                              data warehouse design          2  13\n",
       "284                       different data visualization          2  13\n",
       "539                               statistical packages          2  13\n",
       "5                                     a cloud platform          2  12\n",
       "373                                key data regulation          2  12\n",
       "423                                             no sql          2  12\n",
       "3    a clinical  scientific or healthcare disciplin...          2  10\n",
       "158  clinical database management system developmen...          2  10\n",
       "261                                database management          2  10\n",
       "425                        object oriented programming          2  10\n",
       "545                                    strong medidata          2  10\n",
       "125                                           big data          2   9\n",
       "598                                  unstructured data          2   8\n",
       "48                                           a variety          2   5\n",
       "354                                  high availability          2   5\n",
       "367                                                 it          2   5\n",
       "529                                         sql server          2   5\n",
       "156                             client facing projects          2   4\n",
       "111                              aws data technologies          2   3\n",
       "383                                   machine learning          2   3\n",
       "563                                          the field          2   3\n",
       "439                                               part          2   2\n",
       "463                                           projects          2   2\n",
       "514                                          solidatus          2   2\n",
       "567                      the financial services sector          2   2\n",
       "45              a statistical and or data science role          1  32\n",
       "513                    software engineering experience          1  32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df(ent_adp_df).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ad08c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_text_context(terms, texts, n_before=1, n_after=2):\n",
    "    context = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        sentences = list(doc.sents)\n",
    "        idxs = [i for i, sent in enumerate(sentences) if any(term in sent.text.lower() for term in terms)]\n",
    "        \n",
    "        for idx in idxs:\n",
    "            before = ''.join(sent.text for sent in sentences[max(idx-n_before, 0):idx])\n",
    "            after = ''.join(sent.text for sent in sentences[idx+1:min(idx+n_before+1, len(sentences))])\n",
    "            text = sentences[idx].text\n",
    "            markup = re.sub(fr'(?i)\\b({\"|\".join(terms)})\\b', r'<strong>\\1</strong>',\n",
    "                                 f'<span style=\"color:blue\">{text}</span>')\n",
    "            display(HTML(before + markup + after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4e73edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['experience']\n",
    "\n",
    "for _, q in ent_adp_df.query(\"text=='a'\").head(7).iterrows():\n",
    "    doc = nlp(q.FullDescription)\n",
    "    if q.sent_start > 0:\n",
    "        prev_sent = doc[q.sent_start - 1].sent.text\n",
    "    else:\n",
    "        prev_sent = ''\n",
    "    \n",
    "    if q.sent_end < len(doc):\n",
    "        next_sent = doc[q.sent_end].sent.text\n",
    "    else:\n",
    "        next_sent = ''\n",
    "        \n",
    "    text = doc[q.sent_start:q.sent_end].text\n",
    "    markup = re.sub(fr'(?i)\\b({\"|\".join(terms)})\\b', r'<strong>\\1</strong>',\n",
    "                     f'<span style=\"color:blue\">{text}</span>')\n",
    "    display(HTML(prev_sent + markup + next_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64e77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_span(tok, label='', include=True):\n",
    "    offset = 1 if include else 0\n",
    "    idx = tok.i\n",
    "    while idx > tok.left_edge.i:\n",
    "        if tok.doc[idx - 1].pos_ in ('NOUN', 'PROPN', 'ADJ', 'X'):\n",
    "            idx -= 1\n",
    "        else:\n",
    "            break\n",
    "    return label, idx, tok.i+offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2c380c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conjugations(tok):\n",
    "    new = [tok]\n",
    "    while new:\n",
    "        tok = new.pop()\n",
    "        yield tok\n",
    "        for child in tok.children:\n",
    "            if child.dep_ == 'conj':\n",
    "                new.append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b2567b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "EXP_TERMS = ['experience']\n",
    "def extract_adp_conj_experience(doc, label='EXPERIENCE'):\n",
    "    for tok in doc:\n",
    "        if tok.lower_ in EXP_TERMS:\n",
    "            for child in tok.rights:\n",
    "                if child.dep_ == 'prep':\n",
    "                    for obj in child.children:\n",
    "                        if obj.dep_ == 'pobj':\n",
    "                            for conj in get_conjugations(obj):\n",
    "                                yield get_left_span(conj, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69d4344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">and we don t believe in a siloed approach  our data engineers sit side by side with software engineers and designers  making sure that we have the data we need to provide the \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " our customers want  you ll be deeply embedded in the product team  with your work being deployed to clients every week  you ll work closely with our domain experts  and have the chance to present to clients if that s something that excites you you can expect to have ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python  we deploy our work in a variety of ways depending upon the challenge  from lambdas to docker containers  our etl is run in dagster  which is a friendlier and more modern version of airflow  you d be joining an experienced team but you d be the first data engineer  so you d have lots of scope to define best practices and choose your tools we re interested in talking to people with dev ops and classical software engineering experience  as well as those coming from data science who have a passion for scaling etl systems our only must haves are possessing a hunger to solve business challenges using technology  the ability to build close relationships with your team  and the right to work in the uk which tools  technologies  and processes will you work with data processing with the standard scientific stack  pandas  numpy  scipy  and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will object oriented code forms the bulk of our codebase postgre sql and dynamo </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">db managed databases form the persistence layer   you ll learn to navigate document and relational databases and appreciate the values in both worlds infrastructure automation is owned by the whole team  helping to spread the dev ops mentality across the whole technology department  and beyond  you don t need to be a pro at all of these skills to apply for the role  but we d love to hear about any relevant knowledge and experiences that you have in these areas what we require from applicants right to work in the uk and willingness to come to london office   days a week  years of commercial data engeering  data science  or software engineering \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we re offering competitive salary   generous equity package flexible working hours   we encourage regular breaks and being afk  away from keyboard  to support your wellbeing flexible working location  we like to meet in the office couple of times every week   annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays  and frequent pub trips pakt coffee and snacks of your choice in the office days holiday   bank holidays we re striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology  be that in terms of gender  race  or professional background if you think your skills and experience match what we re looking for and you d like to join a carbon tech industry unicorn  please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of the company s data platform \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development hadoop ecosystem experience java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   experience at the \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " shed we are looking for experience in the following \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    things\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">csv  json and xml broader knowledge of it   e g   security and networking working in an agile environment test driven development and or behaviour driven development continuous integration and continuous deployment  ci cd optional experience the following is optional  but highly desirable experience  building reliable data pipelines experience of \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exploratory data analysis experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " of visualising data working with metrics  segments  aggregates  features requirements of the role maintain a broad knowledge of the technology landscape helping the data shed provide market leading assist our clients in enterprise scale projects utilising best practice development methodologies  well tested spend as much time on tests and security as on writing code work with a team of like minded  high calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that s broken  fix it  that includes the coffee machine benefits we have a variety of benefits including free access to an eap program  an auto enrolment pension scheme  a life assurance scheme  regular socials and a company performance based bonus and for any additional needs you have  we have a friendly and knowledgeable hr team to support you location we have a leeds hq and a flexible hybrid working policy  travel to client sites may be required from time to time  subject to business need ready to be a shedder we also celebrate each other s differences and encourage each other to explore new ways of thinking  the result is a diverse set of individuals who come together to create a multi talented  cohesive organisation  if you think that your uniqueness could make us even stronger  then please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">are you a data engineer interested in or currently working with autonomous vehicle technology  if so  we are looking to talk with you about your python software development skills  including exposure to working with vast volumes of data  in line with the opportunity to join oxbotica as a data engineer at oxbotica  we re fuelled by a bold purpose  to make the earth move from passenger shuttles to industrial vehicles  from congested city streets to mines  our industry leading autonomy software platform enables any vehicle to operate itself safely  securely and efficiently  we call it universal autonomy  it is changing how people and goods move we are a world class team guided by a shared vision to bring the benefits of autonomy to our customers and users  using our skills  \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " and diversity  we are solving the most exciting and important technological challenges of our times  and creating a safer and more sustainable future for people and our planet our    and growing  team members in the uk and canada are building  scaling and commercialising our universal autonomy software to serve immediate market and deployment opportunities we re seeking bold  creative  hyper skilled people to join us  come create the future of autonomy with us at oxbotica  become an  oxbot  the systems metrics team is a cross functional team that is responsible for ensuring transparent evaluation of our technology and operations  clarity and transparency is enabled through concrete evaluation criteria  well defined evaluation processes  and visibility of results we develop and maintain metrics that are visible to all internally within the company  as well as metrics that are visible to the company s external partners during demonstrations  po c deployments  and product releases  we utilise metrics to perform inference to further the improvement of our technology and operations  while striving to maximise coverage of metrics across all aspects of the company as a data engineer your day will include  but will not be limited to  using our python based metrics extraction tools that operate on data produced by oxbotica vehicles working closely with the data that the oxbotica fleet and processes produce and consume where is the data  has the data been offloaded from the producers has the data stream been processed is the data available for consumption designing  developing  and maintaining software while ensuring that data integrity is preserved throughout the data stream working closely with data infrastructure engineers to support implementation of tools that facilitate data driven inference on vast volumes of data supporting the development of autonomy components by clearly illustrating  via quantitative analysis  where we are as a company contributing to processes that show share metrics inferred from the data  e g  performance in autonomy  number of revokes per km  etc   and whether the metrics being computed are sufficient investigating what extra information can be extracted from the current raw data stream identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy requirements what you need to succeed proficiency in python software development skills  tools such as debugger  ide and profilers  proficiency with data science libraries such as pandas  numpy  scipy  bokeh  etc  familiarity with git the ability to maintain high quality code documentation experience with performing mathematically robust statistical analysis  data modelling  and predictive analytics the ability to interact with databases  e g  sql  ui skills for interacting with dashboards constructed using grafana  apache superset  etc the ability to clearly translate numbers into meaningful and informative diagrams extra kudos if you have software development skills in c   familiarity with robotics an understanding of machine learning an understanding of measuring operations and processes an understanding of data streaming processes our culture at oxbotica  our diverse and inclusive culture fuels our growth  we celebrate individuality  foster an environment in which trust and respect flourish  and believe that innovation thrives when powered by different perspectives  experiences and ideas  our purpose  values and principles anchor us as we grow learn more about our culture here benefits competitive salary company share programme hybrid and or flexible work arrangements an outstanding    flexible benefits including private medical insurance  critical illness coverage  life assurance  eap  group income protection funded relocation support fully funded visa sponsorship if required a salary exchange pension plan days annual leave plus bank holidays a pet friendly office environment safe assigned spaces for team members with individual and diverse needs</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">not only does that mean running and maintaining the solution that already exists  but also continually improving it to incorporate new data sources  and to derive new insights  to support ever evolving business demands as data engineer your primary responsibility will be to support a senior data engineer to create and maintain underlying data infrastructure that provides the wider team with the data they need to provide timely  accurate and meaningful deliverables   reporting  in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving  and in demand  industry some of the things we d like you to do assist the development of technical solutions  in line with specifications  that collect  store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures  helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies  ensuring your work incorporates industry best practice monitor automated jobs  troubleshooting data issues as and when they arise support other members of the team responsible for  last mile  transformation and visualization of data within google data studio reports and dashboards provide hands on support to users of reporting solutions  helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings  presenting your solutions and providing updates on your work support the development strong working relationships with third party data providers that we rely on for access to necessary data a bit about yourself required previous experience working with data and technology experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    programming\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and or \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    statistical languages\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  e g  sql  python analytically minded  enabling you to understand and overcome technically complex challenges  and to tell compelling stories with data strong organizational skills and attention to detail  including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills  ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem  and an understanding of the role that data plays within it delivers best results when working in a team environment  and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl  particularly useful if done using google cloud platform  airflow  dbt etc experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    digital marketing platforms\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and the \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " they generate  in particular google marketing platform  facebook  twitter etc  knowledge of their api s a plus an understanding of how data is tracked and exchanged in the process of digital advertising  e g  role of ad servers and other third party tech vendors experience using or building reports with business intelligence software  ideally google data studio work experience within a \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    marketing organization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  preferably at a media agency or related company  e g  publisher  ad tech  client marketing org what you can expect from essence essence s mission is to make advertising more valuable to the world  we do this by employing the world s very best talent to solve some of the toughest challenges of today s digital marketing landscape  it s important that we hire people whose values reflect those of our own  genuine  results focused  daring and insightful  as an essence employee  we promise you a workplace that invests in your career  cares for you and is fun and engaging  we believe these factors create a workplace where you can be yourself and do amazing work </br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job summary square enix has an internal cloud based platform  sgv   which provides our analytics   insight team and other groups across the business with a single data lake pooling game telemetry  sales information  marketing data  web analytics and other information duties include building  optimising and enhancing data acquisition pipelines working with client teams to ensure robust capture of high quality data supporting data analysts and other users of the data via with technical assistance this position requires a driven and talented person that can help the team progress requirements key deliverables build and test new functionality for existing pipelines alongside expanding the scope of data sources supported by the platform ensure the data engineering team deliver on requests from client teams to agreed specification and timelines ensure open and regular communication with other stakeholders as to the status of their projects work to ensure data engineering team is capable to deliver against responsibilities  ensure data is robust and of high quality provide data access and querying support to users both within the team and across the business have a good understanding of the scope  potential and limitations of the datasets maintained by the data engineering team  remaining alert to any opportunity to further employ our data to benefit the business evangelise the use of customer data to better understand our customers across the organisation  to always represent the team professionally   both internally and externally key stakeholders senior director digital channels  director of analytics   insight  data protection officer knowledge   experience essential programming experience in java   preferable  and python experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    testing frameworks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  junit  mockito  etc comfortable familiarity working with large data sets good sql skills strong problem solving skills experience writing batch etls on large datasets using various sources  e g  sql servers  rest apis  json files experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    build tools\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  such as gradle  maven  sbtfamiliarity with osx or linux environment  shell scripting  basic system administration etc  experience using source control collaboration tools such as git hub  bitbucket or git lab familiarity with collaboration and communication tools such as jira  confluence  slack etc desirable bsc or higher level degree in computer science  stem subject or a similar field of study experience with cloud based \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    engineering platforms\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  e g  gcp  aws  azure experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    apache beam experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    streaming data experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dag\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " based workflow management systems  ideally air flow competencies  skills   attributes essential ability to quickly learn and employ new technologies and methodologies  strong documentation skills ability to articulate and present ideas and information with ease and clarity ability to work on own initiative and as part of team other interest in technology  ambition to drive self development excellent attention to detail follower of industry trends and developments our goal at square enix is to hire  retain  develop and promote the best talent  regardless of age  gender  race  religious  belief  sexual orientation or physical ability our pledge to d iat square enix we believe in the importance of being a diverse and global company  and we stand firmly together against any forms of injustice  intolerance  harassment or discrimination  in our effort to create a truly diverse workforce  we pledge to continue to raise awareness in every step of the employee experience  from \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    recruitment\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " to promotions to ensure equal opportunities for all  one of our goals is to champion diversity in games and at work and work together to inspire real change learning and education around d </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">carwow is looking for a data engineer to join our platform engineering team on a full time basis in either a fully remote or hybrid capacity about carwow buying or selling a car shouldn t be difficult  that s why here at carwow we are on a mission to change the way people buy  sell or use a car by creating the world s best online car marketplace  we re not all petrolheads   just a highly driven  excuse the pun  scale up with over  carwowers in the uk  germany  spain and portugal  since starting our journey in   we ve grown to become one of the most trusted comparison sites with over  million users and a trustpilot rating of    we are also very proud to be backed by some of europe s most respected technology  marketplace and automotive investors about the role this year we re investing heavily in the continued growth of our analytics infrastructure and automotive pricing tribe and part of this growth has seen data engineering become its own entity  we are looking for someone to join the team and play a key role designing and building the data systems we use to make data driven decisions across the business and deliver great products   experiences to our customers you ll work closely with our data science and analytics teams in exploring and implementing ways to improve our current data systems whilst supporting with stand alone projects across each of our analytics verticals  we ll make sure you re supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout  requirements must have  sql  python  data infrastructure  sql etl elt knowledge  experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dags\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " to manage script dependencies with tools like airflow nice to have  snowflake  airflow  terraform  ruby  data visualisation tool  e g  looker  tableau  power bi   amplitude  dev ops  redshift  awsplease note  we know that no candidate will be the perfect match for all we ve listed in this posting  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> london  uk   full time a fantastic opportunity to be involved in end to end data management solutions for cutting edge advanced analytics and data science deployments who we are  at kearney analytics  we believe in the power of connected data  we are laser focused on helping organizations harness the interconnectedness of digital  data and decision making  we are problem solvers and builders focused on helping our clients win with data  our culture is cool and innovative  our environment is casual and conducive to collaboration and problem solving  we take our work seriously but not ourselves  it s the perfect balance of freedom and accountability  if you want to be part of something great   join us what can we offer competitive salary vitality private health care life insurance  accident insurance and long term disability insurance bupa annual wellness check  rrp      pension flu jab  eye test travelcard interest free loan annual performance bonus flexible working days annual leave   bank holidays about you you have experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    client projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and in handling vast amounts of data   working on database design and development  data integration and ingestion  designing etl architectures using a variety of etl tools and techniques  you are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled analytics team  play a key role on projects from a data engineering perspective  working with our architects and clients to model the data landscape  obtain data extracts and define secure data exchange approaches  this is a fantastic opportunity to be involved in end to end data management for cutting edge advanced analytics and data science job specifics plan and execute secure  best practice data integration strategies and approaches acquire  ingest  and process data from multiple sources and systems into big data platforms create and manage data environments in the cloud collaborate with our business analysts and data scientists to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models managing and monitoring the data integration process have a strong understanding of information security principles to ensure compliant handling and management of client data qualifications and required skills experience and desire to work with open source and branded open source frameworks experience working on projects within the cloud ideally aws  azure  gcp or snowflake experience working on agile delivery projects and a consulting setting  often working on different and multiple projects at the same time experience working with a variety of etl elt tools like matillion  talend  streamsets preferred strong development background with experience in at least one scripting  object oriented or functional programming language  etc   python  java  scala  c   r  bashexperience working with version control tools such as git hub  bitbucket data warehousing experience  building operational etl data pipelines across a number of sources  and constructing relational and dimensional data models excellent interpersonal skills when interacting with clients in a clear  timely  and professional manner desirable skills experience on \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    client facing projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  including working in close knit teams experience working in a cloud architecture with data lake experience and interest in big data technologies  \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    spark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "   no sql dbs experience or familiarity with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    real time ingestion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    streaming frameworks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " is a plus a deep personal motivation to always produce outstanding work for your clients and colleagues excel in team collaboration and working with others from diverse skill sets and background experience leading a team and driving them go deliver results solution delivery</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">she her hers  he him his  they them theirs  etc  introbumble is looking for an etl data engineer to participate in the development of the data collecting and data processing framework  services and tools for the cross functional data platform department  concretely  this means implementing  deploying and maintaining large scale data pipelines as well as internal data tools that help bumble provide a safe and engaging experience for our \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    users\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and improve the way bumble operates with millions of images and messages exchanged on our platform every day  there is a wealth of opportunity to make a real difference in this role and help people to find love all over the world  the ideal candidate combines strong business acumen  experience in data pipelines  \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    databases\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    development best practices\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " along with a passion for tech key accountabilities working with big data  tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team s ecosystem  dozens of in house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language  ability to write complex queries data warehousing and database basic architecture principles posix unix linux ecosystem knowledge experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    php python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " or desire to learn them we appreciate result oriented work style  flexibility in choosing tools and technical approaches nice to have experience with \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exasol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and or snowflake databases good knowledge of sql  window functions  common table expressions  complex grouping etc  google cloud platform familiarity basic hadoop familiarity  hdfs hive about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a  can do  attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team s advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:10], extract_adp_conj_experience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5800ae9",
   "metadata": {},
   "source": [
    "# Extracting Verbs followed by Adposition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1146f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_verb_maybeadj_noun_experience(doc, label='EXPERIENCE'):\n",
    "    for tok in doc:\n",
    "        if tok.lower_ in EXP_TERMS:\n",
    "            for child in tok.rights:\n",
    "                if child.dep_ == 'acl':\n",
    "                    for gc in child.children:\n",
    "                        if gc.dep_ == 'prep':\n",
    "                            for ggc in gc.children:\n",
    "                                if ggc.dep_ == 'pobj':\n",
    "                                    for c in get_conjugations(ggc):\n",
    "                                        yield get_left_span(c, 'EXPERIENCE')\n",
    "                        elif gc.dep_ == 'dobj':\n",
    "                            for c in get_conjugations(gc):\n",
    "                                yield get_left_span(c, 'EXPERIENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c8841a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">and we don t believe in a siloed approach  our data engineers sit side by side with software engineers and designers  making sure that we have the data we need to provide the \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " our customers want  you ll be deeply embedded in the product team  with your work being deployed to clients every week  you ll work closely with our domain experts  and have the chance to present to clients if that s something that excites you you can expect to have ownership of your projects an independent path to production the ability to make real changes with tangible business value our data science stack is predominantly python  we deploy our work in a variety of ways depending upon the challenge  from lambdas to docker containers  our etl is run in dagster  which is a friendlier and more modern version of airflow  you d be joining an experienced team but you d be the first data engineer  so you d have lots of scope to define best practices and choose your tools we re interested in talking to people with dev ops and classical software engineering experience  as well as those coming from data science who have a passion for scaling etl systems our only must haves are possessing a hunger to solve business challenges using technology  the ability to build close relationships with your team  and the right to work in the uk which tools  technologies  and processes will you work with data processing with the standard scientific stack  pandas  numpy  scipy  and beyond automation with dagster and github actions deployment via gcpcontainerised applications are the key to our technology vision allowing us to replicate production environments locally and scale services at will object oriented code forms the bulk of our codebase postgre sql and dynamo </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">db managed databases form the persistence layer   you ll learn to navigate document and relational databases and appreciate the values in both worlds infrastructure automation is owned by the whole team  helping to spread the dev ops mentality across the whole technology department  and beyond  you don t need to be a pro at all of these skills to apply for the role  but we d love to hear about any relevant knowledge and experiences that you have in these areas what we require from applicants right to work in the uk and willingness to come to london office   days a week  years of commercial data engeering  data science  or software engineering \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " a passion for environmental issues a demonstrated interest in building products and collaborating tightly with scientists and engineers the grit and energy to work in an early stage startup what we re offering competitive salary   generous equity package flexible working hours   we encourage regular breaks and being afk  away from keyboard  to support your wellbeing flexible working location  we like to meet in the office couple of times every week   annual development allowance for you to spend on developing your current skills and learning new things tech equipment of your choice team lunch on wednesdays  and frequent pub trips pakt coffee and snacks of your choice in the office days holiday   bank holidays we re striving to build a diverse team and we would love to hear from applicants from backgrounds less frequently represented in technology  be that in terms of gender  race  or professional background if you think your skills and experience match what we re looking for and you d like to join a carbon tech industry unicorn  please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">bumble s data definition and collection framework provide data to the company s analysts and decision makers by supporting and developing massive data pipelines define the look and feel of bi by developing internal tools upgrade the existing data platform by integrating internal and external data sources  reporting tools and databases support and evolve the underlying infrastructure of the company s data platform \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " we are looking for advanced level python for backend development advanced knowledge of the posix unix linux ecosystem sql based and relational databases  especially data warehouse solutions understanding of popular code development approaches test driven development continuous integration continuous deployment containerized service development desirable skills typescript react for ui development hadoop ecosystem experience java spark programming google cloud platform familiarity snowflake familiarity basic php familiarity about you you are not afraid to learn and build complex systems you are a self starter  you thrive on taking ownership of initiatives with limited oversight you are positive and committed with a  can do  attitude and a flexible approach you know how to manage multiple priorities  breaking large projects into manageable pieces you are the first to notice issues and opportunities and are able to exploit these to your team s advantage you are deeply passionate about bumble s brand vision and values</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " at the data shed we are looking for experience in the following things  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">csv  json and xml broader knowledge of it   e g   security and networking working in an agile environment test driven development and or behaviour driven development continuous integration and continuous deployment  ci cd optional experience the following is optional  but highly desirable experience  building \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    reliable data pipelines experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " of exploratory data analysis experience of visualising data working with metrics  segments  aggregates  features requirements of the role maintain a broad knowledge of the technology landscape helping the data shed provide market leading assist our clients in enterprise scale projects utilising best practice development methodologies  well tested spend as much time on tests and security as on writing code work with a team of like minded  high calibre engineers to translate user requirements into working code working collaboratively across the team lead definition and maintenance of best practice and standards in development and design principles and process never make the same mistake twice make it right and only then make it fast if you see something that s broken  fix it  that includes the coffee machine benefits we have a variety of benefits including free access to an eap program  an auto enrolment pension scheme  a life assurance scheme  regular socials and a company performance based bonus and for any additional needs you have  we have a friendly and knowledgeable hr team to support you location we have a leeds hq and a flexible hybrid working policy  travel to client sites may be required from time to time  subject to business need ready to be a shedder we also celebrate each other s differences and encourage each other to explore new ways of thinking  the result is a diverse set of individuals who come together to create a multi talented  cohesive organisation  if you think that your uniqueness could make us even stronger  then please get in touch </br>      </br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">are you a data engineer interested in or currently working with autonomous vehicle technology  if so  we are looking to talk with you about your python software development skills  including exposure to working with vast volumes of data  in line with the opportunity to join oxbotica as a data engineer at oxbotica  we re fuelled by a bold purpose  to make the earth move from passenger shuttles to industrial vehicles  from congested city streets to mines  our industry leading autonomy software platform enables any vehicle to operate itself safely  securely and efficiently  we call it universal autonomy  it is changing how people and goods move we are a world class team guided by a shared vision to bring the benefits of autonomy to our customers and users  using our skills  \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " and diversity  we are solving the most exciting and important technological challenges of our times  and creating a safer and more sustainable future for people and our planet our    and growing  team members in the uk and canada are building  scaling and commercialising our universal autonomy software to serve immediate market and deployment opportunities we re seeking bold  creative  hyper skilled people to join us  come create the future of autonomy with us at oxbotica  become an  oxbot  the systems metrics team is a cross functional team that is responsible for ensuring transparent evaluation of our technology and operations  clarity and transparency is enabled through concrete evaluation criteria  well defined evaluation processes  and visibility of results we develop and maintain metrics that are visible to all internally within the company  as well as metrics that are visible to the company s external partners during demonstrations  po c deployments  and product releases  we utilise metrics to perform inference to further the improvement of our technology and operations  while striving to maximise coverage of metrics across all aspects of the company as a data engineer your day will include  but will not be limited to  using our python based metrics extraction tools that operate on data produced by oxbotica vehicles working closely with the data that the oxbotica fleet and processes produce and consume where is the data  has the data been offloaded from the producers has the data stream been processed is the data available for consumption designing  developing  and maintaining software while ensuring that data integrity is preserved throughout the data stream working closely with data infrastructure engineers to support implementation of tools that facilitate data driven inference on vast volumes of data supporting the development of autonomy components by clearly illustrating  via quantitative analysis  where we are as a company contributing to processes that show share metrics inferred from the data  e g  performance in autonomy  number of revokes per km  etc   and whether the metrics being computed are sufficient investigating what extra information can be extracted from the current raw data stream identify methods for detecting patterns in the raw and processed data that support development of components responsible for autonomy requirements what you need to succeed proficiency in python software development skills  tools such as debugger  ide and profilers  proficiency with data science libraries such as pandas  numpy  scipy  bokeh  etc  familiarity with git the ability to maintain high quality code documentation experience with performing mathematically robust statistical analysis  data modelling  and predictive analytics the ability to interact with databases  e g  sql  ui skills for interacting with dashboards constructed using grafana  apache superset  etc the ability to clearly translate numbers into meaningful and informative diagrams extra kudos if you have software development skills in c   familiarity with robotics an understanding of machine learning an understanding of measuring operations and processes an understanding of data streaming processes our culture at oxbotica  our diverse and inclusive culture fuels our growth  we celebrate individuality  foster an environment in which trust and respect flourish  and believe that innovation thrives when powered by different perspectives  experiences and ideas  our purpose  values and principles anchor us as we grow learn more about our culture here benefits competitive salary company share programme hybrid and or flexible work arrangements an outstanding    flexible benefits including private medical insurance  critical illness coverage  life assurance  eap  group income protection funded relocation support fully funded visa sponsorship if required a salary exchange pension plan days annual leave plus bank holidays a pet friendly office environment safe assigned spaces for team members with individual and diverse needs</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">not only does that mean running and maintaining the solution that already exists  but also continually improving it to incorporate new data sources  and to derive new insights  to support ever evolving business demands as data engineer your primary responsibility will be to support a senior data engineer to create and maintain underlying data infrastructure that provides the wider team with the data they need to provide timely  accurate and meaningful deliverables   reporting  in doing so you will gain a foundational understanding of cloud technology and key data engineering skills and knowledge to help you build a career in this fast evolving  and in demand  industry some of the things we d like you to do assist the development of technical solutions  in line with specifications  that collect  store and transform disparate data sources assist the development and maintenance of automated jobs that ensure required data is made available in an efficient and scalable way as possible assist the development and maintenance of data quality checks and procedures  helping account teams overcome data issues before they impact the quality of the reporting solution support the translation of user requirements and business needs into technical specifications become a proficient user of google cloud platform and associated technologies  ensuring your work incorporates industry best practice monitor automated jobs  troubleshooting data issues as and when they arise support other members of the team responsible for  last mile  transformation and visualization of data within google data studio reports and dashboards provide hands on support to users of reporting solutions  helping the wider team triage and respond to user queries in a timely manner attend internal stakeholder meetings  presenting your solutions and providing updates on your work support the development strong working relationships with third party data providers that we rely on for access to necessary data a bit about yourself required previous experience working with data and \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    technology experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " with programming and or statistical languages  e g  sql  python analytically minded  enabling you to understand and overcome technically complex challenges  and to tell compelling stories with data strong organizational skills and attention to detail  including the ability to manage multiple tasks in a fairly autonomous way strong spoken and written communication skills  ensuring your thoughts and needs are heard and understood an ability to demonstrate a passion for the digital marketing ecosystem  and an understanding of the role that data plays within it delivers best results when working in a team environment  and an ability to partner effectively with people of varying degrees of technical capability desirable experience building underlying data pipelines and etl  particularly useful if done using google cloud platform  airflow  dbt etc experience with digital marketing platforms and the data they generate  in particular google marketing platform  facebook  twitter etc  knowledge of their api s a plus an understanding of how data is tracked and exchanged in the process of digital advertising  e g  role of ad servers and other third party tech vendors experience using or building reports with business intelligence software  ideally google data studio work experience within a marketing organization  preferably at a media agency or related company  e g  publisher  ad tech  client marketing org what you can expect from essence essence s mission is to make advertising more valuable to the world  we do this by employing the world s very best talent to solve some of the toughest challenges of today s digital marketing landscape  it s important that we hire people whose values reflect those of our own  genuine  results focused  daring and insightful  as an essence employee  we promise you a workplace that invests in your career  cares for you and is fun and engaging  we believe these factors create a workplace where you can be yourself and do amazing work </br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> job summary square enix has an internal cloud based platform  sgv   which provides our analytics   insight team and other groups across the business with a single data lake pooling game telemetry  sales information  marketing data  web analytics and other information duties include building  optimising and enhancing data acquisition pipelines working with client teams to ensure robust capture of high quality data supporting data analysts and other users of the data via with technical assistance this position requires a driven and talented person that can help the team progress requirements key deliverables build and test new functionality for existing pipelines alongside expanding the scope of data sources supported by the platform ensure the data engineering team deliver on requests from client teams to agreed specification and timelines ensure open and regular communication with other stakeholders as to the status of their projects work to ensure data engineering team is capable to deliver against responsibilities  ensure data is robust and of high quality provide data access and querying support to users both within the team and across the business have a good understanding of the scope  potential and limitations of the datasets maintained by the data engineering team  remaining alert to any opportunity to further employ our data to benefit the business evangelise the use of customer data to better understand our customers across the organisation  to always represent the team professionally   both internally and externally key stakeholders senior director digital channels  director of analytics   insight  data protection officer knowledge   \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " essential programming experience in java   preferable  and python experience with testing frameworks  junit  mockito  etc comfortable familiarity working with large data sets good sql skills strong problem solving skills experience writing batch etls on large datasets using various sources  e g  sql servers  rest apis  json files experience with build tools  such as gradle  maven  sbtfamiliarity with osx or linux environment  shell scripting  basic system administration etc  experience using source control collaboration tools such as git hub  bitbucket or git lab familiarity with collaboration and communication tools such as jira  confluence  slack etc desirable bsc or higher level degree in computer science  stem subject or a similar field of study experience with cloud based engineering platforms  e g  gcp  aws  azure experience with apache beam experience with streaming data experience with dag based workflow management systems  ideally air flow competencies  skills   attributes essential ability to quickly learn and employ new technologies and methodologies  strong documentation skills ability to articulate and present ideas and information with ease and clarity ability to work on own initiative and as part of team other interest in technology  ambition to drive self development excellent attention to detail follower of industry trends and developments our goal at square enix is to hire  retain  develop and promote the best talent  regardless of age  gender  race  religious  belief  sexual orientation or physical ability our pledge to d iat square enix we believe in the importance of being a diverse and global company  and we stand firmly together against any forms of injustice  intolerance  harassment or discrimination  in our effort to create a truly diverse workforce  we pledge to continue to raise awareness in every step of the employee experience  from recruitment to promotions to ensure equal opportunities for all  one of our goals is to champion diversity in games and at work and work together to inspire real change learning and education around d </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">carwow is looking for a data engineer to join our platform engineering team on a full time basis in either a fully remote or hybrid capacity about carwow buying or selling a car shouldn t be difficult  that s why here at carwow we are on a mission to change the way people buy  sell or use a car by creating the world s best online car marketplace  we re not all petrolheads   just a highly driven  excuse the pun  scale up with over  carwowers in the uk  germany  spain and portugal  since starting our journey in   we ve grown to become one of the most trusted comparison sites with over  million users and a trustpilot rating of    we are also very proud to be backed by some of europe s most respected technology  marketplace and automotive investors about the role this year we re investing heavily in the continued growth of our analytics infrastructure and automotive pricing tribe and part of this growth has seen data engineering become its own entity  we are looking for someone to join the team and play a key role designing and building the data systems we use to make data driven decisions across the business and deliver great products   experiences to our customers you ll work closely with our data science and analytics teams in exploring and implementing ways to improve our current data systems whilst supporting with stand alone projects across each of our analytics verticals  we ll make sure you re supported by our team of experienced engineers and give you plenty of opportunities to get collaborate on a range of business critical projects throughout  requirements must have  sql  python  data infrastructure  sql etl elt knowledge  \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " with dags to manage script dependencies with tools like airflow nice to have  snowflake  airflow  terraform  ruby  data visualisation tool  e g  looker  tableau  power bi   amplitude  dev ops  redshift  awsplease note  we know that no candidate will be the perfect match for all we ve listed in this posting  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> london  uk   full time a fantastic opportunity to be involved in end to end data management solutions for cutting edge advanced analytics and data science deployments who we are  at kearney analytics  we believe in the power of connected data  we are laser focused on helping organizations harness the interconnectedness of digital  data and decision making  we are problem solvers and builders focused on helping our clients win with data  our culture is cool and innovative  our environment is casual and conducive to collaboration and problem solving  we take our work seriously but not ourselves  it s the perfect balance of freedom and accountability  if you want to be part of something great   join us what can we offer competitive salary vitality private health care life insurance  accident insurance and long term disability insurance bupa annual wellness check  rrp      pension flu jab  eye test travelcard interest free loan annual performance bonus flexible working days annual leave   bank holidays about you you have experience with client projects and in handling vast amounts of data   working on database design and development  data integration and ingestion  designing etl architectures using a variety of etl tools and techniques  you are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled analytics team  play a key role on projects from a data engineering perspective  working with our architects and clients to model the data landscape  obtain data extracts and define secure data exchange approaches  this is a fantastic opportunity to be involved in end to end data management for cutting edge advanced analytics and data science job specifics plan and execute secure  best practice data integration strategies and approaches acquire  ingest  and process data from multiple sources and systems into big data platforms create and manage data environments in the cloud collaborate with our business analysts and data scientists to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models managing and monitoring the data integration process have a strong understanding of information security principles to ensure compliant handling and management of client data qualifications and required skills experience and desire to work with open source and branded open source frameworks experience working on projects within the cloud ideally aws  azure  gcp or snowflake experience working on \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    agile delivery projects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and a consulting setting  often working on different and multiple projects at the same time experience working with a \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    variety\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " of etl elt tools like matillion  talend  streamsets preferred strong development background with experience in at least one scripting  object oriented or functional programming language  etc   python  java  scala  c   r  bashexperience working with version control tools such as git hub  bitbucket data warehousing experience  building \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    operational etl data pipelines\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " across a \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    number\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " of sources  and constructing relational and dimensional data models excellent interpersonal skills when interacting with clients in a clear  timely  and professional manner desirable skills experience on client facing projects  including working in close knit teams experience working in a cloud architecture with data lake experience and interest in big data technologies  spark   no sql dbs experience or familiarity with real time ingestion and streaming frameworks is a plus a deep personal motivation to always produce outstanding work for your clients and colleagues excel in team collaboration and working with others from diverse skill sets and background experience leading a \n",
       "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    team\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " and driving them go deliver results solution delivery</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">she her hers  he him his  they them theirs  etc  introbumble is looking for an etl data engineer to participate in the development of the data collecting and data processing framework  services and tools for the cross functional data platform department  concretely  this means implementing  deploying and maintaining large scale data pipelines as well as internal data tools that help bumble provide a safe and engaging \n",
       "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISSING</span>\n",
       "</mark>\n",
       " for our users and improve the way bumble operates with millions of images and messages exchanged on our platform every day  there is a wealth of opportunity to make a real difference in this role and help people to find love all over the world  the ideal candidate combines strong business acumen  experience in data pipelines  databases and development best practices along with a passion for tech key accountabilities working with big data  tables containing billions of rows and terabytes of data development and improvement of the bumble etl framework and data preparation tools for business analysis development and support of team s ecosystem  dozens of in house projects improving our life and help other teams working with our infrastructure active participation in development and maintenance of the data warehouse and investigation of common data issues define the look and feel of data platform by developing internal tools integrate new technologies into our processes and tools required skills and knowledge a knowledge and understanding of sql language  ability to write complex queries data warehousing and database basic architecture principles posix unix linux ecosystem knowledge experience with php python or desire to learn them we appreciate result oriented work style  flexibility in choosing tools and technical approaches nice to have experience with exasol and or snowflake databases good knowledge of sql  window functions  common table expressions  complex grouping etc  google cloud platform familiarity basic hadoop familiarity  hdfs hive about you you are passionate about technology and not afraid to learn and build complex systems you are positive and committed with a  can do  attitude and a flexible approach you are the first to notice issues and opportunities and are able to exploit these to your team s advantage</br></br></br>        show more</br></br>        </br></br></br>        show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_extraction(desc[:10], extract_verb_maybeadj_noun_experience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ce5c0",
   "metadata": {},
   "source": [
    "# Extracting types of experience accross all job ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55734622",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_exps = [extract_adp_conj_experience,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b535422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_desc = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d444f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.5 s, sys: 3.27 s, total: 1min\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_ents = extract_df(*extract_exps, n_max=n_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd079d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ents.to_csv('experience_adp_ents.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6037c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ents = pd.read_csv('experience_adp_ents.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "295e61e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docidx</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_start</th>\n",
       "      <th>sent_end</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_description</th>\n",
       "      <th>desc_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>3</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>The Data Shed</td>\n",
       "      <td>description at the data shed  we ve been work...</td>\n",
       "      <td>description data shed working truly inspiring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>things</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>227</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>The Data Shed</td>\n",
       "      <td>description at the data shed  we ve been work...</td>\n",
       "      <td>description data shed working truly inspiring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exploratory data analysis experience</td>\n",
       "      <td>3</td>\n",
       "      <td>369</td>\n",
       "      <td>373</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>314</td>\n",
       "      <td>649</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>The Data Shed</td>\n",
       "      <td>description at the data shed  we ve been work...</td>\n",
       "      <td>description data shed working truly inspiring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>programming</td>\n",
       "      <td>5</td>\n",
       "      <td>497</td>\n",
       "      <td>498</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>163</td>\n",
       "      <td>848</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Essence</td>\n",
       "      <td>data engineer  business intelligenceat essenc...</td>\n",
       "      <td>data engineer business intelligenceat essence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>statistical languages</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>502</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>163</td>\n",
       "      <td>848</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Essence</td>\n",
       "      <td>data engineer  business intelligenceat essenc...</td>\n",
       "      <td>data engineer business intelligenceat essence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>database administrator</td>\n",
       "      <td>1768</td>\n",
       "      <td>523</td>\n",
       "      <td>525</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>263</td>\n",
       "      <td>623</td>\n",
       "      <td>PL/SQL Developer</td>\n",
       "      <td>Gattaca</td>\n",
       "      <td>job title  database and wh administrator loca...</td>\n",
       "      <td>title database administrator location durringt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>current rdbms technologies</td>\n",
       "      <td>1768</td>\n",
       "      <td>530</td>\n",
       "      <td>533</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>263</td>\n",
       "      <td>623</td>\n",
       "      <td>PL/SQL Developer</td>\n",
       "      <td>Gattaca</td>\n",
       "      <td>job title  database and wh administrator loca...</td>\n",
       "      <td>title database administrator location durringt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>production dba</td>\n",
       "      <td>1769</td>\n",
       "      <td>208</td>\n",
       "      <td>210</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>SQL Database Developer &amp; Administrator</td>\n",
       "      <td>Anson McCade</td>\n",
       "      <td>role  sql dba   london  ukdescription looking...</td>\n",
       "      <td>role london ukdescription looking join leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>experience</td>\n",
       "      <td>1769</td>\n",
       "      <td>214</td>\n",
       "      <td>215</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>SQL Database Developer &amp; Administrator</td>\n",
       "      <td>Anson McCade</td>\n",
       "      <td>role  sql dba   london  ukdescription looking...</td>\n",
       "      <td>role london ukdescription looking join leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>performance optimization</td>\n",
       "      <td>1769</td>\n",
       "      <td>216</td>\n",
       "      <td>218</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>SQL Database Developer &amp; Administrator</td>\n",
       "      <td>Anson McCade</td>\n",
       "      <td>role  sql dba   london  ukdescription looking...</td>\n",
       "      <td>role london ukdescription looking join leading...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows Ã 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  docidx  start  end       label  \\\n",
       "0                                     data       3    216  217  EXPERIENCE   \n",
       "1                                   things       3    226  227  EXPERIENCE   \n",
       "2     exploratory data analysis experience       3    369  373  EXPERIENCE   \n",
       "3                              programming       5    497  498  EXPERIENCE   \n",
       "4                    statistical languages       5    500  502  EXPERIENCE   \n",
       "...                                    ...     ...    ...  ...         ...   \n",
       "3271                database administrator    1768    523  525  EXPERIENCE   \n",
       "3272            current rdbms technologies    1768    530  533  EXPERIENCE   \n",
       "3273                        production dba    1769    208  210  EXPERIENCE   \n",
       "3274                            experience    1769    214  215  EXPERIENCE   \n",
       "3275              performance optimization    1769    216  218  EXPERIENCE   \n",
       "\n",
       "      sent_start  sent_end                               job_title  \\\n",
       "0              1       258                           Data Engineer   \n",
       "1              1       258                           Data Engineer   \n",
       "2            314       649                           Data Engineer   \n",
       "3            163       848                           Data Engineer   \n",
       "4            163       848                           Data Engineer   \n",
       "...          ...       ...                                     ...   \n",
       "3271         263       623                        PL/SQL Developer   \n",
       "3272         263       623                        PL/SQL Developer   \n",
       "3273           0       240  SQL Database Developer & Administrator   \n",
       "3274           0       240  SQL Database Developer & Administrator   \n",
       "3275           0       240  SQL Database Developer & Administrator   \n",
       "\n",
       "       company_name                                    job_description  \\\n",
       "0     The Data Shed   description at the data shed  we ve been work...   \n",
       "1     The Data Shed   description at the data shed  we ve been work...   \n",
       "2     The Data Shed   description at the data shed  we ve been work...   \n",
       "3           Essence   data engineer  business intelligenceat essenc...   \n",
       "4           Essence   data engineer  business intelligenceat essenc...   \n",
       "...             ...                                                ...   \n",
       "3271        Gattaca   job title  database and wh administrator loca...   \n",
       "3272        Gattaca   job title  database and wh administrator loca...   \n",
       "3273   Anson McCade   role  sql dba   london  ukdescription looking...   \n",
       "3274   Anson McCade   role  sql dba   london  ukdescription looking...   \n",
       "3275   Anson McCade   role  sql dba   london  ukdescription looking...   \n",
       "\n",
       "                                         desc_tokenized  \n",
       "0     description data shed working truly inspiring ...  \n",
       "1     description data shed working truly inspiring ...  \n",
       "2     description data shed working truly inspiring ...  \n",
       "3     data engineer business intelligenceat essence ...  \n",
       "4     data engineer business intelligenceat essence ...  \n",
       "...                                                 ...  \n",
       "3271  title database administrator location durringt...  \n",
       "3272  title database administrator location durringt...  \n",
       "3273  role london ukdescription looking join leading...  \n",
       "3274  role london ukdescription looking join leading...  \n",
       "3275  role london ukdescription looking join leading...  \n",
       "\n",
       "[3276 rows x 11 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62e313c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   experience at the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " shed we are looking for experience in the following things  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">description at the data shed  we ve been working with some truly inspiring clients on anything from real time data integration and data mining to analytics ready data modelling and insight elicitation with data exploration and machine learning  we face new and exciting challenges every day  from ensuring high availability and performance of critical government systems  to understanding and improving complex banking and finance data structures our data engineers find themselves working on a broad range of data centric technologies across the major cloud providers such as amazon web services  aws   microsoft azure  and google cloud platform  gcp   while our teams have commonly used python  sql  java  go  ruby  java script and c   we expect engineers to be agnostic to technology valuing their ability to be adaptable and learn quickly as part of our engineering team  you will be responsible for building large scale data management and analytics platforms  we use a variety of tools  making sure we use the right one for the job at hand  as a close working and collaborative team  we make data valuable and available to our clients  through consultancy services or product development skills   experience at the data shed we are looking for experience in the following \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    things\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "  we need people who are open to new technologies  quick to adapt  and quick to learn  if you don t have one of the following please apply </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showent_df(df_ents[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a96ac97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>experience</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>sql</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>data</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>python</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>restores</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>aws</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>design</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>building</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>role</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>programming</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>databases</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>performance tuning</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>solutions</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>field</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>any</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>creation</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>implementation</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ability</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>years</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>data architecture</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>hands</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>bi tools</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>range</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>data modeling</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>following</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>development</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>data visualisation tools</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>etl</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>power</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>react</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>relational databases</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>use</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>similar data scientist role</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>financial services industry</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>excel</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>dbt</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>non relational databases</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>python strong analytical skills</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>data warehouse design</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>different data visualization</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>statistical packages</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>cloud platform</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>data architect</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>key data regulation</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>visualisation</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>analysis</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  n_company   n\n",
       "281                       experience         15  57\n",
       "576                              sql         10  43\n",
       "145                             data          9  46\n",
       "476                           python          8  67\n",
       "514                         restores          6  26\n",
       "359                        knowledge          6  20\n",
       "47                               aws          6   8\n",
       "230                           design          5  43\n",
       "79                          building          5  16\n",
       "146                    data analysis          4  23\n",
       "519                             role          4  17\n",
       "467                      programming          4  16\n",
       "216                        databases          4  14\n",
       "444               performance tuning          4  13\n",
       "568                        solutions          4  10\n",
       "287                            field          4   7\n",
       "36                               any          4   5\n",
       "130                         creation          3  24\n",
       "334                   implementation          3  23\n",
       "0                            ability          3  22\n",
       "663                            years          3  19\n",
       "157                data architecture          3  18\n",
       "326                            hands          3  17\n",
       "66                          bi tools          3  15\n",
       "490                            range          3  15\n",
       "176                    data modeling          3  14\n",
       "297                        following          3  14\n",
       "236                      development          3  12\n",
       "204         data visualisation tools          3  10\n",
       "267                              etl          3   9\n",
       "372                 machine learning          3   4\n",
       "450                            power          3   4\n",
       "493                            react          3   3\n",
       "508             relational databases          3   3\n",
       "644                              use          3   3\n",
       "439                           pandas          2  28\n",
       "543      similar data scientist role          2  25\n",
       "294      financial services industry          2  16\n",
       "279                            excel          2  15\n",
       "221                              dbt          2  14\n",
       "424         non relational databases          2  14\n",
       "479  python strong analytical skills          2  14\n",
       "205            data warehouse design          2  13\n",
       "239     different data visualization          2  13\n",
       "597             statistical packages          2  13\n",
       "111                   cloud platform          2  12\n",
       "154                   data architect          2  12\n",
       "357              key data regulation          2  12\n",
       "653                    visualisation          2  12\n",
       "27                          analysis          2  10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ent_agg = aggregate_df(df_ents)\n",
    "df_ent_agg.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ffbdc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ent_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff6fbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext import KeywordProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee4eeb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flashtext\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "Building wheels for collected packages: flashtext\n",
      "  Building wheel for flashtext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9309 sha256=7992f5dd750f4f0e7caed29cc92e31d014fd589dd870f4bfd2fe5e8596d5cc0f\n",
      "  Stored in directory: /Users/thuynguyenphan/Library/Caches/pip/wheels/8d/62/8b/71813348245ae1bcbae179193bbc72db819e8057e89298a6ac\n",
      "Successfully built flashtext\n",
      "Installing collected packages: flashtext\n",
      "Successfully installed flashtext-2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install flashtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3980056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_processor = KeywordProcessor(case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93f1c9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = df_ent_agg.query('n>0').text\n",
    "len(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "207c7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for skill in skills:\n",
    "    keyword_processor.add_keyword(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10d75c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f43eb04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 12 ms, total: 1.23 s\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = Counter()\n",
    "ad_counter = Counter()\n",
    "for ad in desc[:10_000]:\n",
    "    keywords = keyword_processor.extract_keywords(ad)\n",
    "    counter.update(keywords)\n",
    "    ad_counter.update(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2a57583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_ad = pd.DataFrame(ad_counter.items(), columns=['text', 'n_ad_occur'])\n",
    "df_count = pd.DataFrame(counter.items(), columns=['text', 'n_occur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d18b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = (\n",
    "    df_ent_agg\n",
    "    .merge(df_count, how='left', validate='1:1')\n",
    "    .merge(df_count_ad, how='left', validate='1:1')\n",
    "     .assign(pct_ad_occur = lambda df: df.n_ad_occur / n_desc,\n",
    "        avg_occur = lambda df: df.n_occur / df.n_ad_occur,\n",
    "        ad_freq = lambda df: df.n_ad_occur / df.n)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72d0d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.to_csv('term_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a44f9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv('term_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "422bbf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_company</th>\n",
       "      <th>n</th>\n",
       "      <th>n_occur</th>\n",
       "      <th>n_ad_occur</th>\n",
       "      <th>pct_ad_occur</th>\n",
       "      <th>avg_occur</th>\n",
       "      <th>ad_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experience</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>6148</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.918690</td>\n",
       "      <td>3.778734</td>\n",
       "      <td>28.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>1578</td>\n",
       "      <td>963</td>\n",
       "      <td>0.543761</td>\n",
       "      <td>1.638629</td>\n",
       "      <td>22.395349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>13092</td>\n",
       "      <td>1548</td>\n",
       "      <td>0.874082</td>\n",
       "      <td>8.457364</td>\n",
       "      <td>33.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "      <td>888</td>\n",
       "      <td>690</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>1.286957</td>\n",
       "      <td>10.298507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>restores</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0.015246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1835</td>\n",
       "      <td>986</td>\n",
       "      <td>0.556748</td>\n",
       "      <td>1.861055</td>\n",
       "      <td>49.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aws</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>481</td>\n",
       "      <td>340</td>\n",
       "      <td>0.191982</td>\n",
       "      <td>1.414706</td>\n",
       "      <td>42.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>design</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>1627</td>\n",
       "      <td>773</td>\n",
       "      <td>0.436477</td>\n",
       "      <td>2.104787</td>\n",
       "      <td>17.976744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>building</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>819</td>\n",
       "      <td>567</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>35.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>365</td>\n",
       "      <td>284</td>\n",
       "      <td>0.160361</td>\n",
       "      <td>1.285211</td>\n",
       "      <td>12.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>role</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3167</td>\n",
       "      <td>1353</td>\n",
       "      <td>0.763975</td>\n",
       "      <td>2.340724</td>\n",
       "      <td>79.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>programming</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>401</td>\n",
       "      <td>280</td>\n",
       "      <td>0.158103</td>\n",
       "      <td>1.432143</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>databases</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>601</td>\n",
       "      <td>392</td>\n",
       "      <td>0.221344</td>\n",
       "      <td>1.533163</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>performance tuning</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>0.035008</td>\n",
       "      <td>1.112903</td>\n",
       "      <td>4.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>solutions</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2128</td>\n",
       "      <td>949</td>\n",
       "      <td>0.535855</td>\n",
       "      <td>2.242360</td>\n",
       "      <td>94.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>field</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>204</td>\n",
       "      <td>180</td>\n",
       "      <td>0.101637</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>25.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>any</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>912</td>\n",
       "      <td>630</td>\n",
       "      <td>0.355731</td>\n",
       "      <td>1.447619</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>creation</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>231</td>\n",
       "      <td>205</td>\n",
       "      <td>0.115754</td>\n",
       "      <td>1.126829</td>\n",
       "      <td>8.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>implementation</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>454</td>\n",
       "      <td>335</td>\n",
       "      <td>0.189159</td>\n",
       "      <td>1.355224</td>\n",
       "      <td>14.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ability</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1885</td>\n",
       "      <td>953</td>\n",
       "      <td>0.538114</td>\n",
       "      <td>1.977964</td>\n",
       "      <td>43.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>years</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>829</td>\n",
       "      <td>661</td>\n",
       "      <td>0.373235</td>\n",
       "      <td>1.254160</td>\n",
       "      <td>34.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data architecture</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>250</td>\n",
       "      <td>123</td>\n",
       "      <td>0.069452</td>\n",
       "      <td>2.032520</td>\n",
       "      <td>6.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hands</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>305</td>\n",
       "      <td>221</td>\n",
       "      <td>0.124788</td>\n",
       "      <td>1.380090</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bi tools</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>range</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>591</td>\n",
       "      <td>411</td>\n",
       "      <td>0.232072</td>\n",
       "      <td>1.437956</td>\n",
       "      <td>27.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data modeling</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>138</td>\n",
       "      <td>97</td>\n",
       "      <td>0.054771</td>\n",
       "      <td>1.422680</td>\n",
       "      <td>6.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>following</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>489</td>\n",
       "      <td>366</td>\n",
       "      <td>0.206663</td>\n",
       "      <td>1.336066</td>\n",
       "      <td>26.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>development</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1749</td>\n",
       "      <td>962</td>\n",
       "      <td>0.543196</td>\n",
       "      <td>1.818087</td>\n",
       "      <td>80.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data visualisation tools</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>etl</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>298</td>\n",
       "      <td>237</td>\n",
       "      <td>0.133823</td>\n",
       "      <td>1.257384</td>\n",
       "      <td>26.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>776</td>\n",
       "      <td>338</td>\n",
       "      <td>0.190853</td>\n",
       "      <td>2.295858</td>\n",
       "      <td>84.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>power</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>287</td>\n",
       "      <td>0.162055</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>71.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>react</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>67</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>1.402985</td>\n",
       "      <td>22.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>relational databases</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>0.031621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>use</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1015</td>\n",
       "      <td>634</td>\n",
       "      <td>0.357990</td>\n",
       "      <td>1.600946</td>\n",
       "      <td>211.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>186</td>\n",
       "      <td>154</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1.207792</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>similar data scientist role</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>financial services industry</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>excel</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>273</td>\n",
       "      <td>214</td>\n",
       "      <td>0.120836</td>\n",
       "      <td>1.275701</td>\n",
       "      <td>14.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dbt</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>non relational databases</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0.014681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>python strong analytical skills</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data warehouse design</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013552</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>different data visualization</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>statistical packages</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cloud platform</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>115</td>\n",
       "      <td>110</td>\n",
       "      <td>0.062112</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>9.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>data architect</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>347</td>\n",
       "      <td>163</td>\n",
       "      <td>0.092038</td>\n",
       "      <td>2.128834</td>\n",
       "      <td>13.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>key data regulation</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>visualisation</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>133</td>\n",
       "      <td>100</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>analysis</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>864</td>\n",
       "      <td>588</td>\n",
       "      <td>0.332016</td>\n",
       "      <td>1.469388</td>\n",
       "      <td>58.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  n_company   n  n_occur  n_ad_occur  \\\n",
       "0                        experience         15  57     6148        1627   \n",
       "1                               sql         10  43     1578         963   \n",
       "2                              data          9  46    13092        1548   \n",
       "3                            python          8  67      888         690   \n",
       "4                          restores          6  26       27          27   \n",
       "5                         knowledge          6  20     1835         986   \n",
       "6                               aws          6   8      481         340   \n",
       "7                            design          5  43     1627         773   \n",
       "8                          building          5  16      819         567   \n",
       "9                     data analysis          4  23      365         284   \n",
       "10                             role          4  17     3167        1353   \n",
       "11                      programming          4  16      401         280   \n",
       "12                        databases          4  14      601         392   \n",
       "13               performance tuning          4  13       69          62   \n",
       "14                        solutions          4  10     2128         949   \n",
       "15                            field          4   7      204         180   \n",
       "16                              any          4   5      912         630   \n",
       "17                         creation          3  24      231         205   \n",
       "18                   implementation          3  23      454         335   \n",
       "19                          ability          3  22     1885         953   \n",
       "20                            years          3  19      829         661   \n",
       "21                data architecture          3  18      250         123   \n",
       "22                            hands          3  17      305         221   \n",
       "23                         bi tools          3  15       37          35   \n",
       "24                            range          3  15      591         411   \n",
       "25                    data modeling          3  14      138          97   \n",
       "26                        following          3  14      489         366   \n",
       "27                      development          3  12     1749         962   \n",
       "28         data visualisation tools          3  10       34          34   \n",
       "29                              etl          3   9      298         237   \n",
       "30                 machine learning          3   4      776         338   \n",
       "31                            power          3   4      350         287   \n",
       "32                            react          3   3       94          67   \n",
       "33             relational databases          3   3       56          56   \n",
       "34                              use          3   3     1015         634   \n",
       "35                           pandas          2  28      186         154   \n",
       "36      similar data scientist role          2  25       25          25   \n",
       "37      financial services industry          2  16       34          20   \n",
       "38                            excel          2  15      273         214   \n",
       "39                              dbt          2  14       33          33   \n",
       "40         non relational databases          2  14       26          26   \n",
       "41  python strong analytical skills          2  14       14          14   \n",
       "42            data warehouse design          2  13       26          24   \n",
       "43     different data visualization          2  13       13          13   \n",
       "44             statistical packages          2  13       13          13   \n",
       "45                   cloud platform          2  12      115         110   \n",
       "46                   data architect          2  12      347         163   \n",
       "47              key data regulation          2  12       12          12   \n",
       "48                    visualisation          2  12      133         100   \n",
       "49                         analysis          2  10      864         588   \n",
       "\n",
       "    pct_ad_occur  avg_occur     ad_freq  \n",
       "0       0.918690   3.778734   28.543860  \n",
       "1       0.543761   1.638629   22.395349  \n",
       "2       0.874082   8.457364   33.652174  \n",
       "3       0.389610   1.286957   10.298507  \n",
       "4       0.015246   1.000000    1.038462  \n",
       "5       0.556748   1.861055   49.300000  \n",
       "6       0.191982   1.414706   42.500000  \n",
       "7       0.436477   2.104787   17.976744  \n",
       "8       0.320158   1.444444   35.437500  \n",
       "9       0.160361   1.285211   12.347826  \n",
       "10      0.763975   2.340724   79.588235  \n",
       "11      0.158103   1.432143   17.500000  \n",
       "12      0.221344   1.533163   28.000000  \n",
       "13      0.035008   1.112903    4.769231  \n",
       "14      0.535855   2.242360   94.900000  \n",
       "15      0.101637   1.133333   25.714286  \n",
       "16      0.355731   1.447619  126.000000  \n",
       "17      0.115754   1.126829    8.541667  \n",
       "18      0.189159   1.355224   14.565217  \n",
       "19      0.538114   1.977964   43.318182  \n",
       "20      0.373235   1.254160   34.789474  \n",
       "21      0.069452   2.032520    6.833333  \n",
       "22      0.124788   1.380090   13.000000  \n",
       "23      0.019763   1.057143    2.333333  \n",
       "24      0.232072   1.437956   27.400000  \n",
       "25      0.054771   1.422680    6.928571  \n",
       "26      0.206663   1.336066   26.142857  \n",
       "27      0.543196   1.818087   80.166667  \n",
       "28      0.019198   1.000000    3.400000  \n",
       "29      0.133823   1.257384   26.333333  \n",
       "30      0.190853   2.295858   84.500000  \n",
       "31      0.162055   1.219512   71.750000  \n",
       "32      0.037832   1.402985   22.333333  \n",
       "33      0.031621   1.000000   18.666667  \n",
       "34      0.357990   1.600946  211.333333  \n",
       "35      0.086957   1.207792    5.500000  \n",
       "36      0.014116   1.000000    1.000000  \n",
       "37      0.011293   1.700000    1.250000  \n",
       "38      0.120836   1.275701   14.266667  \n",
       "39      0.018634   1.000000    2.357143  \n",
       "40      0.014681   1.000000    1.857143  \n",
       "41      0.007905   1.000000    1.000000  \n",
       "42      0.013552   1.083333    1.846154  \n",
       "43      0.007340   1.000000    1.000000  \n",
       "44      0.007340   1.000000    1.000000  \n",
       "45      0.062112   1.045455    9.166667  \n",
       "46      0.092038   2.128834   13.583333  \n",
       "47      0.006776   1.000000    1.000000  \n",
       "48      0.056465   1.330000    8.333333  \n",
       "49      0.332016   1.469388   58.800000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f482c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = list(\n",
    "(df_c\n",
    " .query('ad_freq < 100')\n",
    ").text\n",
    ")\n",
    "len(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66a42eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skills.txt', 'w') as f:\n",
    "    for skill in skills:\n",
    "        print(skill, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7f731bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience                         sql                                data\n",
      "python                             restores                           knowledge\n",
      "aws                                design                             building\n",
      "data analysis                      role                               programming\n",
      "databases                          performance tuning                 solutions\n",
      "field                              creation                           implementation\n",
      "ability                            years                              data architecture\n",
      "hands                              bi tools                           range\n",
      "data modeling                      following                          development\n",
      "data visualisation tools           etl                                machine learning\n",
      "power                              react                              relational databases\n",
      "pandas                             similar data scientist role        financial services industry\n",
      "excel                              dbt                                non relational databases\n",
      "python strong analytical skills    data warehouse design              different data visualization\n",
      "statistical packages               cloud platform                     data architect\n",
      "key data regulation                visualisation                      analysis\n",
      "clinical database management system development experiencedatabase management                healthcare discipline experience\n",
      "strong medidata                    understanding                      big data\n",
      "data engineer                      pto                                unstructured data\n",
      "high availability                  optimization                       recovery models experience\n",
      "sql server                         variety                            client facing projects\n",
      "aws data technologies              big query                          cloud platforms\n",
      "data analytics                     development experience             maintaining\n",
      "sqlexperience                      financial services sector          master data management\n",
      "proficiency                        solidatus                          data science role\n",
      "knowlege                           optimization experience            software engineering experience\n",
      "bank                               adaptive learning experience       customer analytics\n",
      "digital data                       reinforcement                      telecommunications sector background\n",
      "users                              enterprise scale nlp solutions     software development position\n",
      "graduate                           music industry                     music production\n",
      "skills                             visualisation tools                data architects\n",
      "general insurance industry         google cloud environment aws       modern programming languages\n",
      "tool                               agile project delivery             business transformation\n",
      "c level stakeholder engagement     data analysis tools                data ecosystem\n",
      "data modelling tools               data virtualisation platforms      techniques experience\n",
      "advanced sql tsqlknowledge         agile reporting development        aws relational databases\n",
      "azure dev ops                      data architect technical expertise data manipulation skills\n",
      "deep learning                      deep statistical modelling techniques experiencedl frameworks\n",
      "microsoft sql server               similar beginner intermediate level experiencesimilar excellent communication\n",
      "skillsets                          ssis                               carbon emission data\n",
      "cloud architecture                 data modeling lifecycle whole lifecycle experiencedata privacy ability\n",
      "data visualisation                 dbtexperience                      development best practices\n",
      "exasol                             graph ql                           great communication\n",
      "large organisation ability         manufacturing data                 modelling experience\n",
      "php python                         rdbms technologies                 sparx systems enterprise architect\n",
      "agile software development lifecycleanalytical scripting languages     bonus\n",
      "building reports                   computer programming               current rdbms technologies\n",
      "customer analytics role            dashboards                         database administrator\n",
      "media                              ms power point experience          other database technologies\n",
      "related discipline experience      search                             spaces\n",
      "tracking                           agile delivery                     agile techniques\n",
      "broad experience                   data platforms                     etl pipelines\n",
      "etl technical design               financial sector                   gcp\n",
      "market risk management             oracle knowledge                   performance\n",
      "python experience                  queries optimization               reconciliation\n",
      "risk                               risk control                       spark experience\n",
      "t sql                              tabular                            target operating models\n",
      "vba                                america good conduct               application performance\n",
      "background                         business intelligence capabilities clearance\n",
      "compliance                         configuration                      conversion skills\n",
      "data mart solutions                data modelling practices           data security\n",
      "database administrator role experiencedatabricks experience              designing\n",
      "dimensional modelling techniques experienceenforcing                          etl automation\n",
      "event                              financial crime                    fraud software deployment\n",
      "iaa s                              involvement                        py spark spark\n",
      "recovery models                    reusable data frame works          similar sql data engineering role data analysis\n",
      "sound judgment                     transactional replication database agile delivery teams\n",
      "aws cloud native technologies      azure data lakes                   big data additional information netcompany\n",
      "client facing environment          data platform experience           developer role strong competence\n",
      "large industry                     large scale solution design        market data\n",
      "ms sql server                      rstudio                            sap\n",
      "scala                              shelf ui                           similar role technical expertise\n",
      "snowflake significant sql experience significant experiencestakeholder management             success\n",
      "big data experience                configuration automation           data architecture experience\n",
      "dev ops technologies               digital marketing platforms        etl tooling python\n",
      "full delivery life cycle           least two                          map\n",
      "marketing organization             statistical languages              successful candidate\n",
      "technologies                       testing experience                 apache beam experience\n",
      "backend engineering                build tools                        business finance\n",
      "dag                                data testing                       deep learning approaches\n",
      "depth knowledge                    engineering platforms              interpreting\n",
      "large service                      ms sql server administration       other rdbms\n",
      "other relevant field               powershell experience              react expertise\n",
      "recruitment                        relational database design         reviewing\n",
      "service broker ms sql server certificationsql server mid senior level        streaming data experience\n",
      "testing frameworks                 writing                            administration role\n",
      "agile database deployments experiencebusiness industry management       ci cd pipelines\n",
      "computer vision systems            creation python                    data bricks\n",
      "data engineering                   data modeller architect            data pipeline design\n",
      "data science tools problem         financial services area            git version control knowledge\n",
      "microsoft azure experience         mind                               net\n",
      "net core                           python knowledge                   python strong experience\n",
      "pytorch cnn                        query                              similar experience\n",
      "solution architecture delivery     solutions architect                sql developer\n",
      "staff members                      academia                           advanced analytics techniques\n",
      "agile software delivery            agile ways                         aipython\n",
      "analytics experience               apps development                   arm templates\n",
      "automating                         aws services                       awsexperience\n",
      "azure business intelligence solutionsbehaviors                          big data technologies\n",
      "blender                            bud                                building processes\n",
      "business requirements definition   cdk drive dealer software          ci cd\n",
      "ci cd processes                    client projects                    cloud database solutions\n",
      "code development                   commercial environment             css\n",
      "dags                               dashboard development              data governance\n",
      "data loader                        data manipulation tools            data pipeline orchestration framework company\n",
      "data problem                       data proc experience building data platformsdata reporting\n",
      "data science software engineering  data science tools                 data scientist data analyst\n",
      "data strategy                      data technologies                  database design\n",
      "databricks                         deep learning frameworks           different domains\n",
      "ecommerce platforms                entertainment industries           entity linking\n",
      "equity derivatives                 etl packages                       etl tool\n",
      "experimental design                exploratory data analysis experienceexternal web service integrations\n",
      "financial databases                fintech company data               ga adobe analytics\n",
      "git                                goldengate                         health brand\n",
      "healthcare data analysis           industry etl tools                 intermediate knowledge\n",
      "j                                  large data                         large organization previous commercial insights\n",
      "maintenance experience             marketing industry                 ml\n",
      "modern frontend frameworks         ms excel prior use                 ms sql\n",
      "orbit                              performance optimization           performance tuning appreciation\n",
      "power bi preferred experience experienceproduction dba                     professional software development\n",
      "programming languages              qlik                               query good understanding\n",
      "r bonus                            real time ingestion                redash\n",
      "redshift                           response technologies              root cause analysis\n",
      "scale                              scheduling tools                   similar analytics platforms\n",
      "similar databases                  similar nice                       sisra\n",
      "sme                                spark                              sql experience\n",
      "stream lining                      streaming frameworks               sybase\n",
      "three                              ui                                 unity\n",
      "unix environment                   vertex                             web analytics\n",
      "web applications                   workflow orchestrators             acting\n",
      "actuals                            aggregations                       agile methodologies experience\n",
      "agile project environment exposure amazon web services                aml kyc due diligence roles\n",
      "analyst role                       analytics role                     analytics tools\n",
      "ansible terraform git experience   architecture position              aurora\n",
      "aws stack                          awsexcellent active directory      azure data warehousing etl\n",
      "azure synapse                      backend language                   big data tech stack\n",
      "biostatistics                      building dashboards                building microservices\n",
      "building reporting                 building systems                   business intelligence platforms\n",
      "citrix cloud solutions expert level understandingclient organisations               clinical research\n",
      "cloud computing platforms          cloud data warehouse               cloud environment experience\n",
      "code reviews                       common data analysis scripting languagescomplete product life cycle\n",
      "computer hardware software innovationconfidence                         consumer point\n",
      "continuous improvement             continuous integration             crm marketing communication\n",
      "css sass frameworks                cyclops cyclops                    data analysis ability\n",
      "data analysis techniques           data analyst bi developer          data analyst role\n",
      "data analyst statistics environmentdata base integration              data centres\n",
      "data curation                      data governance toolsets           data hygiene\n",
      "data maintenance                   data management concepts           data projects\n",
      "data transformation                data warehouses                    data warehousing experience experience\n",
      "data warehousing tools             database experience                database interrogation\n",
      "database management experience     daxexperience                      delivery good knowledge\n",
      "design thinking                    dev ops engineer position          different organisations\n",
      "dimensional modelling enthusiasm   direct indirect sales              docker code version control\n",
      "docker knowledge                   documenting processes experience   dynamic environment\n",
      "economics                          ecr                                elt\n",
      "enterprise security tools          enterprise software                erp systems e\n",
      "erwin                              etl design                         etl tools\n",
      "evaluation understanding           excellent problem solving skills   express knowledge\n",
      "financial data experience          financial industry                 forecasting\n",
      "front end                          front end frameworks               frontend optimization experience\n",
      "geographical visualizations technical understandinggit administration                 git ops technologies\n",
      "global vdi implementations         good influencing skills            good knowledge\n",
      "google analytics experience        google big query                   google cloud data\n",
      "google cloud platform interview processgovernance roles                   hard service\n",
      "ich gcp environment                implementation management          incident management\n",
      "infrastructure engineer systems engineer cloud engineer good experienceinfrastructure funds               infrastructure technologies delivery\n",
      "infrastructures                    infrastructures experience         intelligent document processing\n",
      "internal product ownership         iqvia                              itil v\n",
      "java script                        key governance timelines sme       kubernetes\n",
      "likes                              many industries                    mdm technology\n",
      "mdx                                mediacom media com                 mi\n",
      "monitoring tools                   month contract                     ms azure\n",
      "ms sqlexperience                   multi threading                    multiple primary vendor solutions\n",
      "mvc understanding                  mysql                              natural language processing\n",
      "natural language processing knowledge experiencenet core good knowledge            net programming stack\n",
      "nice                               nightwatch                         node\n",
      "open banking data                  open source databases              oral communication\n",
      "other cloud providers              outlook                            partner sales\n",
      "planning role                      postgres                           postgress\n",
      "private equity                     private market funds               process automation\n",
      "process management                 professional services              professional services background\n",
      "project management experience      project planning                   property management experience\n",
      "puppet prior experience            qhse management systems experience quantitative subject area strong interpersonal skills\n",
      "rdms technologies                  recovery model experience          replenishment\n",
      "resources                          salt                               sap forecasting\n",
      "sas visual investigator            scratch                            scripting statistical language\n",
      "security operations centre         service delivery                   services experience\n",
      "share point experience             similar compliance role            similar expertise building\n",
      "similar role                       sme credit risk models             soft service provision\n",
      "software developer                 software development demonstrable  software engineer\n",
      "solution identification            spring                             sql ability\n",
      "sql database                       sql dba role                       sql development\n",
      "sql extensive experience           sql queries                        sql server agent job scheduling experience\n",
      "sql server patching                statistical analysis               statistical methodologies\n",
      "strong business analysis skills    support teams                      system performance analysis\n",
      "systems analysis                   tdd bdd methodologies              technical development\n",
      "technical skills migration         technical stack                    terraform\n",
      "test frameworks                    upgrades                           various automation\n",
      "verbal communication skills        version control tools              version deployment differences experience\n",
      "visualization tools                web development                    web engineering solution\n"
     ]
    }
   ],
   "source": [
    "n_max=10000\n",
    "for a,b,c in zip(skills[:n_max:3],skills[1:n_max:3],skills[2:n_max:3]):\n",
    "     print('{:<35}{:<35}{:<}'.format(a,b,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2846a2dd",
   "metadata": {},
   "source": [
    "# AnalysisÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac00bd",
   "metadata": {},
   "source": [
    "Cooccurance would be great for understanding skills!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0415edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ents(query, exact=False, match_case=True):\n",
    "    if exact and match_case:\n",
    "        return df_ents[df_ents.text == query]\n",
    "    elif exact:\n",
    "        return df_ents[df_ents.text.str.lower() == query.lower()]\n",
    "    else:\n",
    "        return df_ents[df_ents.text.str.contains(fr'\\b{query}\\b', flags = 0 if match_case else re.IGNORECASE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c652fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_exp(query, exact=True, match_case=True, n_max=10):\n",
    "    showent_df(filter_ents(query, exact, match_case)[:n_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "49caffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_exp(query, exact=True, match_case=True):\n",
    "    return filter_ents(query, exact, match_case).drop_duplicates('docidx')[['job_title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9f9cdf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def related_experience(query, exact=True, match_case=True):\n",
    "    return (\n",
    "     df_ents[df_ents['docidx'].isin(filter_ents(query, exact, match_case).docidx.to_numpy())]\n",
    "     .query('label == \"EXPERIENCE\"')\n",
    "     .groupby('text')\n",
    "     .agg(n=('text', 'count'),\n",
    "      ads = ('docidx', 'nunique'),\n",
    "     )\n",
    "  .query('n > 1')\n",
    "  .sort_values([ 'ads', 'n'], ascending=False)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0bab1acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In this role  you will participate in process harmonization workshops with the global team  and be responsible for documenting the current state processes for a specific region  As the team progresses in process harmonization and iterates towards a future state  you will be critical in ensuring that the specific regional requirements are accounted for  that any critical regional business functions are supported in the future state process Role Responsibilities Work closely with local business teams to become functional experts in key channel sales   end user sales   merchandising   digital and physical retail processes and related solutions needs Establish credibility as trusted advisors by listening  understanding business requirements  and providing options for consideration The successful candidate will specialize in business stakeholder engagement and facilitation  asking probing questions that get to the real business needs  asking  why  and not just taking requirements at face value   encouraging open communication between all parties and building cooperation amongst the various business teams Understand the strategy and the changing needs of the business via business workshop facilitation and roadmap development for future state  This will involve working with regional business stakeholders  global management teams and colleagues across geographies Focus on recommending process innovation and efficiencies through current state process analysis  user experience  observations  industry trends  standard methodologies  Design Thinking  Agile   leading edge technology and process improvement ideas to challenge the status quo and deliver extraordinary customer focused solutions Understand and document the regional nuances that differ between the current and future state processes Support change management and training needs by providing your understanding of the specific regional requirements and recommendations for a smooth transition into the future state Skills Required Organized  with a natural inclination for both strategic and tactical planning and turn strategy into tangible deliverables Excellent analytical and problem solving skills  outstanding attention to detail and conceptual thinking abilities Analyse business requirements to determine the most effective approach to serving the needs of the organization Proven ability to work independently  exercising judgement and initiative Collaborative  flexible and open working style  with an ability to establish and maintain trust and credibility High level of professionalism  energy  and sense of urgency to make things happen Excellent time management and prioritization skills Ability to influence others and move toward a common vision or goal Exceptional written and verbal communication  and presentation skills  to audiences of varying seniority Capacity to extract  collate and present information in a cohesive and meaningful manner Strong interpersonal skills and excellent active listening skills Self motivated individual  who thrives working in a global  matrixed  fast paced environment  Related Technical Skills Required Strong knowledge of Consumer  Retail  Enterprise channel   End customer sales  Experience in Sales operations  partner management   enablement preferred  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " as a business analyst role on enterprise scale CRM  PRM projects Working knowledge of process documentation  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In this role  you will participate in process harmonization workshops with the global team  and be responsible for documenting the current state processes for a specific region  As the team progresses in process harmonization and iterates towards a future state  you will be critical in ensuring that the specific regional requirements are accounted for  that any critical regional business functions are supported in the future state process Role Responsibilities Work closely with local business teams to become functional experts in key channel sales   end user sales   merchandising   digital and physical retail processes and related solutions needs Establish credibility as trusted advisors by listening  understanding business requirements  and providing options for consideration The successful candidate will specialize in business stakeholder engagement and facilitation  asking probing questions that get to the real business needs  asking  why  and not just taking requirements at face value   encouraging open communication between all parties and building cooperation amongst the various business teams Understand the strategy and the changing needs of the business via business workshop facilitation and roadmap development for future state  This will involve working with regional business stakeholders  global management teams and colleagues across geographies Focus on recommending process innovation and efficiencies through current state process analysis  user experience  observations  industry trends  standard methodologies  Design Thinking  Agile   leading edge technology and process improvement ideas to challenge the status quo and deliver extraordinary customer focused solutions Understand and document the regional nuances that differ between the current and future state processes Support change management and training needs by providing your understanding of the specific regional requirements and recommendations for a smooth transition into the future state Skills Required Organized  with a natural inclination for both strategic and tactical planning and turn strategy into tangible deliverables Excellent analytical and problem solving skills  outstanding attention to detail and conceptual thinking abilities Analyse business requirements to determine the most effective approach to serving the needs of the organization Proven ability to work independently  exercising judgement and initiative Collaborative  flexible and open working style  with an ability to establish and maintain trust and credibility High level of professionalism  energy  and sense of urgency to make things happen Excellent time management and prioritization skills Ability to influence others and move toward a common vision or goal Exceptional written and verbal communication  and presentation skills  to audiences of varying seniority Capacity to extract  collate and present information in a cohesive and meaningful manner Strong interpersonal skills and excellent active listening skills Self motivated individual  who thrives working in a global  matrixed  fast paced environment  Related Technical Skills Required Strong knowledge of Consumer  Retail  Enterprise channel   End customer sales  Experience in Sales operations  partner management   enablement preferred  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " as a business analyst role on enterprise scale CRM  PRM projects Working knowledge of process documentation  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The Mon  Thur  inc  of the first week of every three weeks  No expenses can be claimed to  from the base  Potentially 1 week periods in the USA every 1   2 months  hence must be able to travel to the US   End User  Belron International IR 35 Status  PAYE only Job Description    Data modelling expertise   mandatory   Experience of Erwin or similar tool  e g  Sparx EA    mandatory   Experience and knowledge of API design   mandatory   Data Architecting \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       "   valuable  but not mandatory   Knowledge of the Salesforce Data model   valuable  but not mandatory   Knowledge of JSON structures and generating JSON structures   mandatory   Experience and knowledge of API design   mandatory Data Architect   Integration   6 month contract</br></br></br>        Show more</br></br>        </br></br></br>        Show less</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">but we d still like to hear from you if you don t  Experience in the Telecommunications sector Background in agency or consultancy Experience in deep learning  neural networks  reinforcement and adaptive learning \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " in digital data sets  e g  social listening and social network analysis  plus natural language processing Familiarity with Cloud platforms  Microsoft Azure  GCP or AWS  and data visualisation using Power BIExperience in Marketing ROI initiatives such as Econometrics  Marketing Mix Modelling  Attribution What we can offer you We understand the importance of recognising and rewarding our colleagues  In addition to your base salary  you will be provided with a company bonus commission  pension scheme  private healthcare cover  income protection and life assurance  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">but we d still like to hear from you if you don t  Experience in the Telecommunications sector Background in agency or consultancy Experience in deep learning  neural networks  reinforcement and adaptive learning \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Experience\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EXPERIENCE</span>\n",
       "</mark>\n",
       " in digital data sets  e g  social listening and social network analysis  plus natural language processing Familiarity with Cloud platforms  Microsoft Azure  GCP or AWS  and data visualisation using Power BIExperience in Marketing ROI initiatives such as Econometrics  Marketing Mix Modelling  Attribution What we can offer you We understand the importance of recognising and rewarding our colleagues  In addition to your base salary  you will be provided with a company bonus commission  pension scheme  private healthcare cover  income protection and life assurance  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_exp('Experience', n_max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57c671c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SQL</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coding skills</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pandas</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music industry</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music production</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar data scientist role</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Warehouse Design</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discipline Experience</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understanding</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              n  ads\n",
       "text                                \n",
       "SQL                          30   30\n",
       "Coding skills                14   14\n",
       "Pandas                       14   14\n",
       "music industry               14   14\n",
       "music production             14   14\n",
       "similar data scientist role  14   14\n",
       "Data Warehouse Design         9    9\n",
       "discipline Experience         9    9\n",
       "understanding                 9    9\n",
       "data                          3    3"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_experience('SQL').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7cd84934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data science role</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowlege</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software engineering Experience</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMs</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enterprise scale NLP solutions</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Visualisation experience Knowledge</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advanced SQL TSQLKnowledge</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Intelligence capabilities</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solutions</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toolsets</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big Data Additional Information Netcompany</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Architecture</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             n  ads\n",
       "text                                               \n",
       "Python                                      71   71\n",
       "data science role                           32   32\n",
       "knowlege                                    32   32\n",
       "software engineering Experience             32   32\n",
       "GLMs                                        15   15\n",
       "algorithms                                  15   15\n",
       "enterprise scale NLP solutions              15   15\n",
       "Data Visualisation experience Knowledge     11   11\n",
       "advanced SQL TSQLKnowledge                  11   11\n",
       "Business Intelligence capabilities           7    7\n",
       "event                                        7    7\n",
       "solutions                                    7    7\n",
       "toolsets                                     7    7\n",
       "Big Data Additional Information Netcompany   6    6\n",
       "Data Architecture                            6    6"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_experience('Python').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d22cfc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAG</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build tools</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recruitment</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing frameworks</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n  ads\n",
       "text                      \n",
       "Java                5    5\n",
       "DAG                 4    4\n",
       "build tools         4    4\n",
       "recruitment         4    4\n",
       "testing frameworks  4    4"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_experience('Java').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a7addf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [n, ads]\n",
       "Index: []"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_experience('Javascript').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5063ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = pd.read_csv (r'skills.txt')\n",
    "read_file.to_csv (r'skills.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ab11a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    map(pd.read_csv, ['skills.csv', 'skills_1.csv','skills_2.csv']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d136c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('skills_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b2f1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual clean the set of skills "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa74c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"skills.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "825eccac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Skills\n",
       "0            sql\n",
       "1         python\n",
       "2            aws\n",
       "3         design\n",
       "4  data analysis"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "213e1522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8007"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c03d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Skills\"] = df[\"Skills\"].str.lower() #lowercase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b93f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x for x in df[\"Skills\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_extractor(text):\n",
    "    if i in text and i in data:\n",
    "        return i\n",
    "skill_extractor(desc_tokenized)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
